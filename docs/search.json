[
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "API를 이용한 데이터 수집",
    "section": "",
    "text": "API 제공자는 본인이 가진 데이터베이스를 다른 누군가가 쉽게 사용할 수 있는 형태로 가지고 있으며, 해당 데이터베이스에 접근할 수 있는 열쇠인 API 주소를 가진 사람은 이를 언제든지 사용할 수 있습니다.\nAPI는 API 주소만 가지고 있다면 데이터를 언제, 어디서, 누구나 쉽게 이용할 수 있다는 장점이 있습니다. 또한 대부분의 경우 사용자가 필요한 데이터만을 가지고 있으므로 접속 속도가 빠르며, 데이터를 가공하는 번거로움도 줄어듭니다. 해외에는 금융 데이터를 API의 형태로 제공하는 업체가 많으므로, 이를 잘만 활용한다면 매우 손쉽게 퀀트 투자에 필요한 데이터를 수집할 수 있습니다."
  },
  {
    "objectID": "api.html#주가-다운로드",
    "href": "api.html#주가-다운로드",
    "title": "API를 이용한 데이터 수집",
    "section": "주가 다운로드",
    "text": "주가 다운로드\ngetSymbols() 함수의 기본적인 사용법은 매우 간단합니다. 괄호 안에 다운로드하려는 종목의 티커를 입력하면 됩니다.\n\nlibrary(quantmod)\ngetSymbols('AAPL')\n\n[1] \"AAPL\"\n\n\n\nhead(AAPL)\n\n           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted\n2007-01-03  3.081786  3.092143 2.925000   2.992857  1238319600      2.551165\n2007-01-04  3.001786  3.069643 2.993571   3.059286   847260400      2.607790\n2007-01-05  3.063214  3.078571 3.014286   3.037500   834741600      2.589220\n2007-01-08  3.070000  3.090357 3.045714   3.052500   797106800      2.602005\n2007-01-09  3.087500  3.320714 3.041071   3.306071  3349298400      2.818154\n2007-01-10  3.383929  3.492857 3.337500   3.464286  2952880000      2.953019\n\n\n먼저 getSymbols() 함수 내에 애플의 티커인 AAPL을 입력합니다. 티커와 동일한 변수인 AAPL이 생성되며, 주가 데이터가 다운로드된 후 xts 형태로 입력됩니다.\n다운로드 결과로 총 6개의 열이 생성됩니다. Open은 시가, High는 고가, Low는 저가, Close는 종가를 의미합니다. 또한 Volume은 거래량을 의미하며, Adjusted는 배당이 반영된 수정주가를 의미합니다. 이 중 가장 많이 사용되는 데이터는 Adjusted, 즉 배당이 반영된 수정주가입니다.\n\nchart_Series(Ad(AAPL))\n\n\n\n\n\n\n\n\nAd() 함수를 통해 다운로드한 데이터에서 수정주가만을 선택한 후 chart_Series() 함수를 이용해 시계열 그래프를 그릴 수도 있습니다. 시계열 기간을 입력하지 않으면 2007년 1월부터 현재까지의 데이터가 다운로드되며, 입력 변수를 추가해서 원하는 기간의 데이터를 다운로드할 수도 있습니다.\n\ndata = getSymbols('AAPL',\n                  from = '2000-01-01', to = '2018-12-31',\n                  auto.assign = FALSE)\nhead(data)\n\n           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted\n2000-01-03  0.936384  1.004464 0.907924   0.999442   535796800      0.851942\n2000-01-04  0.966518  0.987723 0.903460   0.915179   512377600      0.780115\n2000-01-05  0.926339  0.987165 0.919643   0.928571   778321600      0.791530\n2000-01-06  0.947545  0.955357 0.848214   0.848214   767972800      0.723033\n2000-01-07  0.861607  0.901786 0.852679   0.888393   460734400      0.757282\n2000-01-10  0.910714  0.912946 0.845982   0.872768   505064000      0.743963\n\n\nfrom에는 시작시점을 입력하고 to에는 종료시점을 입력하면 해당 기간의 데이터가 다운로드됩니다.\ngetSymbols() 함수를 통해 다운로드한 데이터는 자동으로 티커와 동일한 변수명에 저장됩니다. 만일 티커명이 아닌 원하는 변수명에 데이터를 저장하려면 auto.assign 인자를 FALSE로 설정해주면 다운로드한 데이터가 원하는 변수에 저장됩니다.\n\nticker = c('META', 'NVDA') \ngetSymbols(ticker)\n\n[1] \"META\" \"NVDA\"\n\n\n\nhead(META)\n\n           META.Open META.High META.Low META.Close META.Volume META.Adjusted\n2012-05-18     42.05     45.00    38.00      38.23   573576400         38.23\n2012-05-21     36.53     36.66    33.00      34.03   168192700         34.03\n2012-05-22     32.61     33.59    30.94      31.00   101786600         31.00\n2012-05-23     31.37     32.50    31.36      32.00    73600000         32.00\n2012-05-24     32.95     33.21    31.77      33.03    50237200         33.03\n2012-05-25     32.90     32.95    31.11      31.91    37149800         31.91\n\n\n\nhead(NVDA)\n\n           NVDA.Open NVDA.High NVDA.Low NVDA.Close NVDA.Volume NVDA.Adjusted\n2007-01-03  6.178333  6.253333 5.798333   6.013333   115482000      5.518750\n2007-01-04  5.991667  6.013333 5.838333   5.985000    79729800      5.492747\n2007-01-05  5.843333  5.866667 5.570000   5.610000   124334400      5.148589\n2007-01-08  5.630000  5.760000 5.533333   5.651667    65727000      5.186829\n2007-01-09  5.660000  5.698333 5.535000   5.541667    76416600      5.085876\n2007-01-10  5.483333  5.866667 5.400000   5.815000   110874600      5.336730\n\n\n한 번에 여러 종목의 주가를 다운로드할 수도 있습니다. 위 예제와 같이 메타와 엔비디아의 티커인 META와 NVDA를 ticker 변수에 입력하고 getSymbols() 함수에 티커를 입력한 변수를 넣으면 두 종목의 주가가 순차적으로 다운로드됩니다."
  },
  {
    "objectID": "api.html#국내-종목-주가-다운로드",
    "href": "api.html#국내-종목-주가-다운로드",
    "title": "API를 이용한 데이터 수집",
    "section": "국내 종목 주가 다운로드",
    "text": "국내 종목 주가 다운로드\ngetSymbols() 함수를 이용하면 미국뿐 아니라 국내 종목의 주가도 다운로드할 수 있습니다. 국내 종목의 티커는 총 6자리로 구성되어 있으며, 해당 함수에 입력되는 티커는 코스피 상장 종목의 경우 티커.KS, 코스닥 상장 종목의 경우 티커.KQ의 형태로 입력해야 합니다.\n다음은 코스피 상장 종목인 삼성전자 데이터의 다운로드 예시입니다.\n\ngetSymbols('005930.KS')\n\n[1] \"005930.KS\"\n\n\n\ntail(Ad(`005930.KS`))\n\n           005930.KS.Adjusted\n2023-01-12              60500\n2023-01-13              60800\n2023-01-16              61100\n2023-01-17              61000\n2023-01-18              60400\n2023-01-19              61000\n\n\nCl() 함수는 Close, 즉 종가만을 선택하며, 사용 방법은 Ad() 함수와 동일합니다. 비록 배당을 고려할 수는 없지만, 전반적으로 오류가 없는 데이터를 사용할 수 있습니다.\n다음은 코스닥 상장종목인 셀트리온제약의 예시이며, 티커인 068670에 .KQ를 붙여 함수에 입력합니다. 역시나 데이터가 다운로드되어 티커명의 변수에 저장됩니다.\n\ngetSymbols(\"068760.KQ\")\n\n[1] \"068760.KQ\"\n\n\n\ntail(Cl(`068760.KQ`))\n\n           068760.KQ.Close\n2023-01-12              NA\n2023-01-13              NA\n2023-01-16              NA\n2023-01-17              NA\n2023-01-18              NA\n2023-01-19           65700"
  },
  {
    "objectID": "api.html#sql에-데이터-저장하기",
    "href": "api.html#sql에-데이터-저장하기",
    "title": "API를 이용한 데이터 수집",
    "section": "SQL에 데이터 저장하기",
    "text": "SQL에 데이터 저장하기\nAPI나 크롤링을 통해 수집한 데이털르 SQL에 저장해보도록 하겠다. 먼저 SQL에서 다음과 같이 데이터베이스와 주가가 들어갈 테이블을 만든다.\n\ncreate database stock_db;\nuse stock_db;\n\ncreate table price\n(\n    날짜 date,\n    시가 double,\n    고가 double,\n    저가 double,\n    종가 double,\n    거래량 double,\n    종목코드 varchar(6),\n    primary key(날짜, 종목코드)\n);\n\n\n\n\n\n\n이제 삼성전자 주가를 SQL에 저장해보도록 하자.\n\nlibrary(magrittr)\n\ndf = `005930.KS` %>% fortify.zoo() %>%\n  select(1:6) %>%\n  mutate(종목코드 = '005930') %>%\n  set_colnames(c('날짜', '시가', '고가', '저가', '종가', '거래량', '종목코드'))\n\n데이터를 받은 후 클렌징 처리를 해준다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\ndbSendQuery(con,\n  \"SET GLOBAL local_infile = TRUE;\"\n)\n\ndbWriteTable(con, \"price\", df,\n             overwrite = TRUE, row.names = FALSE)\n\n\nR과 SQL을 연결한다.\nlocal_infile를 TRUE로 설정한다.\ndbWriteTable() 함수를 이용해 데이터를 price 테이블에 저장한다.\n\n\n\n\n\n\nSQL을 확인해보면 주가 데이터가 저장되어 있습니다."
  },
  {
    "objectID": "api.html#가입-및-api-token-받기",
    "href": "api.html#가입-및-api-token-받기",
    "title": "API를 이용한 데이터 수집",
    "section": "가입 및 API token 받기",
    "text": "가입 및 API token 받기\n먼저 https://api.tiingo.com/ 사이트에 접속하여 우측 상단의 [Sign-up]을 클릭해 회원가입을 합니다. 그 후 로그인을 한 후 우측 상단에서 본인의 ID를 클릭한 후 [Account]를 선택, 좌측 메뉴의 [API] 부분에서 [Token]을 클릭하면 본인의 API token을 확인할 수 있습니다.\n다음으로 발급받은 API Key를 .Renviron 파일에 추가하도록 합니다. 해당 파일에는 여러 패스워드를 추가해 안전하게 관리할 수 있습니다.\n\nfile.edit(\"~/.Renviron\")\n\n.Renviron 파일이 열리면 다음과 같이 입력을 해줍니다.\n\nRIINGO_TOKEN = '발급받은 API'\n\n파일을 저장한 후 해당 파일을 적용하기 위해 R의 Session을 재시작(ctrl+shift+F10)합니다. 그 후 아래 명령어를 실행하여 API Key를 불러오도록 합니다. (재시작하지 않으면 Key를 불러올 수 없습니다.)\n다시 시작한 후 API Key를 불러옵니다.\n\nRIINGO_TOKEN = Sys.getenv(\"RIINGO_TOKEN\")"
  },
  {
    "objectID": "api.html#데이터-다운로드",
    "href": "api.html#데이터-다운로드",
    "title": "API를 이용한 데이터 수집",
    "section": "데이터 다운로드",
    "text": "데이터 다운로드\nR에서 tiingo를 사용할 수 있게 해주는 riingo 패키지를 이용해 데이터를 받아보도록 하겠습니다. 먼저 tiingo에서 제공하는 종목은 어떠한 것이 있는지 티커 정보들을 확인해봅니다.\n\n# install.packages(\"riingo\")\nlibrary(riingo)\n\ntickers = supported_tickers()\ntickers\n\n# A tibble: 106,998 × 6\n   ticker exchange assetType priceCurr…¹ startDate           endDate            \n   <chr>  <chr>    <chr>     <chr>       <dttm>              <dttm>             \n 1 000001 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 2 000002 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 3 000003 SHE      Stock     CNY         NA                  NA                 \n 4 000004 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 5 000005 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 6 000006 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 7 000007 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 8 000008 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 9 000009 SHE      Stock     CNY         2007-01-05 00:00:00 2023-01-18 00:00:00\n10 000010 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n# … with 106,988 more rows, and abbreviated variable name ¹​priceCurrency\n\n\nticker(티커), exchange(거래소), assetType(주식 종류), priceCurrency(거래 통화), startDate(시작일), endDate(마감일) 정보가 표시됩니다. 거래소와 통화 별 종목이 몇개가 있는지 확인해보도록 하겠습니다.\n\nlibrary(dplyr)\n\ntickers %>% group_by(exchange, priceCurrency) %>% summarize(n = n()) %>%\n  arrange(priceCurrency, desc(n))\n\n# A tibble: 27 × 3\n# Groups:   exchange [24]\n   exchange priceCurrency     n\n   <chr>    <chr>         <int>\n 1 ASX      AUD             169\n 2 SHE      CNY            2570\n 3 SHG      CNY            1936\n 4 SHEB     HKD              42\n 5 SHE      HKD              12\n 6 NMFQS    USD           46245\n 7 PINK     USD           14416\n 8 NASDAQ   USD           13113\n 9 NYSE     USD            8170\n10 OTCGREY  USD            4011\n# … with 17 more rows\n\n\n이 중 마이너 거래소나 장외 거래소의 경우 정보를 받아도 우리나라의 증권사를 통해서는 실제로 거래를 할 수 없을수도 있습니다. 따라서 실제 거래가 가능한 거래소 데이터만 필터링한 후 해당 종목들을 받는 것이 효율적입니다.\n각 종목의 상세 정보를 확인해보도록 하겠습니다.\n\nriingo_meta(\"AAPL\")\n\n# A tibble: 1 × 6\n  ticker name      description   startDate           endDate             excha…¹\n  <chr>  <chr>     <chr>         <dttm>              <dttm>              <chr>  \n1 AAPL   Apple Inc Apple Inc. (… 1980-12-12 00:00:00 2023-01-18 00:00:00 NASDAQ \n# … with abbreviated variable name ¹​exchangeCode\n\n\nriingo_meta() 함수 내에 티커를 입력하면 티커, 종목명, 사업내역 등 대략적인 정보를 받아올 수 있습니다.\n이제 주가를 받아보도록 합시다.\n\nriingo_prices(\"AAPL\")\n\n# A tibble: 251 × 14\n   ticker date                close  high   low  open    volume adjClose adjHigh\n   <chr>  <dttm>              <dbl> <dbl> <dbl> <dbl>     <int>    <dbl>   <dbl>\n 1 AAPL   2022-01-19 00:00:00  166.  171.  166.  170   92914792     165.    170.\n 2 AAPL   2022-01-20 00:00:00  165.  170.  164.  167.  91420515     163.    168.\n 3 AAPL   2022-01-21 00:00:00  162.  166.  162.  164. 122848858     161.    165.\n 4 AAPL   2022-01-24 00:00:00  162.  162.  155.  160. 162706686     160.    161.\n 5 AAPL   2022-01-25 00:00:00  160.  163.  157.  159. 115798367     159.    162.\n 6 AAPL   2022-01-26 00:00:00  160.  164.  158.  164. 108275308     159.    163.\n 7 AAPL   2022-01-27 00:00:00  159.  164.  158.  162. 121954638     158.    163.\n 8 AAPL   2022-01-28 00:00:00  170.  170.  163.  166. 179935660     169.    169.\n 9 AAPL   2022-01-31 00:00:00  175.  175   170.  170. 115541590     174.    174.\n10 AAPL   2022-02-01 00:00:00  175.  175.  172.  174.  86213911     173.    174.\n# … with 241 more rows, and 5 more variables: adjLow <dbl>, adjOpen <dbl>,\n#   adjVolume <int>, divCash <dbl>, splitFactor <dbl>\n\n\nriingo_prices() 함수 내에 티커를 입력하면 close(종가), high(고가), low(저가), open(시가), volumne(거래량) 및 수정주가와 divCash(현금 배당), splitFactor(주식분할 조정계수)까지 데이터를 받을 수 있습니다.\n이번에는 일별 가치지표를 받아보도록 합니다. (무료 계정의 경우 다우존스 30 지수에 포함되는 종목 정보만 제공합니다.)\n\nriingo_fundamentals_metrics('AAPL')\n\n# A tibble: 254 × 7\n   ticker date                    marketCap enterprise…¹ peRatio pbRatio trail…²\n   <chr>  <dttm>                      <dbl>        <dbl>   <dbl>   <dbl>   <dbl>\n 1 AAPL   2022-01-19 00:00:00 2727235373310      2.81e12    27.1    37.9    1.12\n 2 AAPL   2022-01-20 00:00:00 2699016370470      2.78e12    26.8    37.5    1.11\n 3 AAPL   2022-01-21 00:00:00 2664562936770      2.75e12    26.5    37.0    1.10\n 4 AAPL   2022-01-24 00:00:00 2651601883140      2.74e12    26.4    36.9    1.09\n 5 AAPL   2022-01-25 00:00:00 2621414112660      2.71e12    26.1    36.4    1.08\n 6 AAPL   2022-01-26 00:00:00 2619937536930      2.71e12    26.1    36.4    1.08\n 7 AAPL   2022-01-27 00:00:00 2612226530340      2.70e12    26.0    36.3    1.08\n 8 AAPL   2022-01-28 00:00:00 2779690385530      2.87e12    27.6    38.6    1.15\n 9 AAPL   2022-01-31 00:00:00 2852311897980      2.94e12    28.4    39.7    1.18\n10 AAPL   2022-02-01 00:00:00 2849537593010      2.94e12    28.3    39.6    1.17\n# … with 244 more rows, and abbreviated variable names ¹​enterpriseVal,\n#   ²​trailingPEG1Y\n\n\nriingo_fundamentals_metrics() 함수 내에 티커를 입력하면 일간 시가총액, 기업가치, PER, PBR, PEG 정보가 받아집니다.\n마지막으로 재무제표를 받아보도록 합니다.\n\ndf = riingo_fundamentals_statements('AAPL')\ndf\n\n# A tibble: 4 × 8\n  ticker date                 year quarter balanceSheet  cashF…¹ incom…² overv…³\n  <chr>  <dttm>              <int>   <int> <list>        <list>  <list>  <list> \n1 AAPL   2022-09-24 00:00:00  2022       4 <df [26 × 2]> <df>    <df>    <df>   \n2 AAPL   2022-09-24 00:00:00  2022       0 <df [26 × 2]> <df>    <df>    <df>   \n3 AAPL   2022-06-25 00:00:00  2022       3 <df [26 × 2]> <df>    <df>    <df>   \n4 AAPL   2022-03-26 00:00:00  2022       2 <df [26 × 2]> <df>    <df>    <df>   \n# … with abbreviated variable names ¹​cashFlow, ²​incomeStatement, ³​overview\n\n\n티블 내에 다시 데이터프레임이 들어간 형태입니다. 이 중 필요한 데이터만 선택해 묶음을 풀어주면 됩니다.\n\nlibrary(tidyr)\n\ndf %>%\n  select(ticker, date, year, quarter, balanceSheet) %>%\n  unnest(cols = c('balanceSheet'))\n\n# A tibble: 104 × 6\n   ticker date                 year quarter dataCode                     value\n   <chr>  <dttm>              <int>   <int> <chr>                        <dbl>\n 1 AAPL   2022-09-24 00:00:00  2022       4 liabilitiesCurrent    153982000000\n 2 AAPL   2022-09-24 00:00:00  2022       4 equity                 50672000000\n 3 AAPL   2022-09-24 00:00:00  2022       4 taxLiabilities                   0\n 4 AAPL   2022-09-24 00:00:00  2022       4 liabilitiesNonCurrent 148101000000\n 5 AAPL   2022-09-24 00:00:00  2022       4 retainedEarnings       -3068000000\n 6 AAPL   2022-09-24 00:00:00  2022       4 debtCurrent            21110000000\n 7 AAPL   2022-09-24 00:00:00  2022       4 taxAssets                        0\n 8 AAPL   2022-09-24 00:00:00  2022       4 assetsNonCurrent      217350000000\n 9 AAPL   2022-09-24 00:00:00  2022       4 acctPay                64115000000\n10 AAPL   2022-09-24 00:00:00  2022       4 debt                  120069000000\n# … with 94 more rows"
  },
  {
    "objectID": "backtest.html",
    "href": "backtest.html",
    "title": "백테스트 실습하기",
    "section": "",
    "text": "백테스트란 현재 생각하는 전략을 과거부터 실행했을 때 어떠한 성과가 발생하는지 테스트해보는 과정입니다. 과거의 데이터를 기반으로 전략을 실행하는 퀀트 투자에 있어서 이는 핵심 단계이기도 합니다. 백테스트 결과를 통해 해당 전략의 손익뿐만 아니라 각종 위험을 대략적으로 판단할 수 있으며, 어떤 구간에서 전략이 좋았는지 혹은 나빴는지에 대한 이해도 키울 수 있습니다. 이러한 이해를 바탕으로 퀀트 투자를 지속한다면 단기적으로 수익이 나쁜 구간에서도 그 이유에 대한 객관적인 안목을 키울 수 있으며, 확신을 가지고 전략을 지속할 수 있습니다.\n그러나 백테스트를 아무리 보수적으로 혹은 엄밀하게 진행하더라도 이미 일어난 결과를 대상으로 한다는 사실은 변하지 않습니다. 백테스트 수익률만을 보고 투자에 대해 판단하거나, 혹은 동일한 수익률이 미래에도 반복될 것이라고 믿는다면 이는 백미러만 보고 운전하는 것처럼 매우 위험한 결과를 초래할 수도 있습니다.\nR에서 백테스트는 포트폴리오의 경우 PerformanceAnalytics 패키지의 Return.portfolio() 함수를 사용하면 쉽게 할 수 있습니다."
  },
  {
    "objectID": "backtest.html#return.portfolio-함수",
    "href": "backtest.html#return.portfolio-함수",
    "title": "백테스트 실습하기",
    "section": "Return.Portfolio() 함수",
    "text": "Return.Portfolio() 함수\n프로그래밍을 이용해 백테스트할 때 전략이 단순하다면 단 몇 줄만으로도 테스트가 가능합니다. 그러나 전략이 복잡해지거나 적용해야 할 요소가 많아질 경우, 패키지를 이용하는 것이 효율적인 방법입니다.\nPerformanceAnalytics 패키지의 Return.portfolio() 함수는 백테스트를 수행하는데 가장 대중적으로 사용되는 함수입니다. 해당 함수의 가장 큰 장점은 각 자산의 수익률과 리밸런싱 비중만 있으면 백테스트 수익률, 회전율 등을 쉽게 계산할 수 있으며, 리밸런싱 시점과 수익률의 시점이 일치하지 않아도 된다는 점입니다. 즉, 수익률 데이터는 일간, 리밸런싱 시점은 분기 혹은 연간으로 된 경우에도 매우 쉽게 백테스트를 수행할 수 있습니다.\n\n인자 목록 살펴보기\n먼저 Return.portfolio() 함수는 다음과 같은 형태로 구성되어 있습니다.\n\nReturn.portfolio(R, weights = NULL, wealth.index = FALSE,\n  contribution = FALSE, geometric = TRUE,\n  rebalance_on = c(NA, \"years\", \"quarters\", \n                   \"months\", \"weeks\", \"days\"),\n  value = 1, verbose = FALSE, ...)\n\n\n\n\n\n\n\n\n인자\n내용\n\n\n\n\nR\n각 자산 수익률 데이터\n\n\nweights\n리밸런싱 시기의 자산별 목표 비중. 미 입력시 동일비중 포트폴리오를 가정해 백테스트가 이루어짐\n\n\nwealth.index\n포트폴리오 시작점이 1인 wealth index에 대한 생성 여부이며, 디폴트는 FALSE로 설정\n\n\ncontribution\n포트폴리오 내에서 자산별 성과기여를 나타내는지에 대한 여부이며, 디폴트는 FALSE로 설정\n\n\ngeometric\n포트폴리오 수익률 계산시 복리(기하)수익률 적용 여부이며, 디폴트는 TRUE로서 복리수익률을 계산\n\n\nrebalance_on\nweight 값이 미입력 혹은 매번 같은 비중일 경우, 리밸런싱 주기를 선택할 수 있음\n\n\nvalue\n초기 포트폴리오 가치를 의미하며, 디폴트는 1\n\n\nverbose\n부가적인 결과를 표시할지에 대한 여부. 디폴트인 FALSE를 입력하면 포트폴리오 수익률만이 시계열 형태로 계산되며, TRUE를 입력하면 수익률 외에 자산 별 성과기여, 비중, 성과 등이 리스트 형태로 계산됨\n\n\n\n이 중 가장 중요한 인자는 개별 자산의 수익률인 R과 리밸런싱 시기의 자산별 목표 비중인 weights입니다. 매 리밸런싱 시점마다 적용되는 자산별 비중이 동일할 경우(예: 매월 말 60%대 40% 비중으로 리밸런싱) 상수 형태로 입력해도 되지만, 시점마다 자산별 목표비중이 다를 경우 weights는 시계열 형태로 입력되어야 합니다.\n목표 비중을 시계열 형태로 입력할 때 주의해야 할 점은 다음과 같습니다.\n\n시계열 형태로 인식할 수 있도록 행 이름 혹은 인덱스가 날짜 형태로 입력되어야 합니다.\n수익률 데이터와 비중 데이터의 열 개수는 동일해야 하며, 각 열에 해당하는 자산은 동일해야 합니다. 즉, 수익률 데이터의 첫 번째 열에 A주식 데이터가 있다면, 비중 데이터의 첫 번째 열도 A주식의 목표 비중을 입력해야 합니다.\n각 시점의 비중의 합은 1이 되어야 합니다. 그렇지 않을 경우 제대로 된 수익률이 계산되지 않습니다.\n\nweights에 값을 입력하지 않을 경우 동일비중 포트폴리오를 구성하며, 포트폴리오 리밸런싱은 하지 않습니다.\n\n\n출력값 살펴보기\n해당 함수는 verbose 인자를 TRUE로 설정하면 다양한 결괏값을 리스트 형태로 반환합니다.\n\n\n\n\n\n\n\n결과\n내용\n\n\n\n\nreturns\n포트폴리오 수익률\n\n\ncontribution\n일자별 개별 자산의 포트폴리오 수익률 기여도\n\n\nBOP.Weight\n일자별 개별 자산의 포트폴리오 내 비중(시작시점). 리밸런싱이 없을 시 직전 기간 EOP.Weight와 동일\n\n\nEOP.Weight\n일자별 개별 자산의 포트폴리오 내 비중(종료시점)\n\n\nBOP.Value\n일자별 개별 자산의 가치(시작시점). 리밸런싱이 없을 시 직전 기간 EOP.Value와 동일\n\n\nEOP.Value\n일자별 개별 자산의 가치(종료시점)"
  },
  {
    "objectID": "backtest.html#전통적인-60대-40-포트폴리오-백테스트",
    "href": "backtest.html#전통적인-60대-40-포트폴리오-백테스트",
    "title": "백테스트 실습하기",
    "section": "전통적인 60대 40 포트폴리오 백테스트",
    "text": "전통적인 60대 40 포트폴리오 백테스트\nReturn.portfolio() 함수의 가장 간단한 예제로서 전통적인 60대 40 포트폴리오를 백테스트합니다. 해당 포트폴리오는 주식과 채권에 각각 60%와 40%를 투자하며, 특정 시점마다 해당 비중을 맞춰주기 위해 리밸런싱을 수행합니다. 매해 말 리밸런싱을 가정하는 예제를 살펴보겠습니다.\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\nlibrary(magrittr)\nticker = c('SPY', 'TLT')\ngetSymbols(ticker)\n\n[1] \"SPY\" \"TLT\"\n\nprices = do.call(cbind,\n                 lapply(ticker, function(x) Ad(get(x))))\nrets = Return.calculate(prices) %>% na.omit()\n\n글로벌 자산의 ETF 데이터 중 주식(S&P 500)과 채권(미국 장기채)에 해당하는 데이터를 다운로드한 후 수익률을 계산합니다.\n\ncor(rets)\n\n             SPY.Adjusted TLT.Adjusted\nSPY.Adjusted    1.0000000   -0.3731717\nTLT.Adjusted   -0.3731717    1.0000000\n\n\ncor() 함수를 통해 두 자산간의 상관관계를 확인해보면 매우 낮은 상관관계를 보이며, 강한 분산효과를 기대해볼 수 있습니다.\n\nportfolio = Return.portfolio(R = rets,\n                             weights = c(0.6, 0.4),\n                             rebalance_on = 'years',\n                             verbose = TRUE)\n\nReturn.portfolio() 함수를 이용하여 백테스트를 실행합니다.\n\n자산의 수익률인 R에는 수익률 테이블인 rets를 입력합니다.\n리밸런싱 비중인 weights에는 60%와 40%를 의미하는 c(0.6, 0.4)를 입력합니다.\n리밸런싱 시기인 rebalance_on에는 연간 리밸런싱에 해당하는 years를 입력합니다. 리밸런싱 주기는 이 외에도 quarters, months, weeks, days도 입력이 가능합니다.\n결과물들을 리스트로 확인하기 위해 verbose를 TRUE로 설정합니다.\n\n위 과정을 통해 주식과 채권 투자비중을 매해 60%와 40%로 리밸런싱하는 포트폴리오의 백테스트가 실행됩니다. 아래 표는 함수 내에서 포트폴리오의 수익률이 어떻게 계산되는지를 요약한 과정입니다.\n\n\n\n\n\n\n\nReturn.portfolio() 계산 과정\n \n\n\n시작금액\n시작합계\n시작비중\n수익률\n종료금액\n종료합계\n종료비중\n최종수익률\n\n  \n      \n    1.주식 \n    2.채권 \n    3.1+2 \n    4.주식 \n    5.채권 \n    6.주식 \n    7.채권 \n    8.주식 \n    9.채권 \n    10.8+9 \n    11.주식 \n    12.채권 \n    13.최종 \n  \n \n\n  \n    2017-12-26 \n    1.603 \n    0.940 \n    2.543 \n    0.630 \n    0.370 \n    -0.001 \n    0.003 \n    1.601 \n    0.943 \n    2.544 \n    0.629 \n    0.371 \n    0.000 \n  \n  \n    2017-12-27 \n    1.601 \n    0.943 \n    2.544 \n    0.629 \n    0.371 \n    0.000 \n    0.013 \n    1.602 \n    0.956 \n    2.557 \n    0.626 \n    0.374 \n    0.005 \n  \n  \n    2017-12-28 \n    1.602 \n    0.956 \n    2.557 \n    0.626 \n    0.374 \n    0.002 \n    -0.001 \n    1.605 \n    0.955 \n    2.560 \n    0.627 \n    0.373 \n    0.001 \n  \n  \n    2017-12-29 \n    1.605 \n    0.955 \n    2.560 \n    0.627 \n    0.373 \n    -0.004 \n    0.002 \n    1.599 \n    0.956 \n    2.555 \n    0.626 \n    0.374 \n    -0.002 \n  \n  \n    2018-01-02 \n    1.533 \n    1.022 \n    2.555 \n    0.600 \n    0.400 \n    0.007 \n    -0.011 \n    1.544 \n    1.011 \n    2.555 \n    0.604 \n    0.396 \n    0.000 \n  \n  \n    2018-01-03 \n    1.544 \n    1.011 \n    2.555 \n    0.604 \n    0.396 \n    0.006 \n    0.005 \n    1.554 \n    1.016 \n    2.570 \n    0.605 \n    0.395 \n    0.006 \n  \n  \n    2018-01-04 \n    1.554 \n    1.016 \n    2.570 \n    0.605 \n    0.395 \n    0.004 \n    0.000 \n    1.560 \n    1.016 \n    2.576 \n    0.606 \n    0.394 \n    0.002 \n  \n\n\n\n\n\n먼저 2017-12-27에 해당하는 데이터를 보면 시작시점에 주식과 채권에는 각각 1.601과 0.943이 투자되어 있으며, 이를 합하면 2.544이 됩니다. 이를 포트폴리오 내 비중으로 환산하면 비중은 각각 0.629와 0.371가 됩니다.\n해당일의 주식과 채권의 수익률은 각각 0, 0.013이 되며, 이를 시작금액에 곱하면 종료시점의 금액은 1.602와 0.956이 됩니다. 각각의 금액을 종료금액의 합인 2.557로 나누게 되면, 포트폴리오 내 비중은 0.626, 0.374로 변하게 됩니다. 포트폴리오 수익률은 2017-12-27 포트폴리오 금액인 2.557을 전일의 포트폴리오 금액인 2.544로 나누어 계산된 값인 0.005가 됩니다.\n리밸런싱이 없다면 2017-12-27일의 종료금액과 종료비중은 다음 날인 2017-12-28의 시작금액과 시작비중에 그대로 적용되며, 위와 동일한 단계를 통해 포트폴리오 수익률이 계산됩니다.\n그러나 매해 리밸런싱을 가정했으므로, 첫 영업일인 2018-01-02에는 포트폴리오 리밸런싱이 이루어집니다. 따라서 전일 2017-12-29의 종료금액의 합인 2.555를 사전에 정의한 0.6과 0.4에 맞게 각 자산을 시작시점에 매수 혹은 매도하게 됩니다. 이후에는 기존과 동일하게 해당일의 수익률을 곱해 종료시점의 금액과 비중을 구한 후 포트폴리오 수익률을 계산하게 됩니다.\n리밸런싱 전일 종료시점의 비중과 리밸런싱 당일 시작시점의 비중 차이의 절대값을 합하면, 포트폴리오의 회전율을 계산할 수도 있습니다. 해당 예제에서는 2017-12-29 종료시점의 비중인 0.626, 0.374와 2018-01-02 시작시점의 비중인 0.6, 0.4의 차이인 0.026, -0.026의 절대값의 합계인 0.052가 회전율이 됩니다.\n이처럼 리밸런싱을 원하는 시점과 비중을 정의하면, Return.portfolio() 함수 내에서는 이러한 단계를 거쳐 포트폴리오의 수익률, 시작과 종료시점의 금액 및 비중이 계산되며, 이를 응용하여 회전율을 계산할 수도 있습니다.\n\nportfolios = cbind(rets, portfolio$returns) %>%\n  setNames(c('주식', '채권', '60대 40'))\n\ncharts.PerformanceSummary(portfolios,\n                          main = '60대 40 포트폴리오')\n\n\n\n\n\n\n\n\nPerformanceAnalytics 패키지의 charts.PerformanceSummary() 함수는 기간별 수익률을 입력 시 누적수익률, 일별 수익률, 드로우다운(낙폭) 그래프를 자동으로 그려줍니다.\n그래프는 색으로 구분되어 각각 주식 수익률(SPY), 채권 수익률(TLT), 60대 40 포트폴리오 수익률을 나타냅니다. 주식과 채권은 상반되는 움직임을 보이며 상승하며, 분산 투자 포트폴리오는 각 개별 자산에 비해 훨씬 안정적인 수익률을 보입니다.\n\nturnover = xts(\n  rowSums(abs(portfolio$BOP.Weight -\n                timeSeries::lag(portfolio$EOP.Weight)),\n          na.rm = TRUE),\n  order.by = index(portfolio$BOP.Weight))\n\nchart.TimeSeries(turnover)\n\n\n\n\n\n\n\n\n전일 종료시점의 비중인 EOP.Weight를 lag() 함수를 이용해 한 단계씩 내린 후 시작시점의 비중인 BOP.Weight와의 차이의 절댓값을 더해주면 해당 시점에서의 회전율이 계산됩니다. lag() 함수의 경우 dplyr 패키지에도 동일한 이름의 함수가 있으므로, 충돌을 방지하기 위해 timeSeries 패키지의 함수임을 선언해줍니다. 이를 xts() 함수를 이용해 시계열 형태로 만든 후 chart.TimeSeries() 함수를 이용해 그래프로 나타내줍니다.\n리밸런싱 시점에 해당하는 매해 첫 영업일에 회전율이 발생하며, 그렇지 않은 날은 매수 혹은 매도가 없으므로 회전율 역시 0을 기록합니다. 2008년에는 주식과 채권의 등락폭이 심했으므로 이듬해엔 2009년 리밸런싱으로 인한 회전율이 심하지만, 이를 제외한 해는 회전율이 그리 심하지 않습니다."
  },
  {
    "objectID": "backtest.html#마켓-타이밍-전략-백테스트",
    "href": "backtest.html#마켓-타이밍-전략-백테스트",
    "title": "백테스트 실습하기",
    "section": "마켓 타이밍 전략 백테스트",
    "text": "마켓 타이밍 전략 백테스트\n이전 테스트가 리밸런싱 시점별 비중이 60%와 40%로 고정되어 있었다면, 이번에는 시점별 비중이 다른 형태의 예제를 살펴보겠습니다.\n메브 파버(Meb Faber)는 본인의 논문을 통해, 시점 선택(Market Timing) 전략을 사용할 경우 단순 매수 후 보유 대비 극심한 하락장에서 낙폭을 줄일 수 있으며, 이로 인해 위험 대비 수익률을 올릴 수 있다고 설명합니다. 논문에서 말하는 시점 선택의 투자 규칙은 다음과 같습니다.\n\\[주가 > 10개월\\,이동평균 \\to 매수\\] \\[주가 < 10개월\\,이동평균 \\to 매도\\,및\\,현금\\,보유\\]\n해당 규칙을 미국 S&P 500에 적용하는 예제를 살펴보겠습니다. 현재 주식 가격이 과거 10개월 주식 가격의 단순 평균 대비 이상이면 매수, 그렇지 않으면 전량 매도 후 현금을 보유하는 전략이며, 리밸런싱은 매월 실행합니다.\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\n\nsymbols = c('SPY', 'SHY')\ngetSymbols(symbols, src = 'yahoo')\n\n[1] \"SPY\" \"SHY\"\n\nprices = do.call(cbind,\n                 lapply(symbols, function(x) Ad(get(x))))\nrets = Return.calculate(prices) %>% na.omit\n\n먼저 주식과 현금에 해당하는 ETF 데이터를 다운로드합니다. 주식에 해당하는 ETF로 는 S&P 500 수익률을 추종하는 SPY를 사용하며, 현금에 해당하는 ETF로는 미국 단기채 수익률을 추종하는 SHY를 사용합니다.\n\nwts = list()\nlookback = 10\n\nep = endpoints(rets, on = 'months')\nprint(ep)\n\n  [1]    0   19   38   60   80  102  123  144  167  186  209  230  250  271  291\n [16]  311  333  354  375  397  418  439  462  481  503  523  542  564  585  605\n [31]  627  649  670  691  713  733  755  774  793  816  837  857  879  900  922\n [46]  943  964  985 1007 1027 1046 1069 1089 1110 1132 1152 1175 1196 1217 1238\n [61] 1259 1279 1299 1321 1341 1363 1384 1405 1428 1447 1468 1489 1509 1530 1549\n [76] 1569 1591 1613 1633 1655 1677 1697 1720 1740 1761 1782 1801 1822 1843 1864\n [91] 1885 1907 1928 1949 1972 1991 2013 2033 2052 2074 2095 2115 2137 2159 2180\n[106] 2201 2223 2243 2265 2284 2304 2326 2347 2368 2390 2410 2433 2454 2475 2496\n[121] 2517 2537 2556 2579 2598 2620 2642 2662 2685 2705 2727 2748 2768 2789 2808\n[136] 2829 2850 2872 2893 2914 2937 2956 2979 3000 3019 3040 3059 3080 3101 3123\n[151] 3143 3165 3187 3207 3230 3250 3271 3292 3311 3333 3354 3374 3396 3418 3439\n[166] 3460 3482 3502 3524 3543 3562 3585 3606 3626 3648 3669 3691 3712 3733 3754\n[181] 3776 3796 3815 3838 3858 3879 3900 3920 3943 3964 3985 4006 4027 4038\n\n\n각 시점별 비중이 입력될 wts를 공백의 리스트 형식으로 저장해주며, n개월 이동평균값에 해당하는 lookback 변수는 10을 입력합니다.\nxts 패키지의 endpoints() 함수를 이용해 매월 말일의 위치를 구합니다. 해당 함수는 endpoints(x, on= 'months', k=1)의 형태로 이루어지며 x는 시계열 데이터, on은 원하는 기간, k는 구간 길이를 의미합니다. 즉, 시계열 데이터에서 월말에 해당하는 부분의 위치를 반환하며, 매월이 아닌 weeks, quarters, years도 입력이 가능합니다. 결과적으로 ep에는 rets의 인덱스 중 매월 말일에 해당하는 부분의 위치가 구해집니다.\n\nrets[ep] %>% head()\n\n            SPY.Adjusted  SHY.Adjusted\n2007-01-31  0.0067230635  0.0011249703\n2007-02-28  0.0102510363 -0.0007464134\n2007-03-30  0.0002114229  0.0000000000\n2007-04-30 -0.0082921858  0.0007469322\n2007-05-31 -0.0010418912 -0.0006241438\n2007-06-29  0.0003326802  0.0019998630\n\n\n이를 이용해 월말 지점만 뽑을 수도 있습니다.\n\ni = lookback + 1\nsub_price = prices[ep[i-lookback] : ep[i] , 1]\n\nhead(sub_price, 3)\n\n           SPY.Adjusted\n2007-01-03     103.4001\n2007-01-04     103.6195\n2007-01-05     102.7930\n\ntail(sub_price, 3)\n\n           SPY.Adjusted\n2007-10-26     113.8292\n2007-10-29     114.2071\n2007-10-30     113.4143\n\nsma = mean(sub_price)\n\nwt = rep(0, 2)\nwt[1] = ifelse(last(sub_price) > sma, 1, 0)\nwt[2] = 1 - wt[1]\nwts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n\n해당 전략은 for loop 구문을 통해, 매월 말 과거 10개월 이동평균을 구한 후 매수 혹은 매도를 선택한 후 비중을 계산합니다. 예시를 위해 첫 번째 시점의 테스트 과정을 살펴보며, 과거 10개월에 해당하는 가격의 이동평균이 필요하므로 처음 시작은 i+1 인 11부터 가능합니다.\n\n주가는 일별 데이터이며, 현재부터 과거 10개월에 해당하는 주가를 선택해야 합니다. 앞서 endpoints() 함수를 통해 주가에서 월말 기준점의 위치를 찾았으며, ep[i]는 현재시점 주가의 위치를, ep[i-lookback]는 현재부터 10개월 전 주가 위치를 의미합니다. 이를 통해 과거 10개월 간 주가를 찾은 후 sub_price에 저장합니다.\nmean()을 통해 10개월 주가의 평균을 계산합니다.\nrep(0, 2)를 통해 비중이 들어갈 0벡터를 생성합니다.\nifelse() 구문을 통해 해당 전략의 조건에 맞는 비중을 계산합니다. wt[1]은 주식의 투자비중이며, 만일 현재 주가가 10개월 이동평균보다 클 경우 주식에 해당하는 비중은 1을, 그렇지 않을 경우 0을 부여합니다. wt[2]는 현금의 투자비중이며, 1에서 주식의 투자비중을 뺀 값을 입력합니다. 아래 표에는 해당 규칙이 요약되어 있습니다.\n위에서 만들어진 벡터를 xts()를 통해 시계열 형태로 바꾼 후, wts의 i번째 리스트에 저장해줍니다.\n\n\n\n\n\n\n\n\n\n자산\n현재주가 > 10개월 이동평균\n현재 주가 < 10개월 이동평균\n\n\n\n\n주식비중\nwt[1] = 1\nwt[1] = 0\n\n\n현금비중\nwt[2] = 0\nwt[2] = 1\n\n\n\n위 과정을 for loop 구문을 통해 전체 기간에 적용한 백테스트는 다음과 같습니다.\n\nep = endpoints(rets, on = 'months')\nwts = list()\nlookback = 10\n\nfor (i in (lookback+1) : length(ep)) {\n  sub_price = prices[ep[i-lookback] : ep[i] , 1]\n  sma = mean(sub_price)\n  wt = rep(0, 2)\n  wt[1] = ifelse(last(sub_price) > sma, 1, 0)\n  wt[2] = 1 - wt[1]\n  \n  wts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n}\n\nwts = do.call(rbind, wts)\n\n매월 말 과거 10개월 이동평균을 구한 후 현재 주가와 비교해 주식 혹은 현금 투자비중을 구한 후 wts 리스트에 저장합니다. 그 후 do.call() 함수를 통해 리스트를 테이블로 묶어줍니다.\n수익률 데이터와 비중 데이터가 구해졌으므로 Return.portfolio() 함수를 통해 포트폴리오의 수익률을 계산합니다.\n\nTactical = Return.portfolio(rets, wts, verbose = TRUE)\nportfolios = na.omit(cbind(rets[,1], Tactical$returns)) %>%\n  setNames(c('매수 후 보유', '시점 선택 전략'))\n\ncharts.PerformanceSummary(portfolios,\n                          main = \"Buy & Hold vs Tactical\")\n\n\n\n\n\n\n\n\n\n수익률 데이터와 비중 데이터의 입력을 통해 백테스트를 실행합니다.\ncbind() 함수를 통해 SPY 데이터와 포트폴리오 수익률을 합쳐줍니다. 시점 선택 포트폴리오의 경우 lookback 기간인 초기 10개월에 대한 수익률이 없어 NA로 표시되므로 na.omit()을 통해 해당 부분을 제거합니다.\ncharts.PerformanceSummary() 함수를 통해 수익률을 그래프로 나타냅니다.\n\n검은색 그래프는 S&P 500 에 매수 후 보유 시 수익률이고, 주황색 그래프는 시점 선택 전략을 적용한 수익률입니다. 2008년과 같은 하락장에서 낙폭이 훨씬 낮음이 확인됩니다.\n\nturnover = xts(rowSums(abs(Tactical$BOP.Weight -\n                             timeSeries::lag(Tactical$EOP.Weight)),\n                       na.rm = TRUE),\n               order.by = index(Tactical$BOP.Weight))\n\nchart.TimeSeries(turnover)\n\n\n\n\n\n\n\n\n해당 전략의 회전율을 확인해보면, 몇 년간 매매가 없는 경우도 있습니다. 그러나 매매가 발생할 시 매수와 매도 포지션 양쪽의 매매로 인해 200%의 회전율이 발생하게 됩니다."
  },
  {
    "objectID": "backtest.html#동적-자산배분-백테스트",
    "href": "backtest.html#동적-자산배분-백테스트",
    "title": "백테스트 실습하기",
    "section": "동적 자산배분 백테스트",
    "text": "동적 자산배분 백테스트\n마지막으로 기존에 배웠던 것들을 응용해 동적 자산배분의 백테스트를 수행하겠습니다. 일반적인 자산배분이 주식과 채권, 대체자산에 투자비중을 사전에 정해놓고 약간의 비율만 수정하는 정적 자산배분인 반면, 동적 자산배분이란 투자비중에 대한 제한이 없이 동적으로 포트폴리오를 구성하는 방법입니다.\n동적 자산배분을 이용한 포트폴리오는 다음과 같이 구성됩니다.\n\n글로벌 10개 자산 중 과거 12개월 수익률이 높은 5개 자산을 선택합니다.\n최소분산 포트폴리오를 구성하며, 개별 투자비중은 20%로 합니다.\n매월 리밸런싱을 실시합니다.\n\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nsymbols = c('SPY', # 미국 주식\n            'IEV', # 유럽 주식 \n            'EWJ', # 일본 주식\n            'EEM', # 이머징 주식\n            'TLT', # 미국 장기채\n            'IEF', # 미국 중기채\n            'IYR', # 미국 리츠\n            'RWX', # 글로벌 리츠\n            'GLD', # 금\n            'DBC'  # 상품\n            )\n\ngetSymbols(symbols, src = 'yahoo')\n\n [1] \"SPY\" \"IEV\" \"EWJ\" \"EEM\" \"TLT\" \"IEF\" \"IYR\" \"RWX\" \"GLD\" \"DBC\"\n\nprices = do.call(cbind, lapply(symbols, function(x) Ad(get(x)))) %>%\n  setNames(symbols)\n\nrets = Return.calculate(prices) %>% na.omit()\n\n글로벌 자산을 대표하는 ETF 데이터를 다운로드한후 수정주가의 수익률을 계산합니다.\n\nep = endpoints(rets, on = 'months')\nwts = list()\nlookback = 12\nwt_zero = rep(0, 10) %>% setNames(colnames(rets))\n\n백테스트에 사용되는 각종 값을 사전에 정의합니다.\n\nendpoints() 함수를 통해 매월 말일의 위치를 구합니다.\n매월의 투자비중이 들어갈 빈 리스트를 wts에 설정합니다.\n수익률을 측정할 과거 n기간을 12개월로 설정합니다.\nrep() 함수를 통해 비중이 들어갈 0으로 이루어진 벡터를 만들며 이름을 설정합니다.\n\n다음은 매월 말 투자 규칙에 따라 포트폴리오의 비중을 구하는 백테스트 과정입니다.\n\nfor (i in (lookback+1) : length(ep)) {\n  sub_ret = rets[ep[i-lookback] : ep[i] , ]\n  cum = Return.cumulative(sub_ret)\n  \n  K = rank(-cum) <= 5\n  covmat = cov(sub_ret[, K])\n  \n  wt = wt_zero\n  wt[K] = 0.2\n  \n  wts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n}\n\nwts = do.call(rbind, wts)\n\nfor loop 구문을 통해 매월 말 과거 12개월 수익률을 구한 후 비중을 계산하므로, 처음 시작은 i+1인 13부터 가능합니다.\n\nep[i]는 현재시점 수익률의 위치를, ep[i-lookback]는 현재부터 12개월 전 수익률의 위치를 의미합니다. 이를 통해 과거 12개월 간 수익률을 찾은 후 sub_ret에 저장합니다.\nReturn.cumulative() 함수를 통해 해당 기간의 자산별 누적수익률을 구합니다.\nrank() 함수를 통해 수익률 상위 5개 자산을 선택하며, 내림차순으로 정렬해야하므로 마이너스(-)를 붙여줍니다.\ncov() 함수를 통해 수익률 상위 5개 자산의 분산-공분산 행렬을 구하도록 합니다.\n임시로 비중이 저장될 wt 변수에 위에서 만든 0벡터(wt_zero)를 입력한 후 optimalPortfolio() 함수를 통해 최소분산 포트폴리오를 구성하는 해를 찾습니다. 개별 투자비중의 제한은 최소 10%, 최대 30%를 설정하며, 구해진 해를 wt의 K번째 값에 입력합니다.\n위에서 만들어진 벡터를 xts()를 통해 시계열 형태로 바꾼 후 wts의 i번째 리스트에 저장합니다.\nfor loop 구문이 끝난 후 do.call() 함수를 통해 투자비중이 저장된 리스트를 테이블 형태로 바꿔줍니다.\n\n이를 통해 동적 자산배분의 투자 규칙에 맞는 매월 말 투자비중이 계산되었습니다.\n\nGDAA = Return.portfolio(rets, wts, verbose = TRUE)\ncharts.PerformanceSummary(GDAA$returns, main = '동적자산배분')\n\n\n\n\n\n\n\n\n수익률과 비중 데이터가 있으므로 Return.portfolio() 함수를 통해 백테스트 수익률을 계산할 수 있습니다. charts.PerformanceSummary() 함수를 통해 누적수익률을 확인하면 해당 전략을 이용한 포트폴리오가 꾸준히 우상향하는 모습을 보이게됩니다.\n\nwts %>% fortify.zoo() %>%\n  gather(key, value, -Index) %>%\n  mutate(Index = as.Date(Index)) %>%\n  mutate(key = factor(key, levels = unique(key))) %>%\n  ggplot(aes(x = Index, y = value)) +\n  geom_area(aes(color = key, fill = key),\n            position = 'stack') +\n  xlab(NULL) + ylab(NULL) +  theme_bw() +\n  scale_x_date(date_breaks=\"years\", date_labels=\"%Y\",\n               expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(plot.title = element_text(hjust = 0.5,\n                                  size = 12),\n        legend.position = 'bottom',\n        legend.title = element_blank(),\n        axis.text.x = element_text(angle = 45,\n                                   hjust = 1, size = 8),\n        panel.grid.minor.x = element_blank()) +\n  guides(color = guide_legend(byrow = TRUE))\n\n\n\n\n\n\n\n\n반면 자산별 투자비중의 변화가 많은 것을 알 수 있습니다. 그 원인은 수익률 상위 5개에 해당하는 자산이 매월 말 바뀌며, 최소분산 포트폴리오를 구성하는 비중이 계속해서 바뀌기 때문입니다.\n회전율이 상대적으로 낮았던 기존 백테스트에서는 매매비용, 세금, 기타비용 등을 고려하지 않아도 수익률에 크게 영향이 없지만, 회전율이 상대적으로 높은 전략에서는 이러한 것들을 무시하지 않을 수 없습니다.\n\nGDAA$turnover = xts(\n  rowSums(abs(GDAA$BOP.Weight -\n                timeSeries::lag(GDAA$EOP.Weight)),\n          na.rm = TRUE),\n  order.by = index(GDAA$BOP.Weight))\n\nchart.TimeSeries(GDAA$turnover)\n\n\n\n\n\n\n\n\n기존에 살펴본 방법으로 회전율을 계산한다면 매월 상당한 매매회전이 발생함이 확인됩니다.\n\nfee = 0.0030\nGDAA$net = GDAA$returns - GDAA$turnover*fee\n\n매수 혹은 매도당 발생하는 세금, 수수료, 시장충격 등 총 비용을 0.3%로 가정합니다. 포트폴리오 수익률에서 회전율과 총 비용의 곱을 빼면, 비용 후 포트폴리오의 순수익률이 계산됩니다.\n\ncbind(GDAA$returns, GDAA$net) %>%\n  setNames(c('No Fee', 'After Fee')) %>%\n  charts.PerformanceSummary(main = 'GDAA')\n\n\n\n\n\n\n\n\n기존 비용을 고려하지 않은 포트폴리오(검은색)에 비해, 비용을 차감한 포트폴리오(붉은색)의 수익률이 시간이 지남에 따라 서서히 감소합니다. 이러한 차이는 비용이 크거나 매매회전율이 높을수록 더욱 벌어지게 됩니다."
  },
  {
    "objectID": "crawl.html",
    "href": "crawl.html",
    "title": "크롤링 기초",
    "section": "",
    "text": "API를 이용하면 데이터를 매우 쉽게 수집할 수 있지만, 국내 주식 데이터를 다운로드 하기에는 한계가 있으며, 원하는 데이터가 API의 형태로 제공된다는 보장도 없습니다. 따라서 우리는 필요한 데이터를 얻기 위해 직접 찾아 나서야 합니다.\n크롤링 혹은 스크래핑이란 웹사이트에서 원하는 정보를 수집하는 기술입니다. 대부분의 금융 웹사이트는 간단한 형태로 작성되어 있어, 몇 가지 기술만 익히면 어렵지 않게 데이터를 크롤링할 수 있습니다.\n**크롤링을 할 때 주의해야 할 점이 있습니다. 특정 웹사이트의 페이지를 쉬지 않고 크롤링하는 행위를 무한 크롤링이라고 합니다. 무한 크롤링은 해당 웹사이트의 자원을 독점하게 되어 타인의 사용을 막게 되며 웹사이트에 부하를 주게 됩니다. 일부 웹사이트에서는 동일한 IP로 쉬지 않고 크롤링을 할 경우 접속을 막아버리는 경우도 있습니다. 따라서 하나의 페이지를 크롤링한 후 1\\~2초 가량 정지하고 다시 다음 페이지를 크롤링하는 것이 좋습니다.**"
  },
  {
    "objectID": "crawl.html#인코딩의-이해와-r에서-utf-8-설정하기",
    "href": "crawl.html#인코딩의-이해와-r에서-utf-8-설정하기",
    "title": "크롤링 기초",
    "section": "인코딩의 이해와 R에서 UTF-8 설정하기",
    "text": "인코딩의 이해와 R에서 UTF-8 설정하기\nR에서 스크립트를 한글로 작성해 저장한 후 이를 다시 불러올 때, 혹은 한글로 된 데이터를 크롤링하면 오류가 뜨거나 읽을 수 없는 문자로 나타나는 경우가 종종 있습니다. 이는 한글 인코딩 때문에 발생하는 문제이며, 이러한 현상을 흔히 ’인코딩이 깨졌다’라고 표현합니다. 인코딩이란 사람이 사용하는 언어를 컴퓨터가 사용하는 0과 1로 변환하는 과정을 말하며, 이와 반대의 과정을 디코딩이라고 합니다.\n이렇듯 사람과 컴퓨터 간의 언어를 번역하기 위해 최초로 사용된 방식이 아스키(ASCII: American Standard Code for Information Interchange)입니다. 0부터 127까지 총 128개 바이트에 알파벳과 숫자, 자주 사용되는 특수문자 값을 부여하고, 문자가 입력되면 이에 대응되는 바이트가 저장됩니다. 그러나 아스키의 ’American’이라는 이름에서 알 수 있듯이 이는 영어의 알파벳이 아닌 다른 문자를 표현하는 데 한계가 있으며, 이를 보완하기 위한 여러 방법이 나오게 되었습니다."
  },
  {
    "objectID": "crawl.html#한글-인코딩-방식의-종류",
    "href": "crawl.html#한글-인코딩-방식의-종류",
    "title": "크롤링 기초",
    "section": "한글 인코딩 방식의 종류",
    "text": "한글 인코딩 방식의 종류\n인코딩에 대한 전문적인 내용은 이 책의 범위를 넘어가며, 크롤링을 위해서는 한글을 인코딩하는 데 쓰이는 EUC-KR과 CP949, UTF-8 정도만 이해해도 충분합니다. 만일 ’알’이라는 단어를 인코딩한다면 어떤 방법이 있을까요? 먼저 ’알’이라는 문자 자체에 해당하는 코드를 부여해 나타내는 방법이 있습니다. 아니면 이를 구성하는 모음과 자음을 나누어 ㅇ, ㅏ, ㄹ 각각에 해당하는 코드를 부여하고 이를 조합할 수도 있습니다. 전자와 같이 완성된 문자 자체로 나타내는 방법을 완성형, 후자와 같이 각 자모로 나타내는 방법을 조합형이라고 합니다.\n한글 인코딩 중 완성형으로 가장 대표적인 방법은 EUC-KR입니다. EUC-KR은 현대 한글에서 많이 쓰이는 문자 2,350개에 번호를 붙인 방법입니다. 그러나 2,350개 문자로 모든 한글 자모의 조합을 표현하기 부족해, 이를 보완하고자 마이크로소프트가 도입한 방법이 CP949입니다. CP949는 11,720개 한글 문자에 번호를 붙인 방법으로 기존 EUC-KR보다 나타낼 수 있는 한글의 개수가 훨씬 많아졌습니다. 윈도우의 경우 기본 인코딩이 CP949로 되어 있습니다.\n조합형의 대표적 방법인 UTF-8은 모음과 자음 각각에 코드를 부여한 후 조합해 한글을 나타냅니다. 조합형은 한글뿐만 아니라 다양한 언어에 적용할 수 있다는 장점이 있어 전 세계 웹페이지의 대부분이 UTF-8로 만들어지고 있습니다."
  },
  {
    "objectID": "crawl.html#웹의-동작-방식",
    "href": "crawl.html#웹의-동작-방식",
    "title": "크롤링 기초",
    "section": "웹의 동작 방식",
    "text": "웹의 동작 방식\n크롤링은 웹사이트의 정보를 수집하는 과정입니다. 따라서 웹이 어떻게 동작하는지 이해할 필요가 있습니다.\n\n\n\n\n\n먼저 클라이언트란 여러분의 데스크톱이나 휴대폰과 같은 장치와 크롬이나 파이어폭스와 같은 소프트웨어를 의미합니다. 서버는 웹사이트와 앱을 저장하는 컴퓨터를 의미합니다. 클라이언트가 특정 정보를 요구하는 과정을 ’요청’이라고 하며, 서버가 해당 정보를 제공하는 과정을 ’응답’이라고 합니다. 그러나 클라이언트와 서버가 연결되어 있지 않다면 둘 사이에 정보를 주고받을 수 없으며, 이를 연결하는 공간이 바로 인터넷입니다. 또한 건물에도 고유의 주소가 있는 것처럼, 각 서버에도 고유의 주소가 있는데 이것이 인터넷 주소 혹은 URL입니다.\n여러분이 네이버에서 경제 기사를 클릭하는 경우를 생각해봅시다. 클라이언트는 사용자인 여러분이고, 서버는 네이버이며, URL은 www.naver.com 이 됩니다. 경제 기사를 클릭하는 과정이 요청이며, 클릭 후 해당 페이지를 보여주는 과정이 응답입니다.\n\nHTTP\n클라이언트가 각기 다른 방법으로 데이터를 요청한다면, 서버는 해당 요청을 알아듣지 못할 것입니다. 이를 방지하기 위해 규정된 약속이나 표준에 맞추어 데이터를 요청해야 합니다. 이러한 약속을 HTTP(HyperText Transfer Protocol)라고 합니다.\n클라이언트가 서버에게 요청의 목적이나 종류를 알리는 방법을 HTTP 요청 방식(HTTP Request Method)이라고 합니다. HTTP 요청 방식은 크게 GET, POST, PUT, DELETE라는 네 가지로 나눌 수 있지만 크롤링에는 GET과 POST 방식이 대부분 사용되므로 이 두 가지만 알아도 충분합니다.\n인터넷을 사용하다 보면 한 번쯤 ‘이 페이지를 볼 수 있는 권한이 없음(HTTP 오류 403 - 사용할 수 없음)’ 혹은 ’페이지를 찾을 수 없음(HTTP 오류 404 - 파일을 찾을 수 없음)’이라는 오류를 본 적이 있을 겁니다. 여기서 403과 404라는 숫자는 클라이언트의 요청에 대한 서버의 응답 상태를 나타내는 HTTP 상태 코드입니다.\nHTTP 상태 코드는 100번대부터 500번대까지 있으며, 성공적으로 응답을 받을 시 200번 코드를 받게 됩니다. 각 코드에 대한 내용은 HTTP 상태 코드를 검색하면 확인할 수 있으며, 크롤링 과정에서 오류가 발생할 시 해당 코드를 통해 어떤 부분에서 오류가 발생했는지 확인이 가능합니다.\n\n\n\n\n\n\n\n\n코드\n내용\n설명\n\n\n\n\n1xx\nInformational (조건부 응답)\n리퀘스트를 받고, 처리 중에 있음\n\n\n2xx\nSuccess (성공)\n리퀘스트를 정상적으로 처리함\n\n\n3xx\nRedirection (리디렉션)\n리퀘스트 완료를 위해 추가 동작이 필요함\n\n\n4xx\nClient Error (클라이언트 오류)\n클라이언트 요청을 처리할 수 없어 오류 발생\n\n\n5xx\nServer Error (서버 오류)\n서버에서 처리를 하지 못하여 오류 발생"
  },
  {
    "objectID": "crawl.html#html과-css",
    "href": "crawl.html#html과-css",
    "title": "크롤링 기초",
    "section": "HTML과 CSS",
    "text": "HTML과 CSS\n클라이언트와 서버가 데이터를 주고받을 때는 디자인이라는 개념이 필요하지 않습니다. 그러나 응답받은 정보를 사람이 확인하려면 보기 편한 방식으로 바꾸어줄 필요가 있는데 웹페이지가 그러한 역할을 합니다. 웹페이지의 제목, 단락, 목록 등 레이아웃을 잡아주는 데 쓰이는 대표적인 마크업 언어가 HTML(HyperText Markup Language)입니다. HTML을 통해 잡혀진 뼈대에 글자의 색상이나 폰트, 배경색, 배치 등 화면을 꾸며주는 역할을 하는 것이 CSS(Cascading Style Sheets)입니다.\n우리의 목적은 웹페이지를 만드는 것이 아니므로 HTML과 CSS에 대해 자세히 알 필요는 없습니다. 그러나 크롤링하고자 하는 데이터가 웹페이지의 어떤 태그 내에 위치하고 있는지, 어떻게 크롤링하면 될지 파악하기 위해서는 HTML과 CSS에 대한 기본적인 지식은 알아야 합니다.\nHTML과 CSS의 실습은 아래 페이지에서 해볼 수 있습니다.\nhttps://www.w3schools.com/html/tryit.asp?filename=tryhtml_intro\n\nHTML 기본 구조\nHTML은 크게 메타 데이터를 나타내는 head와 본문을 나타내는 body로 나누어집니다. head에서 title은 웹페이지에서 나타나는 제목을 나타내며 body 내에는 본문에 들어갈 각종 내용들이 포함되어 있습니다.\n\n<html>\n<head>\n<title>Page Title</title>\n</head>\n\n<body>\n<h2> This is page heading </h2>\n<p> THis is first paragraph text </p>\n</body>\n</html>\n\n\n\n\n\n\n<head> 부분에 입력한 내역은 실습 페이지 구조 상 확인되지 않지만, <body> 부분에 입력한 글자들은 우측 결과물 페이지에서 확인이 가능합니다. <h2>와 <p> 등의 태그가 하는 역할들에 대해서 더욱 자세히 알아보도록 하겠습니다.\n\n\n태그와 속성\nHTML 코드는 태그와 속성, 내용으로 이루어져 있습니다. 크롤링한 데이터에서 특정 태그의 데이터만을 찾는 방법, 특정 속성의 데이터만을 찾는 방법, 뽑은 자료에서 내용만을 찾는 방법 등 내용을 찾는 방법이 모두 다르기 때문에 태그와 속성에 대해 좀 더 자세히 살펴보겠습니다.\n\n\n\n\n\n꺾쇠(<>)로 감싸져 있는 부분을 태그라고 하며, 여는 태그 <>가 있으면 반드시 이를 닫는 태그인 </>가 쌍으로 있어야 합니다. 속성은 해당 태그에 대한 추가적인 정보를 제공해주는 것으로, 뒤에 속성값이 따라와야 합니다. 내용은 우리가 눈으로 보는 텍스트 부분을 의미합니다. 앞의 HTML 코드는 문단을 나타내는\n\n, 정렬을 나타내는 align 속성과 center를 통해 가운데 정렬을 지정하며, 내용에는 ’퀀트 투자 Cookbook’을 나타내고,\n\n태그를 통해 태그를 마쳤습니다.\n\n\nh 태그와 p 태그\nh 태그는 폰트의 크기를 나타내는 태그이며, p 태그는 문단을 나타내는 태그입니다. 이를 사용한 간단한 예제는 다음과 같습니다. h 태그의 숫자가 작을수록 텍스트 크기는 커지는 것이 확인되며, 숫자는 1에서 6까지 지원됩니다. p 태그를 사용하면 각각의 문단이 만들어지는 것이 확인됩니다.\n\n<html>\n<body>\n\n<h1>Page heading: size 1</h1>\n<h2>Page heading: size 2</h2>\n<h3>Page heading: size 3</h3>\n\n<p>Quant Cookbook</p>\n<p>By Henry</p>\n\n</body>\n</html>\n\n\n\n\n\n\nh 태그의 숫자가 작을수록 텍스트 크기는 커지며, 숫자는 1에서 6까지 지원됩니다. 또한 p 태그를 사용하면 각각의 문단이 만들어집니다.\n\n\n리스트를 나타내는 ul 태그와 ol 태그\nul과 ol 태그는 리스트(글머리 기호)를 만들 때 사용됩니다. ul은 순서가 없는 리스트(unordered list), ol은 순서가 있는 리스트(ordered list)를 만듭니다.\n\n<html>\n<body>\n\n<h2> Unordered List</h2>\n<ul>\n  <li>List 1</li>\n  <li>List 2</li>\n  <li>List 3</li>\n</ul>  \n\n<h2> Ordered List</h2>\n<ol>\n  <li>List A</li>\n  <li>List B</li>\n  <li>List C</li>\n  <li>List D</li>\n </ol> \n\n</body>\n</html>\n\n\n\n\n\n\nul 태그로 감싼 부분은 글머리 기호가 순서가 없는 •으로 표현되며, ol 태그로 감싼 부분은 숫자가 순서대로 표현됩니다. 각각의 리스트는 li를 통해 생성됩니다.\n\n\ntable 태그\ntable 태그는 표를 만드는 태그입니다.\n\n<html>\n<body>\n\n<h2>Sample Table</h2>\n\n<table>\n  <tr>\n    <th>Column 1</th>\n    <th>Column 2</th>\n    <th>Column 3</th>    \n  </tr>\n  <tr>\n    <td>1</td>\n    <td>2</td>\n    <td>3</td>\n  </tr>\n  <tr>\n    <td>A</td>\n    <td>B</td>\n    <td>C</td>\n  </tr>\n  <tr>\n    <td>a</td>\n    <td>b</td>\n    <td>c</td>\n  </tr>\n</table>\n\n</body>\n</html>\n\n\n\n\n\n\ntable 태그 내의 tr 태그는 각 행을 의미하며, 각 셀의 구분은 th 혹은 td 태그를 통해 구분할 수 있습니다. th 태그는 진하게 표현되므로 주로 테이블의 제목에 사용되고, td 태그는 테이블의 내용에 사용됩니다.\n\n\na 태그와 img 태그 및 속성\na 태그와 img 태그는 다른 태그와는 다르게, 혼자 쓰이기보다는 속성과 결합해 사용됩니다. a 태그는 href 속성과 결합해 다른 페이지의 링크를 걸 수 있습니다. img 태그는 src 속성과 결합해 이미지를 불러옵니다.\n\n<html>\n<body>\n\n<h2>a tag & href attribute</h2>\n<p>HTML links are defined with the a tag.\nThe link address is specified in the href attribute:</p>\n\n<a href=\"https://blog.naver.com/leebisu\">Henry's Quantopia</a>\n\n<h2>img tag & src attribute</h2>\n<p>HTML images are defined with the img tag,\nand the filename of the image source is\nspecified in the src attribute:</p>\n\n<img src=\"https://www.python.org/static/img/python-logo.png\",\nwidth=\"200\",height=\"100\">\n\n</body>\n</html>\n\n\n\n\n\n\na 태그 뒤 href 속성에 연결하려는 웹페이지 주소를 속성값(https://blog.naver.com/leebisu)으로으로){.uri} 입력한 후 내용(Henry’s Quantopia)을 입력하면, 내용 텍스트에 웹페이지의 링크가 추가됩니다. img 태그 뒤 src 속성의 속성값에는 불러오려는 이미지 주소를 입력하며, width 속성과 height 속성을 통해 이미지의 가로 세로 길이를 조절할 수도 있습니다. 페이지 내에서 링크된 주소를 모두 찾거나, 모든 이미지를 저장하려고 할 때 속성값을 찾으면 손쉽게 원하는 작업을 할 수 있습니다.\n\n\ndiv 태그\ndiv 태그는 화면의 전체적인 틀(레이아웃)을 만들 때 주로 사용하는 태그입니다. 단독으로도 사용될 수 있으며, 꾸밈을 담당하는 style 속성과 결합되어 사용되기도 합니다.\n\n<html>\n<body>\n\n<div style=\"background-color:black;color:white\">\n  <h5>First Div</h5>\n  <p>Black backgrond, White Color</p>\n</div> \n\n<div style=\"background-color:yellow;color:red\">\n  <h5>Second Div</h5>\n  <p>Yellow backgrond, Red Color</p>\n</div> \n\n<div style=\"background-color:blue;color:grey\">\n  <h5>Second Div</h5>\n  <p>Blue backgrond, Grey Color</p>\n</div> \n\n</body>\n</html>\n\n\n\n\n\n\ndiv 태그를 통해 총 세 개의 레이아웃으로 나누어진 것을 알 수 있습니다. style 속성 중 background-color는 배경 색상을, color는 글자 색상을 의미하며, 각 레이아웃마다 다른 스타일이 적용되었습니다.\n\n\nCSS\nCSS는 앞서 설명했듯이 웹페이지를 꾸며주는 역할을 합니다. head에서 각 태그에 CSS 효과를 입력하면 본문의 모든 해당 태그에 CSS 효과가 적용됩니다. 이처럼 웹페이지를 꾸미기 위해 특정 요소에 접근하는 것을 셀렉터(Selector)라고 합니다.\n\n<html>\n<head>\n<style>\nbody {background-color: powderblue;}\nh4   {color: blue;}\n</style>\n</head>\n<body>\n\n<h4>This is a heading</h4>\n<p>This is a first paragraph.</p>\n<p>This is a second paragraph.</p>\n\n</body>\n</html>\n\n\n\n\n\n\nhead의 style 태그에서 여러 CSS 효과가 정의되었습니다. 먼저 body의 전체 배경 색상을 powderblue로 설정했으며, h4 태그의 글자 색상은 파란색(blue)으로 설정했습니다. body 태그 내에서 style에 태그를 주지 않더라도, head에서 정의한 CSS 효과가 모두 적용됩니다.\n\n\n클래스와 id\n위의 예제에서 클래스 속성을 이용하면 특정 이름을 가진 클래스에 동일한 효과를 적용할 수 있습니다.\n\n<html>\n<style>\n.language {\n  background-color: tomato;\n  color: white;\n  padding: 10px;\n} \n.desc {\n  background-color: moccasin;\n  color: black;\n  padding: 10px;\n} \n</style>\n\n<div>\n<h2 class=\"language\">Python</h2>\n<p class=\"desc\"> Python is a high-level, general-purpose programming language.</p>\n</div>\n\n<div>\n<h2>SQL</h2>\n<p>SQL is a domain-specific language used in programming and designed for managing data held in a RDBMS, or for stream processing in a RDBMS. </p>\n</div>\n\n<div>\n<h2 class=\"language\">R</h2>\n<p class=\"desc\">R is a free software environment for statistical computing and graphics.</p>\n<div>\n</html>\n\n\n\n\n\n\n셀렉터를 클래스에 적용할 때는 클래스명 앞에 마침표(.)를 붙여 표현합니다다. 위 예제에서 language 클래스는 배경 색상이 tomato, 글자 색상은 흰색, 여백은 10px로 정의됩니다. desc 클래스는 배경 색상이 moccasin, 글자 색상은 검은색, 여백은 10px로 정의되었습니다. 본문의 첫 번째(Python)와 세 번째(R) 레이아웃의 h2 태그 뒤에는 language 클래스를, p 태그 뒤에는 desc 클래스를 속성으로 입력했습니다. 따라서 해당 레이아웃에만 CSS 효과가 적용되며, 클래스 값이 없는 두 번째 레이아웃에는 효과가 적용되지 않습니다.\nid 또한 이와 비슷한 역할을 합니다. HTML 내에서 클래스는 여러 개가 정의될 수 있는 반면, id는 단 하나만 사용하기를 권장합니다.\n\n<html>\n<head>\n<style>\n\n#myHeader {\n  background-color: lightblue;\n  color: black;\n  padding: 15px;\n  text-align: center;\n}\n\n</style>\n</head>\n<body>\n\n<h1 id=\"myHeader\">My Header</h1>\n\n</body>\n</html>\n\n\n\n\n\n\n셀렉터를 id에 적용할 때는 id명 앞에 샵(#)를 붙여 표현하며, 페이지에서 한 번만 사용된다는 점을 제외하면 클래스와 사용 방법이 거의 동일합니다. 클래스나 id 값을 통해 원하는 내용을 크롤링하는 경우도 많으므로, 각각의 이름 앞에 마침표(.)와 샵(#) 을 붙여야 한다는 점을 꼭 기억해야 합니다."
  },
  {
    "objectID": "crawl.html#get과-post-방식-이해하기",
    "href": "crawl.html#get과-post-방식-이해하기",
    "title": "크롤링 기초",
    "section": "GET과 POST 방식 이해하기",
    "text": "GET과 POST 방식 이해하기\n우리가 인터넷에 접속해 서버에 파일을 요청하면, 서버는 이에 해당하는 파일을 우리에게 보내줍니다. 크롬과 같은 웹 브라우저는 이러한 과정을 사람이 수행하기 편하고 시각적으로 보기 편하도록 만들어진 것이며, 인터넷 주소는 서버의 주소를 기억하기 쉽게 만든 것입니다. 우리가 서버에 데이터를 요청하는 형태는 다양하지만 크롤링에서는 주로 GET과 POST 방식을 사용합니다.\n\n\n\n\n\n\nGET 방식\nGET 방식은 인터넷 주소를 기준으로 이에 해당하는 데이터나 파일을 요청하는 것입니다. 주로 클라이언트가 요청하는 쿼리를 앰퍼샌드(&) 혹은 물음표(?) 형식으로 결합해 서버에 전달합니다.\n네이버 홈페이지에 접속한 후 [퀀트]를 검색하면, 주소 끝부분에 [&query=퀀트]가 추가되며 이에 해당하는 페이지의 내용을 보여줍니다. 즉, 해당 페이지는 GET 방식을 사용하고 있으며 입력 종류는 query, 입력값은 [퀀트]임을 알 수 있습니다.\n\n\n\n\n\n[헤지펀드]를 다시 검색하면, 주소 끝부분이 [&query=헤지펀드&oquery=퀀트…]로 변경됩니다. 현재 입력값은 헤지펀드, 기존 입력값은 퀀트이며 이러한 과정을 통해 연관검색어가 생성됨도 유추해볼 수 있습니다.\n\n\n\n\n\n\n\nPOST 방식\nPOST 방식은 사용자가 필요한 값을 추가해서 요청하는 방법입니다. GET 방식과 달리 클라이언트가 요청하는 쿼리를 body에 넣어서 전송하므로 요청 내역을 직접 볼 수 없습니다. 동행복권 홈페이지에 접속해 [당첨결과] 메뉴를 확인해봅시다.\n\nhttps://www.dhlottery.co.kr/gameResult.do?method=byWin\n\n\n\n\n\n\n이번엔 회차 바로가기를 변경한 후 [조회]를 클릭합니다. 페이지의 내용은 선택일 기준으로 변경되었지만, 주소는 변경되지 않고 그대로 남아 있습니다. GET 방식에서는 입력 항목에 따라 웹페이지 주소가 변경되었지만, POST 방식을 사용해 서버에 데이터를 요청하는 해당 웹사이트는 그렇지 않은 것을 알 수 있습니다.\nPOST 방식의 데이터 요청 과정을 살펴보려면 개발자도구를 이용해야 하며, 크롬에서는 [F12]키를 눌러 개발자도구 화면을 열 수 있습니다. 개발자도구 화면을 연 상태에서 다시 한번 [조회]를 클릭해봅시다. [Network] 탭을 클릭하면, [조회]을 클릭함과 동시에 브라우저와 서버 간의 통신 과정을 살펴볼 수 있습니다. 이 중 상단의 gameResult.do?method=byWin 이라는 항목이 POST 형태임을 알 수 있습니다.\n\n\n\n\n\n해당 메뉴를 클릭하면 통신 과정을 좀 더 자세히 알 수 있습니다. [Payload] 탭의 [Form Data]에는 서버에 데이터를 요청하는 내역이 있습니다. drwNo와 dwrNoList에는 선택한 회차의 숫자가 들어가 있습니다.\n\n\n\n\n\n이처럼 POST 방식은 요청하는 데이터에 대한 쿼리가 GET 방식처럼 URL을 통해 전송되는 것이 아닌 body를 통해 전송되므로, 이에 대한 정보는 웹 브라우저를 통해 확인할 수 없으며, 개발자도구 화면을 통해 확인해야 합니다."
  },
  {
    "objectID": "crawl.html#명언-크롤링하기",
    "href": "crawl.html#명언-크롤링하기",
    "title": "크롤링 기초",
    "section": "명언 크롤링하기",
    "text": "명언 크롤링하기\n크롤링의 간단한 예제로 ‘Quotes to Scrape’ 사이트에 있는 명언을 수집힙니다.\n\nhttps://quotes.toscrape.com/\n\n먼저 해당사이트에 접속한 후, 명언에 해당하는 부분에 마우스 커서를 올려둔 후 마우스 오른쪽 버튼을 클릭하고 [검사]를 선택하면 개발자 도구 화면이 나타납니다. 여기서 해당 글자가 HTML 내에서 어떤 부분에 위치하는지 확인할 수 있습니다. 각 네모에 해당하는 부분은 [div 태그의 quote 클래스]에 위치하고 있으며, 명언은 [div 태그 → span 태그의 text 클래스]에, 명언가는 [div 태그 → span 태그 → small 태그의 author 클래스]에 위치하고 있습니다.\n\n\n\n\n\n먼저 해당 페이지의 내용을 불러옵니다.\n\nlibrary(httr)\nlibrary(rvest)\n\nurl = 'https://quotes.toscrape.com/'\nquote = GET(url)\n\nprint(quote)\n\nResponse [https://quotes.toscrape.com/]\n  Date: 2023-01-19 02:45\n  Status: 200\n  Content-Type: text/html; charset=utf-8\n  Size: 11.1 kB\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Quotes to Scrape</title>\n    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n    <link rel=\"stylesheet\" href=\"/static/main.css\">\n</head>\n<body>\n    <div class=\"container\">\n...\n\n\nurl에 해당 주소를 입력한 후 GET() 함수를 이용해 해당 페이지의 내용을 받아온다. Response 부분을 확인해보면 Status가 200, 즉 데이터가 이상 없이 받아졌음이 확인됩니다.\n이제 rvest 패키지를 이용해 html 정보를 불러오도록 합니다.\n\nquote_html = read_html(quote)\n\nprint(quote_html)\n\n{html_document}\n<html lang=\"en\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body>\\n    <div class=\"container\">\\n        <div class=\"row header-box\"> ...\n\n\nread_html() 함수는 받아온 페이지 내용을 html 정보로 변환합니다. 이를 확인해보면 head 부분과 body 부분이 존재합니다.\n우리는 개발자 도구 화면에서 명언에 해당하는 부분이 [div 태그의 quote 클래스 → span 태그의 text 클래스]에 위치하고 있음을 살펴보았습니다. 이를 활용해 명언만을 추출하는 방법은 다음과 같습니다.\n\nquote_div = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span.text')\n\nprint(quote_div)\n\n{xml_nodeset (10)}\n [1] <span class=\"text\" itemprop=\"text\">“The world as we have created it is a ...\n [2] <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show  ...\n [3] <span class=\"text\" itemprop=\"text\">“There are only two ways to live your ...\n [4] <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, ...\n [5] <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is g ...\n [6] <span class=\"text\" itemprop=\"text\">“Try not to become a man of success.  ...\n [7] <span class=\"text\" itemprop=\"text\">“It is better to be hated for what yo ...\n [8] <span class=\"text\" itemprop=\"text\">“I have not failed. I've just found 1 ...\n [9] <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never ...\n[10] <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you  ...\n\n\n\nhtml_nodes() 함수는 태그, id, 클래스, xpath 등의 정보를 이용해 해당하는 데이터를 추출합니다. div 태그에서 클래스에 해당하는 quote 클래스에 해당하는 데이터를 찾으며, 클래스의 경우 앞에 콤마(.)를 붙입니다(id의 경우 앞에 샵(#)을 붙입니다). html_node() 함수는 해당하는 정보 중 가장 첫번째 데이터만을 추출하며, html_nodes() 함수는 모든 데이터를 추출하는 차이가 있습니다.\nspan 태그 중 text 클래스를 찾습니다.\n\n결과를 확인하면 개발자 도구 화면과 거의 일치합니다. 이제 텍스트에 해당하는 부분만 추출합니다.\n\nquote_text = quote_div %>%\n  html_text()\n\nprint(quote_text)\n\n [1] \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"                \n [2] \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"                                              \n [3] \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n [4] \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"                           \n [5] \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"                    \n [6] \"“Try not to become a man of success. Rather become a man of value.”\"                                                                \n [7] \"“It is better to be hated for what you are than to be loved for what you are not.”\"                                                 \n [8] \"“I have not failed. I've just found 10,000 ways that won't work.”\"                                                                  \n [9] \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"                                              \n[10] \"“A day without sunshine is like, you know, night.”\"                                                                                 \n\n\nhtml_text() 함수를 이용하면 html 에서 텍스트 정보만을 추출할 수 있습니다.\n이번에는 명언을 말한 사람에 해당하는 정보만 수집합니다.\n\nquote_who = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span') %>%\n  html_nodes('small.author') %>%\n  html_text()\n\nprint(quote_who)\n\n [1] \"Albert Einstein\"   \"J.K. Rowling\"      \"Albert Einstein\"  \n [4] \"Jane Austen\"       \"Marilyn Monroe\"    \"Albert Einstein\"  \n [7] \"André Gide\"        \"Thomas A. Edison\"  \"Eleanor Roosevelt\"\n[10] \"Steve Martin\"     \n\n\n파이프 오퍼레이터(%>%)를 통해 html에서 원하는 부분만 추출하는 작업을 단계별로 진행할 수 있습니다.\n마지막으로 명언가 정보에 해당하는 링크(about)를 불러오도록 합니다. 이는 [quote 클래스 → span 태그 → a 태그 내에서 href 속성]에 위치하고 있습니다.\n\nquote_link = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span') %>%\n  html_nodes('a') %>%\n  html_attr('href')\n\nprint(quote_link)\n\n [1] \"/author/Albert-Einstein\"   \"/author/J-K-Rowling\"      \n [3] \"/author/Albert-Einstein\"   \"/author/Jane-Austen\"      \n [5] \"/author/Marilyn-Monroe\"    \"/author/Albert-Einstein\"  \n [7] \"/author/Andre-Gide\"        \"/author/Thomas-A-Edison\"  \n [9] \"/author/Eleanor-Roosevelt\" \"/author/Steve-Martin\"     \n\n\nhtml_attr() 함수는 속성값을 찾아주는 함수이며, href 속성에 해당하는 값을 찾아줍니다.\n기본 url(https://quotes.toscrape.com)에에){.uri} 해당하는 정보가 없으므로 이를 추가적으로 붙여줍니다.\n\nquote_link = paste0('https://quotes.toscrape.com', quote_link)\n\nquote_link\n\n [1] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [2] \"https://quotes.toscrape.com/author/J-K-Rowling\"      \n [3] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [4] \"https://quotes.toscrape.com/author/Jane-Austen\"      \n [5] \"https://quotes.toscrape.com/author/Marilyn-Monroe\"   \n [6] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [7] \"https://quotes.toscrape.com/author/Andre-Gide\"       \n [8] \"https://quotes.toscrape.com/author/Thomas-A-Edison\"  \n [9] \"https://quotes.toscrape.com/author/Eleanor-Roosevelt\"\n[10] \"https://quotes.toscrape.com/author/Steve-Martin\"     \n\n\n세 개의 데이터를 하나의 데이터프레임으로 묶어 정리합니다.\n\nquote_df = data.frame(\n  'quote' = quote_text,\n  'author' = quote_who,\n  'link' = quote_link\n)\n\nquote_df\n\n                                                                                                                                   quote\n1                  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n2                                                “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n3  “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n4                             “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n5                      “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n6                                                                  “Try not to become a man of success. Rather become a man of value.”\n7                                                   “It is better to be hated for what you are than to be loved for what you are not.”\n8                                                                    “I have not failed. I've just found 10,000 ways that won't work.”\n9                                                “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n10                                                                                  “A day without sunshine is like, you know, night.”\n              author                                                 link\n1    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n2       J.K. Rowling       https://quotes.toscrape.com/author/J-K-Rowling\n3    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n4        Jane Austen       https://quotes.toscrape.com/author/Jane-Austen\n5     Marilyn Monroe    https://quotes.toscrape.com/author/Marilyn-Monroe\n6    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n7         André Gide        https://quotes.toscrape.com/author/Andre-Gide\n8   Thomas A. Edison   https://quotes.toscrape.com/author/Thomas-A-Edison\n9  Eleanor Roosevelt https://quotes.toscrape.com/author/Eleanor-Roosevelt\n10      Steve Martin      https://quotes.toscrape.com/author/Steve-Martin"
  },
  {
    "objectID": "crawl.html#xpath를-이용해-원하는-지점만-찾기",
    "href": "crawl.html#xpath를-이용해-원하는-지점만-찾기",
    "title": "크롤링 기초",
    "section": "xpath를 이용해 원하는 지점만 찾기",
    "text": "xpath를 이용해 원하는 지점만 찾기\nxpath란 HTML의 위치를 나타내는 형태입니다. 만일 웹페이지에서 한 지점의 데이터만 추출해야 할 경우, 번거롭게 html의 구조를 모두 발라내기 보다는 xpath를 이용하는 것이 훨씬 효율적입니다.\n예제로 yes24의 판매지수를 크롤링 하도록 하겠습니다. 해당 지수는 책의 출간일 그리고 판매량에 따라 매일 바뀝니다.\nhttp://www.yes24.com/Product/Goods/108408162\n이 중 개발자도구 화면에서 판매지수에 해당하는 부분을 찾은 후, 우클릭 해 [Copy → Copy xpath]를 선택하면 해당 내역이 복사됩니다. 이는 다음과 같습니다.\n//*[@id=\"yDetailTopWrap\"]/div[2]/div[1]/span[3]/span[3]\n이를 이용해 크롤링 하는 법은 다음과 같습니다.\n\nlibrary(rvest)\nlibrary(httr)\n\nurl = 'http://www.yes24.com/Product/Goods/108408162'\n\ndata = GET(url)\n\ndata_sales = data %>%\n  read_html() %>%\n  html_nodes(xpath = '//*[@id=\"yDetailTopWrap\"]/div[2]/div[1]/span[3]/span[3]')\n\nprint(data_sales)\n\n{xml_nodeset (1)}\n[1] <span class=\"gd_sellNum\">\\r\\n                <em class=\"divi\">|</em>\\r\\n  ...\n\n\nxpath를 통해 해당 부분만 손쉽게 추출할 수 있습니다. 이제 판매지수에 해당하는 숫자만 선택하도록 하면 됩니다.\n\nlibrary(stringr)\n\ndata_sales %>%\n  html_text() %>%\n  str_extract_all('(\\\\d)+') %>%\n  .[[1]] %>%\n  str_c(., collapse = '') %>%\n  as.numeric()\n\n[1] 4155\n\n\n먼저 정규표현식을 이용해 숫자부분만 추출할 수 있습니다.\n\nhtml_text() 함수를 통해 텍스트 데이터만 불러옵니다.\nstr_extract_all() 함수 내에 정규표현식을 이용해 숫자에 해당하는 데이터만 추출합니다.\n첫번째 원소를 선택한다.\nstr_c() 함수를 통해 모든 텍스트를 붙입니다.\nas.numeric() 함수를 이용해 숫자 형태로 변경합니다.\n\n그러나 정규표현식은 꽤나 복잡합니다. 다행히 패키지 내 함수를 사용하면 위 과정을 매우 간단하게 수행할 수 있습니다.\n\ndata_sales %>%\n  html_text() %>%\n  readr::parse_number()\n\n[1] 4155\n\n\nreadr 패키지의 parse_number() 함수는 여러 텍스트 중 숫자 형태만 추출해주는 매우 유용한 함수입니다."
  },
  {
    "objectID": "crawl.html#표-크롤링",
    "href": "crawl.html#표-크롤링",
    "title": "크롤링 기초",
    "section": "표 크롤링",
    "text": "표 크롤링\n표는 html 중 td와 th 태그로 구성되어 있으며, 이를 일일이 추출하며 다시 표 형태로 만드는 것은 사실상 불가능에 가깝습니다. 다행히 R의 크롤링 패키지에는 표 형태만 간단하게 추출할 수 있는 함수 역시 존재합니다.\n예제로써 UFC의 역대 챔피언 리스트를 크롤링 해보도록 합시다.\nhttps://en.wikipedia.org/wiki/List_of_UFC_champions\n위 페이지에는 각 체급별 챔피언의 역사가 표 형태로 정리되어 있습니다. 이 중 표만 가져오는 법은 다음과 같습니다.\n\nlibrary(rvest)\nlibrary(httr)\n\nurl = 'https://en.wikipedia.org/wiki/List_of_UFC_champions'\ndata_ufc = GET(url)\n\n\ndata_ufc %>%\n  read_html() %>%\n  html_table()\n\nhtml_table() 함수는 테이블 형태의 데이터만 추출하는 함수입니다. 그러나 윈도우의 경우 다음과 같은 오류가 뜹니다.\n\nError in type.convert.default(x, as.is = TRUE, dec = dec, na.strings = na.strings) : \n  invalid multibyte string at '<e2><94>'\n\n이는 웹페이지와 컴퓨터의 인코딩이 달라 발생하는 오류이며, 잠시 로케일 언어를 영어로 변경하여 크롤링 하면 오류가 발생하지 않습니다.\n\nSys.setlocale(\"LC_ALL\", \"English\")\n\nWarning in Sys.setlocale(\"LC_ALL\", \"English\"): using locale code page other than\n65001 (\"UTF-8\") may cause problems\n\n\n[1] \"LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252\"\n\nchampion_list = data_ufc %>%\n  read_html() %>%\n  html_table()\n\nSys.setlocale(\"LC_ALL\", \"Korean\")\n\nWarning in Sys.setlocale(\"LC_ALL\", \"Korean\"): using locale code page other than\n65001 (\"UTF-8\") may cause problems\n\n\n[1] \"LC_COLLATE=Korean_Korea.949;LC_CTYPE=Korean_Korea.949;LC_MONETARY=Korean_Korea.949;LC_NUMERIC=C;LC_TIME=Korean_Korea.949\"\n\n\nchampion_list는 44개 원소로 이루어진 리스트이며, 각 원소에는 웹페이지의 테이블 정보가 들어가 있습니다. 이 중 원하는 표만 선택하면 됩니다.\n\nchampion_list[[1]]\n\n# A tibble: 9 x 4\n  Division          Champion                 Since        Defenses\n  <chr>             <chr>                    <chr>        <chr>   \n1 Heavyweight       Vacant                   Jan 14, 2023 <U+2014>       \n2 Light Heavyweight Vacant                   Nov 23, 2022 <U+2014>       \n3 Middleweight      Alex Pereira             Nov 12, 2022 0       \n4 Welterweight      Leon Edwards             Aug 20, 2022 0       \n5 Lightweight       Islam Makhachev          Oct 22, 2022 0       \n6 Featherweight     Alexander Volkanovski    Dec 14, 2019 4       \n7 Bantamweight      Aljamain Sterling        Mar 6, 2021  2       \n8 Flyweight         Deiveson Figueiredo      Jan 22, 2022 0       \n9 Flyweight         Brandon Moreno (interim) Jul 30, 2022 0"
  },
  {
    "objectID": "crawl.html#post-방식-크롤링",
    "href": "crawl.html#post-방식-크롤링",
    "title": "크롤링 기초",
    "section": "POST 방식 크롤링",
    "text": "POST 방식 크롤링\nGET 방식은 요청 쿼리가 url에 포함되어 있으므로 매우 손쉽게 페이지 내역을 받을 수 있었습니다. 그러나 POST 방식은 요청 쿼리가 숨겨져 있으므로 이를 직접 입력해야 합니다. 앞서 살펴본 로또 당첨번호를 크롤링 해보도록 하겠습니다.\nhttps://www.dhlottery.co.kr/gameResult.do?method=byWin\n개발자도구 화면을 연 상태에서 조회를 누른 후 [gameResult.do?…] 부분을 클릭합니다. [Headers] 탭의 General 에서 Request URL은 데이터를 요청하는 서버 주소를 의미합니다.\n\n\n\n\n\nPayload 탭의 [Form Data] 에는 요청하는 쿼리가 나타나 있습니다.\n\n\n\n\n\n또한 당첨번호에 해당하는 부분의 html 위치를 확인해보면, num win 클래스에 위치하고 있음을 알 수 있습니다.\n\n\n\n\n\n위의 정보를 이용해 POST 형태로 데이터를 받아보도록 하겠습니다.\n\nlibrary(httr)\nlibrary(rvest)\n\nurl = 'https://www.dhlottery.co.kr/gameResult.do?method=byWin'\n\ndata_lotto = POST(\n  url, \n  body = list(\n    drwNo = \"1009\",\n    dwrNoList = \"1009\"\n  )\n)\n\ndata_lotto_html = data_lotto %>% read_html() \n\n\nurl에는 서버 주소를 입력하며, 쿼리값은 body 내에 리스트 형태로 입력한다. 요청한 쿼리, 즉 1009회 당첨결과에 해당하는 데이터가 받아집니다. 만일 다른 회차의 값이 궁금하면 1009 숫자를 다른 숫자로 입력하면 됩니다.\nread_html() 함수를 통해 html 내용을 추출합니다.\n\n이제 당첨번호에 해당하는 데이터만을 뽑아내도록 합니다.\n\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text()\n\n결과를 확인해보면 당첨번호와 함께 , 같은 문자들이 보입니다. 이는 띄어쓰기, 줄바꿈 등에 해당하는 태그입니다. 우리에게 남은 일은 숫자에 해당하는 부분만 뽑아내는 것이며, 클렌징 방법은 매우 많습니다.\n\nlibrary(stringr)\n\n# 1\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text() %>%\n  str_extract_all('(\\\\d)+') %>%\n  unlist()\n\n# 2\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text() %>%\n  str_replace_all(\"[\\r\\n\\t]\", \" \") %>%\n  str_split(\" \") %>%\n  unlist() %>%\n  unique() %>%\n  .[3:8]"
  },
  {
    "objectID": "crawl.html#셀레니움-실습하기",
    "href": "crawl.html#셀레니움-실습하기",
    "title": "크롤링 기초",
    "section": "셀레니움 실습하기",
    "text": "셀레니움 실습하기\n셀레니움의 경우 R에서 세팅하기는 지나치게 번거로우므로, 파이썬에서 하는 것을 권장합니다.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nimport time\nfrom bs4 import BeautifulSoup\n\n\n\n\n\n\nwebdriver.Chrome(service=Service(ChromeDriverManager().install())) 코드를 실행하면 크롬 브라우저의 버전을 탐색한 다음, 버전에 맞는 웹드라이버를 다운로드하여 해당 경로를 셀레니움에 전달해준다. 또한 크롬 창이 열리며, 좌측 상단에 'Chrome이 자동화된 테스트 소프트웨어에 의해 제어되고 있습니다.'라는 문구가 뜬다. 이제 파이썬 코드를 이용해 해당 페이지를 조작할 수 있다.\n\nurl = 'https://www.naver.com/'\ndriver.get(url)\ndriver.page_source[1:1000]\n\n\n\n\n\n\ndriver.get() 내에 URL 주소를 입력하면 해당 주소로 이동한다. 또한 driver.page_source를 통해 열려있는 창의 HTML 코드를 확인할 수도 있다. 이제 네이버 메인에서 [뉴스]버튼을 누르는 동작을 실행해보자. 개발자도구 화면을 통해 확인해보면 [뉴스] 탭은 아래 HTML에 위치하고 있다.\n\n<a href=\"https://news.naver.com/\" class=\"nav\" data-clk=\"svc.news\">뉴스</a>\n\n\n\n\n\n\n\ndriver.find_element(By.LINK_TEXT , value = '뉴스').click()\n\n\n\n\n\n\n브라우저 상에서 보이는 버튼, 검색창, 사진, 테이블, 동영상 등을 엘레먼트(element, 요소)라고 한다. find_element()는 다양한 방법으로 엘레먼트에 접근하게 해주며, By.* 를 통해 어떠한 방법으로 엘레먼트에 접근할지 선언한다. LINK_TEXT의 경우 링크가 달려 있는 텍스트로 접근하며, value = '뉴스', 즉 뉴스라는 단어가 있는 엘레먼트로 접근한다. click() 함수는 마우스 클릭을 실행하며 결과 적으로 뉴스 탭을 클릭한 후 페이지가 이동되는 것을 확인할 수 있다. find_element() 내 접근방법 및 셀레니움의 각종 동작 제어 방법에 대해서는 나중에 다시 정리하도록 한다.\n이제 뒤로가기를 실행해보도록 하자.\n\ndriver.back()\n\nback()은 뒤로가기를 의미하며, 기존 페이지인 네이버 메인으로 이동한다.\n이제 특정 검색어를 검색하는 방법에 대해 알아보자. 먼저 검색창의 위치가 어디에 있는지 확인해보면 query라는 id와 input_text라는 class에 위치하고 있다.\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'input_text').send_keys('퀀트 투자 포트폴리오 만들기')\n\n\n\n\n\n\nfind_element() 내에 By.CLASS_NAME을 입력하면 클래스 명에 해당하는 엘레먼트에 접근하며, 여기서는 검색창에 접근한다. 그 후 send_keys() 내에 텍스트를 입력하면 해당 내용이 웹페이지에 입력된다. 이제 웹페이지에서 검색 버튼 해당하는 돋보기 모양을 클릭하거나 엔터키를 누르면 검색이 실행된다. 먼저 돋보기 모양의 위치를 확인해보면 search_btn id와 btn_submit 클래스에 위치하고 있다.\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'btn_submit').send_keys(Keys.ENTER)\n\n\n\n\n\n\nfind_element(By.CLASS_NAME, value = 'btn_submit')를 통해 검색 버튼에 접근한다. 그 후 send_keys(Keys.ENTER)를 입력하면 엔터키를 누르는 동작이 실행된다. 페이지를 확인해보면 검색이 실행된 후 결과를 확인할 수 있다.\n이번에는 다른 단어를 검색해보도록 하자. 웹에서 기존 검색어 내용을 지운 후, 검색어를 입력하고, 버튼을 클릭해야 한다. 이를 위해 검색어 박스와 검색 버튼의 위치를 찾아보면 다음과 같다.\n\n검색어 박스: box_window 클래스\n검색 버튼: bt_search 클래스\n\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'box_window').clear()\ndriver.find_element(By.CLASS_NAME, value = 'box_window').send_keys('이현열 퀀트')\ndriver.find_element(By.CLASS_NAME, value = 'bt_search').click()\n\n\n검색어 박스(box_window)에 접근한 후, clear()를 실행하면 모든 텍스트가 지워진다.\nsend_keys('이현열 퀀트')를 실행하여 새로운 검색어를 입력한다.\n검색 버튼(bt_search)에 접근한 후, click()을 실행하여 해당 버튼을 클릭한다.\n\n이번에는 [VIEW] 버튼을 클릭하는 동작을 실행해보도록 한다. 기존처럼 링크나 클래스명을 통해 엘레먼트에 접근할 수도 있지만, 이번에는 XPATH를 이용해 접근해보도록 하자. XPATH란 XML 중 특정 값의 태그나 속성을 찾기 쉽게 만든 주소다. 예를 들어 윈도우 탐색기에서는 특정 폴더의 위치가 'C:\\Program Files'과 같이 주소처럼 보이며 이는 윈도우의 PATH 문법이다. XML 역시 이와 동일한 개념의 XPATH가 있다. 웹페이지에서 XPATH를 찾는 법은 다음과 같다.\n\n개발자도구 화면에서 위치를 찾고 싶은 부분에서 마우스 우클릭을 한다.\n[Copy → Copy Xpath]를 선택한다.\n\n\n\n\n\n\n위 과정을 통해 XPATH가 복사된다. 메모장을 확인해보면 VEW 부분의 XPATH는 다음과 같다.\n//*[@id=\"lnb\"]/div[1]/div/ul/li[2]/a\n이를 이용해 해당 부분을 클릭하는 동작을 실행해보자.\n\ndriver.find_element(By.XPATH, value = '//*[@id=\"lnb\"]/div[1]/div/ul/li[2]/a').click()\n\n\n\n\n\n\n탭이 [통합] 검색이 아닌 [VIEW]로 변경되었다. 이번에는 [옵션]을 클릭한 후 정렬을 [최신순]으로 하는 동작을 실행해보자. 둘의 위치는 다음과 같다.\n\n옵션 버튼: option_filter (클래스)\n최신순 버튼: //*[@id=\"snb\"]/div[2]/ul/li[2]/div/div/a[2] (Xpath)\n\n\n\n\n\n\n코드 실행에 앞서 옵션 창이 열려있다면 [X] 버튼을 눌러 닫아주도록 한다.\n\n\n\n\n\n옵션 창을 닫은 후 아래의 코드를 실행하도록 한다.\n\ndriver.find_element(By.CLASS_NAME, value = 'option_filter').click()\ndriver.find_element(By.XPATH, value = '//*[@id=\"snb\"]/div[2]/ul/li[2]/div/div/a[2]').click()\n\n\n\n\n\n\n옵션 클릭 후 최신순 버튼을 클릭하는 동작을 수행하여 검색어가 최신순으로 정렬되었다. 이제 page down 기능을 수행해보도록 하자.\n\ndriver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n# driver.find_element(By.TAG_NAME, value = 'body').send_keys(Keys.PAGE_DOWN)\n\n먼저 document.body.scrollHeight는 웹페이지의 높이를 나타내는 것으로써, window.scrollTo(0, document.body.scrollHeight);는 웹페이지의 가장 하단까지 스크롤을 내리라는 자바스크립트 명령어다. driver.execute_script()를 통해 해당 명령어를 실행하면 웹페이지가 아래로 스크롤이 이동된다. send_keys(Keys.PAGE_DOWN) 는 키보드의 페이지다운(PgDn) 버튼을 누르는 동작이며 이 역시 페이지가 아래로 이동시킨다.\n그러나 결과를 살펴보면 스크롤이 끝까지 내려간 후 얼마간의 로딩이 있은 후에 새로운 데이터가 생성된다. 이처럼 유튜브나 인스타그램, 페이스북 등 많은 검색결과를 보여줘야 하는 경우 웹페이지 상에서 한 번에 모든 데이터를 보여주기 보다는 스크롤을 가장 아래로 위치하면 로딩을 거쳐 추가적인 결과를 보여준다. 따라서 스크롤을 한 번만 내리는 것이 아닌 모든 결과가 나올 때까지 내리는 동작을 실행해야 한다.\n\nprev_height = driver.execute_script('return document.body.scrollHeight')\n\nwhile True:\n    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n    time.sleep(2)\n    \n    curr_height = driver.execute_script('return document.body.scrollHeight')\n    if curr_height == prev_height:\n        break\n    prev_height = curr_height\n\n\nreturn document.body.scrollHeight은 현재의 창 높이는 반환하는 자바스크립트 명령어이며, 이를 prev_height에 저장한다.\nwhile문을 통해 반복문을 실행한다.\n셀레니움을 통해 페이지의 최하단으로 스크롤을 내린다.\n페이지가 로딩되는 시간을 기다리기 위해 2초간 슬립을 준다.\ncurr_height에 현재 창 높이를 저장한다.\ncurr_height와 prev_height가 동일하다는 의미는 페이지가 끝까지 내려왔다는 의미이다. 따라서 이 경우 break를 통해 while문을 멈추며, 그렇지 않을 경우 다시 스크롤을 내리는 동작을 반복한다.\nprev_height에 새로운 창 높이를 입력한다.\n\n이제 모든 검색 결과가 나타났으면 이전 장에서 살펴보았던 정적 크롤링을 통해 데이터 수집이 가능하다. 제목 부분을 확인해보면 api_txt_lines total_tit _cross_trigger 클래스에 위치하고 있으며, 이를 통해 모든 제목을 크롤링해보자.\n\nhtml = BeautifulSoup(driver.page_source, 'lxml')\ntxt = html.find_all(class_ = 'api_txt_lines total_tit _cross_trigger')\ntxt_list = [i.get_text() for i in txt]\n\ntxt_list[0:10]\n\n\ndriver.page_source를 통해 현재 웹페이지의 HTML 정보를 가져올 수 있으며, 이를 BeautifulSoup 객체로 만들어준다.\nfind_all() 함수를 통해 제목 부분에 위치하는 데이터를 모두 불러온다.\nfor문을 통해 텍스트만 추출한다.\n\n이처럼 동적 페이지의 경우도 셀레니움을 통해 웹페이지를 제어한 후 BeautifulSoup 패키지를 사용해 원하는 부분을 추출하면 얼마든지 크롤링이 가능하다.\n\ndriver.quit()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Welcome\n본 강의는 R을 이용해 금융 데이터 분석 및 퀀트 투자 프로세스에 대해 살펴봅니다. 수업 목차는 다음과 같습니다.\n\n데이터 분석 프로세스\nSQL 기초\nR 기초 및 데이터분석 실습\nR와 SQL 연결해 사용하기\nAPI를 이용한 데이터 수집\n크롤링 기초\n퀀트 전략을 이용한 포트폴리오 구성하기\n백테스트 실습\n성과 및 위험 평가하기"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "데이터 분석 프로세스",
    "section": "",
    "text": "데이터분석 혹은 데이터사이언스의 업무 진행 과정은 다음과 같습니다.\nR 내에서 이러한 데이터 분석을 편하게 하기 위해서는 tidyverse 패키지가 만들어 낸 생태계를 이해할 필요가 있습니다. tidyverse란 R studio에서 만든 패키지 중 핵심 패키지들을 묶은 Package of Packages 입니다.\n데이터 과학에서 업무 과정 별 사용되는 패키지는 다음과 같습니다."
  },
  {
    "objectID": "intro.html#데이터-불러오기",
    "href": "intro.html#데이터-불러오기",
    "title": "데이터 분석 프로세스",
    "section": "데이터 불러오기",
    "text": "데이터 불러오기\n회사의 서버에 저장된 데이터를 불러와야 데이터 분석을 할 수 있습니다. 그러나 실무에서는 그보다 먼저 데이터의 수집 및 어떤 플랫폼에 저장할 지 제대로 정의해야, 수월한 데이터 분석을 수행할 수 있습니다.\n\n데이터 수집 및 저장\n제대로 된 데이터가 있어야 제대로 된 분석을 할 수 있습니다. 데이터 구매를 위해 비싼 비용을 사용하지만, 대부분의 데이터가 완벽하다고 말할 수는 없습니다. 해외 금융회사의 경우 여러 벤더로부터 데이터를 구매한 후 크로스체크를 통해 오류가 있는 데이터를 찾아내며, 주니어 퀀트의 경우 데이터 오류 검증을 하는 업무부터 시작해 나갑니다.\n또한 분석을 하기 편한 플랫폼에 저장되어 있어야 빠른 데이터 분석이 가능합니다. 예를 들어 raw data가 엑셀 형태로 되어있다면 관리도 쉽지 않고, 분석 하기에도 불편합니다.\n대부분 금융 데이터의 경우 주가, 재무제표 등 정형 데이터이므로, 데이터 저장에 RDBMS을 이용하는 것이 효율적입니다. sql을 이용할 경우 원하는 데이터를 수초 내에 조회가 가능합니다.\n\n\n\n\n\nRDBMS\n\n\n\n\n그러나 보험사나 카드사와 같이 쌓이는 데이터의 양이 지나치게 만을 경우, 단순히 sql로 데이터를 처리하기에는 한계가 있습니다. 실제로 sql 쿼리를 통해 원하는 데이터를 한달치 뽑는데만 10분 정도가 소요되기도 했습니다. 몇년치에 해당하는 데이터를 모두 뽑는데만 몇 시간이 걸리고, 만일 오류가 있어서 다시 데이터를 뽑아야 한다면 그냥 하루가 날아갑니다.\n이러한 빅데이터의 분석을 위해서는 RDBMS 보다는 하둡이나 스파크, 카프카 등을 이용하는 것이 좋습니다. 예를 들어 스파크의 경우 기존 sql과 비교해 월등히 빠른 속도와, 분석가들이 익숙한 R, Python, sql 문법을 그대로 사용할 수 있는 장점이 있습니다.\n만일 RDBMS로도 원하는 데이터를 ‘참을 만한 시간’ 내에 조회가 가능하다면 그대로 사용을, 도저히 감당이 안될 정도이면 빅데이터 플랫폼으로 변경할 것을 추천하며, 이러한 플랫폼의 차이는 분석가의 업무가 아니긴 하지만 어느 정도는 알고는 있는 것이 좋습니다.\n\n\n데이터 서버 접속 및 불러오기\n데이터 서버가 구축되어 있다고, 무작정 R/Python을 이용해 서버에 접속하여 데이터를 내려받아 분석을 하는 것은 좋지 않습니다. 데이터의 용량이 클 경우 내려받는데만 수 시간이 걸릴 수 있으며, 제대로 처리하지 못할 수도 있습니다. 따라서 서버 내에서 최대한 원하는 형태까지 데이터를 가공한 후(기본 클랜징, 그룹핑, 원하는 기간과 컬럼만 선택 등) R/Python을 이용해 분석을 하는 편이 효율적입니다.\n그러나 이를 위해 데이터를 담당하는 사람에게 일일이 요청할 수는 없습니다. 일부 회사에서 원하는 형태로 데이터를 요청할 때 마다 부서 비용이 지출되기도 하고, 원하는 형태가 아닐 경우 재요청을 해야합니다. 이 과정에서 비용 뿐만 아니라 며칠이 소요됩니다. 따라서 데이터를 분석하는 사람이라면 차라리 직접 서버에 접속해 원하는 데이터를 최대한 가공한 후, R/Python로 서버에 접속하여 데이터를 내려받는 것이 이상적입니다. 이를 위해 기본적인 sql 문법도 알고 있어야 하며, 다행히도 dplyr 패키지를 공부하면 sql 문법도 자연스럽게 공부가 됩니다.\nR의 경우 RJDBC, RODBC, ROrcacle 등의 패키지를 이용해 DB에 직접 연결할 수 있습니다. R과 서버를 연결시키면, R 내에서 직접 sql 쿼리를 날린 후 결과를 받을 수 있습니다.\nR에서는 spark 역시 사용할 수 있습니다.\n\nSparkR: http://spark.apache.org/docs/latest/sparkr.html\nsparklyr: https://spark.rstudio.com/\n\nzeppelin을 사용한다면 PySpark를 이용해 파이썬을 사용할 수도 있습니다.\n\nhttps://zeppelin.apache.org/docs/latest/interpreter/spark.html"
  },
  {
    "objectID": "intro.html#데이터-정리하기-tidy",
    "href": "intro.html#데이터-정리하기-tidy",
    "title": "데이터 분석 프로세스",
    "section": "데이터 정리하기 (tidy)",
    "text": "데이터 정리하기 (tidy)\n데이터 분석의 단계에서 가장 많은 시간을 할애하는 것이 데이터 정리하기, 즉 클랜징 단계입니다. 데이터가 제대로 클랜징 처리가 되어야 분석이나 모델링을 하는 것이 가능합니다. 다행히 금융 데이터는 데이터가 지저분한 형태로 들어오는 경우가 거의 없지만, 그래도 완벽하게 원하는 형태는 아닙니다. 더구나 비정형 데이터의 경우 클랜징 처리를 어떻게 하느냐에 따라 전혀 다른 결과가 나오기도 합니다. 클랜징이 필요한 예를 들어봅시다.\n\nDate가 yyyymmdd 형태로 들어올 경우, yyyy-mm-dd 형태로 변경\n시가총액이 ‘192,370,650’ 처럼 문자형태로 들어올 경우 192370650 인 숫자형태로 변경\n수익률이 19.30 형태로 들어올 경우, 0.1930 으로 변경\n컬럼이름 변경\n결측치(NA) 처리\n\n먼저 데이터의 전반적인 처리에는 tidyr 패키지가 사용됩니다. 그 외에도 팩터 처리에는 forcats, 시간 처리에는 lubridate, 문자 처리에는 stringr 패키지가 사용됩니다. 특히 금융 데이터는 대부분 시계열 형태로 들어오므로, lubridate 패키지가 많이 사용됩니다.\n또한 magrittr 패키지의 파이프 오퍼레이터(%>%)를 사용해 데이터를 훨씬 직관적으로 처리할 수 있습니다.\n\ntidyr: https://tidyr.tidyverse.org/\nforcats: https://forcats.tidyverse.org/\nlubridate: https://lubridate.tidyverse.org/\nstringr: https://stringr.tidyverse.org/\n\n물론 간단한 클랜징 처리는 R/Python이 아닌 sql 내에서 사전에 처리하는 것이 속도 측면에서 이득입니다."
  },
  {
    "objectID": "intro.html#데이터-분석하기-explore",
    "href": "intro.html#데이터-분석하기-explore",
    "title": "데이터 분석 프로세스",
    "section": "데이터 분석하기 (Explore)",
    "text": "데이터 분석하기 (Explore)\n원하는 데이터가 준비되었으면, 본격적으로 데이터를 분석해야 한다. 이 단계는 크게 변형, 시각화, 모델링으로 구분됩니다.\n\n데이터 변형\n먼저 각종 테이블을 하나로 합칠 필요가 있으며, 이 때는 *_join() 구문이 사용됩니다.\n\n\n\n\n\njoin\n\n\n\n\n또한 데이터를 분석하기 위해 다음 함수가 대표적으로 사용됩니다.\n\nselect(): 원하는 컬럼 선택\nfilter(): 조건에 맞는 행 선택\nmutate(): 열 생성 및 데이터 변형\ngroup_by(): 그룹별로 데이터를 묶기\n\n이 외에도 dplyr 패키지에는 데이터 분석을 위한 대부분의 함수가 포함되어 있습니다.\n\n\n데이터 시각화\nR의 가장 큰 강점은 데이터 시각화라고 말하는 사람도 있습니다. 그만큼 ggplot2 패키지를 이용해 데이터를 직관적으로 표현할 수 있다. 해당 패키지는 릴랜드 윌킨스(Leland Wilkinson)의 책 The Grammar of Graphics를 기본 철학으로 만들어졌습니다.\nggplot의 경우 인터넷에도 다양한 예제가 있으므로, 원하는 형태의 그림이 있을 시 얼마든지 검색이 가능합니다.\n\nhttps://r-graph-gallery.com/ggplot2-package.html\nhttp://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html"
  },
  {
    "objectID": "intro.html#모델링",
    "href": "intro.html#모델링",
    "title": "데이터 분석 프로세스",
    "section": "모델링",
    "text": "모델링\n기존의 R 내에 머신러닝 관련 패키지는 너무 분산되어 있었습니다. 그러나 Rstudio에서 통계분석, 머신러닝을 위한 tidymodel 세계관 구축 중입니다.\n\n\n\n\n\ntidymodel\n\n\n\n\n\nhttps://www.tidymodels.org/learn/\n\n과거 해들리 위컴의 R4DS 책이 발간된 이후 tidyverse 생태계가 R의 메인으로 자리잡은 것 처럼, tidymodel 패키지가 완성된 후 책으로 나온다면 이 역시 새로운 세계관으로 자리잡지 않을까 생각한다. 현재 해당 패키지를 만들고 있는 개발자들이 관련 책도 함께 써나가고 있는 중입니다.\n\nhttps://www.tmwr.org/"
  },
  {
    "objectID": "intro.html#소통-communicate",
    "href": "intro.html#소통-communicate",
    "title": "데이터 분석 프로세스",
    "section": "소통 (communicate)",
    "text": "소통 (communicate)\n혼자 일을 하지 않는 이상 결국 업무의 마무리는 문서화와 보고입니다. 하지만 사내에서만 보는 문서를 굳이 한글이나 워드로 작성하는 것은 매우 비효율적입니다. 코딩으로 나온 값을 다시 csv로 저장한 다음, 엑셀에서 가공하고, 그걸 다시 워드로 옮기고, 생각만 해도 숨막히는 작업입니다. R에서 코딩으로 데이터 분석을 했다면, 결과물 역시 코딩으로 하는 것이 훨씬 효율적입니다.\n\nQuarto\nQuarto는 문서 내에서 코드(R, 파이썬 등)와 텍스트를 동시에 사용가능하여 효율적으로 문서를 작성할 수 있게 해줍니다. 만일 양식이 동일한 문서에서 기초 데이터만 매번 바뀌는 상황이라면, 기존의 환경에서는 매번 기초 데이터를 뽑아 문서로 작성해야 합니다. 그러나 Quarto를 이용한다면 데이터를 받는 것부터 문서화까지 코드로 만들어 두어 100% 자동화가 가능합니다.\n\n\n\n\n\n\nhttps://quarto.org/\n\nQuarto는 기본적은 markdown 기능 외에도 latex, html(css)도 직접 사용 가능해 훨씬 아름다운 문서 작성이 가능합니다. Quarto를 이용한 문서화 과정은 다음과 같습니다.\n\nqmd로 문서를 작성\nknitr 패키지가 코드를 실행한 후 md 파일로 변환\npandoc 패키지가 각종 결과물로 변환 (HTML, PDF, Word, Presentation 등)\n\n\n\n\n\n\n실무적으로는 이러한 것들을 몰라도 Qmd 작성 테크닉만 알고 있다면, 작성 후 Render 버튼을 누르기만 하면 문서가 만들어집니다. 대부분의 경우 편하게 볼 수 있는 HTML 형태로 결과물을 생성하지만, 만일 보고용이라면 PDF로 결과물을 생성한 후, 프린트를 해도 됩니다.\n\n\nQuarto Book\nQuarto Book(Bookdown)은 Quarto를 이용해 만들 수 있으며, 웹북을 만들어 줍니다. 사내에서 업무 프로세스처럼 목차가 있는 문서를 만들어야 할 경우, 대부분 이파일 저파일 덕지덕지 저장해놓기 마련이며 관리도 되지 않습니다. 만일 이러한 것들을 웹북 형태로 만들어 둔다면 통합적으로 관리하기 용이하며, 인덱싱이 되므로 검색하기도 편합니다.\n\nhttps://hyunyulhenry.github.io/quant_cookbook/\n\n\n\nShiny\nQuarto를 이용한 문서도 결과적으로 일차원적인 문서, 즉 보고자가 작성한 문서라는 한계가 있습니다. 그러나 보고를 받는 사람이 추가적인 데이터를 보고 싶을 경우, 예를 들어 운용중인 100개 펀드 리스트 중 원하는 펀드를 선택한 후, 원하는 날짜의 보유 종목을 확인하고자 할 경우, 매번 보고자가 해당 데이터를 뽑은 후 문서화를 해야 한다.\n그러나 R의 Shiny를 이용할 경우 간편하게 앱을 만들 수 있으며, 이 모든 과정이 가능합니다. 또한 Quarto와 마찬가지로 DB 서버에 연결하는 코드까지 짜둘 경우, DB가 업데이트 됨에 따라 앱의 결과물 역시 최신 데이터를 보여줍니다. 사내에 샤이니를 제대로 만들 줄 아는 사람 한명만 있어도, 굳이 비싼 돈을 주고 tableau를 구매하지 않아도 되고, 확장성도 훨씬 넓습니다.\n\nhttps://doomoolmori.shinyapps.io/boolio/"
  },
  {
    "objectID": "intro.html#배포",
    "href": "intro.html#배포",
    "title": "데이터 분석 프로세스",
    "section": "배포",
    "text": "배포\n코드를 저장하고, 완성된 문서를 배포하는 것 역시 중요합니다. 먼저 코드 저장의 경우 Rstudio와 Github를 연동해두면, 매우 쉽게 Github로 코드를 업로드할 수 있습니다. 만일 사내에서 Gitlab을 사용한다면, 이 또한 좋은 저장 수단입니다.\nGithub을 이용한다면 Quarto로 생성된 문서 역시 자동으로 url이 생성되므로, 문서를 공유하기 보다는 해당 url을 공유하는 것이 훨씬 좋습니다. 만일 데이터를 새로 분석하거나 양식이 바뀔 경우 파일을 공유하면 이래저래 꼬일 가능성이 있지만, url을 접속하면 최신 버젼의 파일이 자동으로 업데이트 되기 때문입니다.\nShiny의 경우도 Rstudio를 통해 shinyapps.io에 업로드하여 url을 생성할 수 있습니다. 그러나 보안 등의 이슈로 사내에서만 봐야하는 결과물이라면, 사내에 Shiny server를 설치하여 사내전용 url을 생성하는 것 역시 가능합니다. 또한 특정 부서만 접근이 가능하게 하려면 shinymanager 패키지를 통해 ID/PW를 부여할 수도 있습니다.\n매일 자동으로 생성되는 문서가 있다면, 문서가 생성된 후 이메일이나 슬랙/텔레그램으로 결과물을 전송하는 것 역시 가능합니다. 매일 체크해기는 해야하지만 그 중요도가 낮은 문서의 경우, 이러한 자동화를 통해 출근길에 휴대폰으로 간단하게 확인하는 것 또한 가능합니다."
  },
  {
    "objectID": "performance.html",
    "href": "performance.html",
    "title": "성과 및 위험 평가하기",
    "section": "",
    "text": "포트폴리오 혹은 전략의 수익률을 바탕으로 각종 성과 및 위험을 평가해야 합니다. 아무리 성과가 좋은 전략이라도 위험이 너무 크다면 투자를 하기 부담스럽습니다. 또한 전략의 수익률이 지속적으로 감소하는 추세라면 경쟁이 치열해져 더 이상 작동하지 않는 전략일 가능성도 있습니다.\n포트폴리오의 예시로 버크셔 헤서웨이(Berkshire Hathaway Inc.) 주식의 수익률을 이용하겠습니다. 해당 주식의 수익률을 통해 성과 및 위험을 평가해보고, 회귀분석을 통해 팩터에 대한 노출도도 살펴보겠습니다."
  },
  {
    "objectID": "performance.html#결과-측정-지표",
    "href": "performance.html#결과-측정-지표",
    "title": "성과 및 위험 평가하기",
    "section": "결과 측정 지표",
    "text": "결과 측정 지표\n포트폴리오의 평가에서 가장 중요한 지표는 수익률과 위험입니다. 수익률은 누적수익률과 연율화 수익률, 연도별 수익률이 주요 지표이며, 위험은 변동성과 낙폭이 주요 지표입니다.\n이 외에도 승률, 롤링 윈도우 값 등 다양한 지표를 살펴보기도 합니다. 이러한 지표를 수식을 이용해 직접 계산할 수도 있지만, PerformanceAnalytics 패키지에서 제공하는 다양한 함수들을 이용해 편하게 계산할 수 있습니다.\n\n수익률 및 변동성\n\nlibrary(PerformanceAnalytics)\nchart.TimeSeries(price)\n\n\n\n\n\n\n\n\nchart.TimeSeries() 함수를 통해 수익률을 그릴 수 있습니다.\n\nlibrary(ggplot2)\nlibrary(magrittr)\n\nprice %>% fortify.zoo() %>%\n  set_colnames(c('date', 'value')) %>%\n  ggplot(aes(x = date, y = value)) +\n  geom_line()\n\n\n\n\n\n\n\n\n좀 더 섬세한 그래프 작업을 해야할 때는 ggplot() 함수를 이용하면 됩니다.\n\nret = Return.calculate(price)\nchart.CumReturns(ret)\n\n\n\n\n\n\n\n\n만일 수익률로 계산된 경우 chart.CumReturns() 함수를 이용해 누적수익률을 그릴수도 있습니다.\n수익률 중 가장 많이보는 지표는 누적 수익률, 연율화 수익률(산술), 연율화 수익률(기하)입니다. 각 수익률을 구하는 법은 다음과 같습니다.\n\n누적 수익률: \\((1+r_1) \\times (1+r_2) \\times \\dots \\ \\times (1+r_n) - 1 = \\{\\prod_{i=1}^n(1+r_i)\\}-1\\),\n연율화 수익률(산술): \\(\\frac{(r_1 + r_2 + \\dots + r_i)}{n} \\times scale\\)\n연율화 수익률(기하): \\(\\{\\prod_{i=1}^n(1+r_i)\\}^{scale / Days} - 1\\)\n\n먼저 누적수익률은 각 수익률에 1을 더한 값을 모두 곱한 후 1을 빼면 됩니다. 연율화 수익률(산술)은 단순히 수익률의 평균을 구한 후 연율화를 위한 조정값(\\(scale\\))을 곱해주면 됩니다. 데이터가 일간일 경우 조정값은 252, 주간일 경우 52, 월간일 경우 12입니다. 현재 데이터는 월간 기준이므로 조정값은 12가 됩니다. 마지막으로 연율화 수익률(기하)은 각 수익률에 1을 더한 값의 곱을 구한 후 연율화를 위해 승수를 적용한 후 1을 빼주며, Days는 시계열의 관측 기간입니다. 마지막으로 연율화 수익률(기하)의 경우 각 수익률에 1을 더한 값의 곱을 구한 후, 연율화를 위해 승수를 곱한 후 1을 빼주면 되며, \\(Days\\)는 시계열의 관측 기간입니다.\n수식에 맞게 값을 입력해 계산할 수도 있지만, 함수를 이용하면 더욱 손쉽게 계산이 가능하며 실수할 가능성도 줄어듭니다.\n\nReturn.cumulative(ret)\n\n                  BRK-B.Adjusted\nCumulative Return       12.28879\n\n\n누적수익률은 Return.cumulative() 함수를 통해 구할 수 있습니다.\n\nReturn.annualized(ret, geometric = FALSE) # 연율화 수익률(산술)\n\n                  BRK-B.Adjusted\nAnnualized Return      0.1229626\n\nReturn.annualized(ret) # 연율화 수익률(기하)\n\n                  BRK-B.Adjusted\nAnnualized Return      0.1019027\n\n\n연율화 수익률(산술)은 Return.annualized() 함수 내 geometric 인자를 FALSE로 선택해줌으로써, 연율화 수익률(기하)는 Return.annualized() 함수를 통해 계산이 가능합니다.\n위험으로 가장 많이 사용되는 지표는 변동성입니다. 연율화 변동성은 sd() 함수를 통해 변동성을 계산한 후 조정값을 곱해 계산할 수도 있지만, StdDev.annualized() 함수를 사용해 더욱 쉽게 계산할 수도 있습니다.\n\nStdDev.annualized(ret) # 연율화 변동성\n\n                              BRK-B.Adjusted\nAnnualized Standard Deviation      0.2284221\n\n\n수익을 위험으로 나누어 위험 조정 수익률을 보는 지표가 샤프 지수(Sharpe Ratio)입니다. 해당 지수는 \\(\\frac {R_i - R_f}{\\sigma_i}\\)로 계산되며, 분자에는 포트폴리오 수익률에서 무위험 수익률을 차감한 값이, 분모에는 포트폴리오의 변동성이 오게 됩니다.\n\nSharpeRatio.annualized(ret, Rf = 0, geometric = TRUE)\n\n                                BRK-B.Adjusted\nAnnualized Sharpe Ratio (Rf=0%)      0.4461159\n\n\nSharpeRatio.annualized() 함수를 이용하면 포트폴리오 수익률에서 무위험 수익률을 차감한 값을 연율화로 변경한 후 연율화 변동성으로 나누어 샤프 지수를 계산합니다. geometric을 TRUE로 설정하면 기하평균 기준 연율화 수익률을, FALSE로 설정하면 산술평균 기준 연율화 수익률을 계산합니다.\n\ntable.AnnualizedReturns(ret)\n\n                          BRK-B.Adjusted\nAnnualized Return                 0.1019\nAnnualized Std Dev                0.2284\nAnnualized Sharpe (Rf=0%)         0.4461\n\n\n연간 수익률, 변동성, 샤프지수를 한 번에 계산할 경우 table.AnnualizedReturns() 함수를 사용하면 됩니다.\n\n\n낙폭(drawdown)과 최대낙폭(MDD)\n먼저 낙폭(Drawdown)은 수익률이 하락한 후 반등하기 전까지 얼마나 하락했는지를 나타냅니다. 최대낙폭(Maximum Drawdown)은 이러한 낙폭 중 가장 값이 큰 값으로서, 최고점에서 최저점까지 얼마나 손실을 보는지를 나타냅니다. 투자를 함에 있어 수익률이 하락하는 것은 어쩔 수 없지만, 최대낙폭이 지나치게 큰 전략에 투자하는 것은 매우 위험한 선택이 될 수 있습니다.\n\n\n\n\n\nR에서는 각종 낙폭에 대한 지표를 손쉽게 구할 수 있습니다.\n\ntable.Drawdowns(ret, top = 10)\n\n         From     Trough         To   Depth Length To Trough Recovery\n1  2007-12-11 2009-03-05 2013-02-15 -0.5386   1305       310      995\n2  1998-06-22 2000-03-10 2003-11-14 -0.4935   1360       435      925\n3  2020-01-21 2020-03-23 2020-11-16 -0.2957    210        44      166\n4  2022-03-29 2022-10-12       <NA> -0.2658    204       137       NA\n5  2014-12-19 2016-01-25 2016-11-10 -0.1869    478       275      203\n6  1996-05-13 1996-06-03 1997-02-12 -0.1625    192        15      177\n7  2018-10-10 2018-12-24 2019-12-12 -0.1609    296        52      244\n8  2004-04-13 2005-09-21 2006-08-21 -0.1599    595       365      230\n9  2018-02-02 2018-06-27 2018-09-18 -0.1489    158       101       57\n10 1997-06-16 1997-08-29 1998-01-20 -0.1423    151        54       97\n\n\nFrom은 전고점, Trough는 저점, To는 회복지점 입니다. Depth는 하락정도이며, Length, To Trough, Recovery는 낙폭 일수를 나타냅니다. 금융위기때의 경우 최대 53%가 하락했으며, 310일간 하락 및 995일간 회복하여 전고점 회복까지 1305일이 걸렸습니다.\n\nmaxDrawdown(ret)\n\n[1] 0.5386158\n\n\nMDD를 구할때는 maxDrawdown() 함수가 사용됩니다.\n\nchart.Drawdown(ret)\n\n\n\n\n\n\n\n\nchart.Drawdown() 함수를 통해 낙폭 그래프를 그릴수도 있습니다.\n\nlibrary(ggplot2)\nlibrary(magrittr)\n\ndd = Drawdowns(ret)\n\ndd %>% fortify.zoo() %>%\n  set_colnames(c('date', 'value')) %>%\n  ggplot(aes(x = date, y = value)) +\n  geom_line()\n\n\n\n\n\n\n\n\nDrawdowns() 함수를 통해 낙폭을 계산할 수도 있으며, 이 후 ggplot() 함수를 통해 그림을 그릴 수도 있습니다.\n\n\n기타 지표\n\nCalmarRatio(ret)\n\n             BRK-B.Adjusted\nCalmar Ratio      0.1891937\n\n\n칼마 지수(Calmar Ratio)는 연율화 수익률을 최대낙폭으로 나눈 값으로서, 특히나 안정적인 절대 수익률을 추구하는 헤지펀드에서 많이 참조하는 지표입니다.\n\nSortinoRatio(ret)\n\n                         BRK-B.Adjusted\nSortino Ratio (MAR = 0%)      0.0518033\n\n\n소티노 지수(Sortino)는 샤프 지수와 비슷하며, 전체 변동성이 아닌 하락 위험(\\(\\sigma^{downside}\\))을 사용합니다.\n\\[S = \\frac{E(R-R^f)}{\\sigma^{downside}}\\] 하락 위험(또는 하락 편차)은 최소 허용 수익률(MAR) 미만 수익률의 표준편차로 계산됩니다.\n\\[\\sigma^{downside} = \\sigma(R1_{R<MAR})\\] 최소 허용 수익률은 종종 무위험 수익률이나 0으로 설정됩니다. 하락 위험에 사용된 지표 함수 R1{R<MAR}은 수익률이 0보다 작으면 1, 그렇지 않으면 0으로 계산합니다. 따라서 수익률이 최소 허용 수익률보다 높을 때 수익률의 변동은 하락 위험에 영향을 주지 않습니다. 이는 투자자들이 오직 (또는 많은 부분) 하락에만 관심을 갖는다는 가정에 기초합니다. 따라서 소르티노지수는 투자자가 2년 동안 매해 5%를 버는지, 혹은 첫해에는 1%와 이듬해에는 9%를 버는지는 신경 쓰지 않는다고 가정합니다. 반면 샤프지수는 투자자가 전자를 선호한다는 가정을 기반으로 합니다.\n\n\n연도별 수익률\n월별, 분기별, 연도별 수익률을 계산할 때는 apply.*() 함수가 사용됩니다.\n\napply.yearly(ret, Return.cumulative) %>% head()\n\n           BRK-B.Adjusted\n1996-12-31    -0.04137935\n1997-12-31     0.38399285\n1998-12-31     0.52696551\n1999-12-31    -0.22127664\n2000-12-29     0.28633892\n2001-12-31     0.07264227\n\n\napply.yearly() 함수 내 계산 함수를 Return.cumulative로 설정한다면 연도별 수익률을 계산할 수 있습니다.\n\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nR.yr = apply.yearly(ret, Return.cumulative) %>%\n  fortify.zoo() %>%\n  mutate(Index = year(Index)) %>%\n  set_colnames(c('Index', 'value'))\n\nggplot(R.yr, aes(x = Index, y = value)) +\n  geom_bar(position = \"dodge\", stat = \"identity\", fill = 'skyblue') +\n  ggtitle('Yearly Return') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme_bw() +\n  scale_y_continuous(expand = c(0.03, 0.03)) +\n  scale_x_continuous(breaks = R.yr$Index,\n                     expand = c(0.01, 0.01)) +\n  theme(plot.title = element_text(hjust = 0.5,\n                                  size = 12),\n        legend.position = 'bottom',\n        legend.title = element_blank(),\n        legend.text = element_text(size=7),\n        axis.text.x = element_text(angle = 45,\n                                   hjust = 1, size = 8),\n        panel.grid.minor.x = element_blank() ) +\n  guides(fill = guide_legend(byrow = TRUE)) +\n      geom_text(aes(label = paste(round(value * 100, 2), \"%\"),\n                    vjust = ifelse(value >= 0, -0.5, 1.5)),\n                position = position_dodge(width = 1),\n                size = 3)\n\n\n\n\n\n\n\n\napply.yearly() 함수를 통해 계산한 연도별 수익률에 ggplot() 함수를 응용하면 막대 그래프로 나타낼 수도 있으며, 시각화를 통해 포트폴리오의 수익률 추이가 더욱 쉽게 확인됩니다.\n\n\n승률 및 롤링 윈도우\n승률이란 포트폴리오가 벤치마크 대비 높은 성과를 기록한 비율을 의미하며 다음과 같이 계산됩니다.\n\\[\\frac{(포트폴리오 수익률 > 벤치마크) 일수}{전체 기간}\\]\n벤치마크가 S&P 500 지수, KOSPI 200 지수처럼 구체적으로 존재하는 경우도 있지만, 절대수익을 추구하는 경우에는 이러한 벤치마크가 0 혹은 무위험 수익률이 되기도 합니다.\n\nUpsideFrequency(ret, MAR = 0)\n\n[1] 0.4943436\n\n\nUpsideFrequency() 함수는 벤치마크 대비 승률을 계산해줍니다. MAR 인자는 0이 기본값으로 설정되어 있으며, 원하는 벤치마크가 있을 시 이를 입력해주면 됩니다.\n\nUpsideFrequency(ret %>% apply.monthly(Return.cumulative), MAR = 0)\n\n[1] 0.5607477\n\n\n일간 기준 승률은 노이즈가 많으므로 월간, 혹은 연간으로 계산할 필요도 있습니다. 이번에는 S&P500 대비 승률을 계산해보도록 합니다.\n\ngetSymbols('^GSPC', from = '1996-05-09')\n\n[1] \"^GSPC\"\n\nBM = Ad(GSPC) %>% Return.calculate()\n\nUpsideFrequency(ret, MAR = BM)\n\n[1] 0.4802024\n\nUpsideFrequency(ret %>% apply.yearly(Return.cumulative), MAR = BM %>% apply.yearly(Return.cumulative))\n\n[1] 0.6071429\n\n\nS&P500 수익률에 해당하는 ‘GSPC’ 데이터를 받은 후 수익률을 계산합니다. 이를 버크셔 일간 및 연간 수익률과 비교하여 승률을 구합니다.\n위에서 구한 각종 지표들은 투자자가 포트폴리오의 시작부터 현재까지 투자를 했다는 전제 하에 계산됩니다. 그러나 투자를 시작하는 시점은 사람마다 다르기에, 무작위 시점에 투자했을 때 향후 n개월 후 승률 혹은 연율화 수익률 등을 계산할 필요도 있습니다. 이러한 기법을 롤링 윈도우라고 합니다.\n\nret_m = ret %>% apply.monthly(., Return.cumulative) \n\n먼저 수익률을 월간으로 변경합니다.\n\nroll_12 = ret_m %>% rollapply(., 12, Return.cumulative)\nroll_24 = ret_m %>% rollapply(., 24, Return.cumulative)\nroll_36 = ret_m %>% rollapply(., 36, Return.cumulative)\n\ncbind(roll_12, roll_24, roll_36) %>%\n  UpsideFrequency(na.rm = TRUE)\n\n                            BRK.B.Adjusted BRK.B.Adjusted.1 BRK.B.Adjusted.2\nUpside Frequency (MAR = 0%)      0.7290323        0.8255034        0.9055944\n\n\n롤링 윈도우 승률은 무작위 시점에 투자했을 시 미래 n개월 동안의 누적 수익률을 구하고, 해당 값이 벤치마크 대비 수익이 높았던 비율을 계산합니다. 만일 12개월 롤링 윈도우 승률이 100%라면, 어떠한 시점에 투자해도 12개월 후에는 언제나 벤치마크를 이겼음을 의미합니다. 반면 아무리 누적 수익률이 높은 전략도 이러한 롤링 윈도우 승률이 지나치게 낮다면, 단순히 한 번의 운으로 인해 수익률이 높은 것처럼 보일수 있습니다.\n함수를 이용해 해당 값을 구하는 과정은 다음과 같습니다.\n\napply.*() 함수를 이용해 원하는 기간의 수익률로 변경하며, 위 예제에서는 월간 수익률로 변경했습니다.\nrollapply() 함수를 통해 원하는 기간의 롤링 윈도우 통곗값을 구해줍니다. 각각 12개월, 24개월, 36개월 기간에 대해 연율화 수익률을 계산해줍니다.\n값들을 묶어준 후 UpsideFrequency() 함수를 통해 승률을 계산합니다.\n\n해당 과정을 통해 계산된 12개월, 24개월, 36개월 롤링 승률을 사려보면, 투자 기간이 길어질수록 승률이 높아집니다. 이번에는 시각화로 나타내보겠습니다.\n\ncbind(roll_12, roll_24, roll_36) %>%\n  fortify.zoo() %>%\n  set_colnames(c('date', '12', '24', '36')) %>%\n  pivot_longer(names_to = 'period', values_to = 'return', -date) %>%\n  ggplot(aes(x = date, y = return, color = period)) + \n  geom_line(size = 1.3) +\n  geom_hline(aes(yintercept = 0), color = 'black')"
  },
  {
    "objectID": "performance.html#팩터-회귀분석",
    "href": "performance.html#팩터-회귀분석",
    "title": "성과 및 위험 평가하기",
    "section": "팩터 회귀분석",
    "text": "팩터 회귀분석\n포트폴리오 수익률에 대한 성과 평가만큼 중요한 것이, 수익률이 어디에서 발생했는가에 대한 요인을 분석하는 것입니다. 베타를 통한 개별 주식과 주식시장과의 관계를 시작으로, 수익률을 설명하기 위한 여러 모형들이 개발되고 발표되었습니다. 그중 일반적으로 많이 사용되는 모형은 기존의 CAPM에 사이즈 팩터(SMB), 밸류 팩터(HML)를 추가한 파마-프렌치의 3팩터 모형, 그리고 3팩터 모형에 모멘텀 팩터(UMD)를 추가한 카하트의 4팩터 모형입니다.\n\\[R - R_f= \\alpha +  \\beta_m \\times \\ [R_m - R_f] + \\beta_{SMB} \\times R_{SMB} + \\beta_{HML} \\times R_{HML} + \\beta_{UMD} \\times R_{UMD}\\]\n위 수식에 맞게 회귀분석을 실시하며, 이를 위해 4팩터 데이터를 다운받습니다.\n\nlibrary(frenchdata)\n\nff_three = download_french_data('Fama/French 3 Factors')\nff_mom = download_french_data('Momentum Factor (Mom)')\n\nff = ff_three$subsets$data[[1]] %>%\n  inner_join(ff_mom$subsets$data[[1]]) %>%\n  mutate(date = as.character(date)) %>%\n  mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n  mutate(across(-date, ~. / 100)) \n\nret_bind = ret_m %>%\n  fortify.zoo() %>%\n  set_colnames(c('date', 'ri')) %>%\n  mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n  inner_join(ff) %>%\n  mutate(r_excess = ri - RF)\n\n\n쓰리팩터와 모멘텀 데이터를 받습니다.\ndate가 yyyymm으로 되어있으므로 yyyy-mm-dd로 변경하며 월말 데이터로 바꿉니다.\ndate 열을 제외한 열이 퍼센트 데이터이므로 100으로 나눕니다.\n버크셔 수익률 역시 클렌징 처리를 한 후 두 데이터를 합칩니다.\n버크셔 수익률에서 무위험 수익률을 빼 초과수익률을 계산합니다.\n\n\nreg = lm(r_excess ~ `Mkt-RF` + SMB+ HML + Mom, data = ret_bind)\n\nsummary(reg)\n\n\nCall:\nlm(formula = r_excess ~ `Mkt-RF` + SMB + HML + Mom, data = ret_bind)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.125098 -0.027838 -0.004936  0.022913  0.184605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.003036   0.002447   1.240    0.216    \n`Mkt-RF`     0.710336   0.056438  12.586  < 2e-16 ***\nSMB         -0.508077   0.076659  -6.628 1.48e-10 ***\nHML          0.443402   0.073921   5.998 5.48e-09 ***\nMom          0.012662   0.051984   0.244    0.808    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0427 on 314 degrees of freedom\nMultiple R-squared:  0.428, Adjusted R-squared:  0.4208 \nF-statistic: 58.75 on 4 and 314 DF,  p-value: < 2.2e-16\n\n\nlm() 함수를 통해 회귀분석을 수행합니다. 베타의 절댓값이 크다는 의미는 수익률이 해당 팩터와의 관계가 높다는 의미이며, 양수일 경우에는 양의 관계가, 음수일 경우에는 음의 관계가 높다는 의미입니다. 또한 t값 혹은 P값을 통해 관계가 얼마나 유의한지도 확인할 수 있습니다.\n\n시장 베타에 해당하는 \\(\\beta_m\\)은 1보다 낮습니다. 즉 시장과의 관계가 낮다고 볼 수 있습니다. 또한 t값이 충분히 유의합니다.\n사이즈 베타에 해당하는 \\(\\beta_{SMB}\\)는 음수입니다. 즉 소형주보다 대형주 수익률과 관계가 있습니다. t값 역시 충분히 유의힙니다.\n밸류 베타에 해당하는 \\(\\beta_{HML}\\)은 양수입니다. 즉 가치주 수익률과 관계가 있습니다. t값 역시 충분히 유의합니다.\n모멘텀 베타에 해당하는 \\(\\beta_{Mom}\\)의 t밸류는 매우 작아 유의하지 않습니다.\n이를 제외한 알파의 t값은 유의하지 않습니다. 즉 기존의 팩터로 모든 수익률의 설명이 가능합니다.\n\n\nlibrary(broom)\ntidy(reg)\n\n# A tibble: 5 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.00304   0.00245     1.24  2.16e- 1\n2 `Mkt-RF`     0.710     0.0564     12.6   1.09e-29\n3 SMB         -0.508     0.0767     -6.63  1.48e-10\n4 HML          0.443     0.0739      6.00  5.48e- 9\n5 Mom          0.0127    0.0520      0.244 8.08e- 1\n\n\nbroom 패키지의 tidy() 함수를 사용하면 분석 결과 중 계수에 해당하는 값만을 요약해서 볼 수 있습니다.\n\nlibrary(stargazer)\nstargazer(reg, type = 'text', out = 'reg_table.html')\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                             r_excess          \n-----------------------------------------------\n`Mkt-RF`                     0.710***          \n                              (0.056)          \n                                               \nSMB                          -0.508***         \n                              (0.077)          \n                                               \nHML                          0.443***          \n                              (0.074)          \n                                               \nMom                            0.013           \n                              (0.052)          \n                                               \nConstant                       0.003           \n                              (0.002)          \n                                               \n-----------------------------------------------\nObservations                    319            \nR2                             0.428           \nAdjusted R2                    0.421           \nResidual Std. Error      0.043 (df = 314)      \nF Statistic           58.747*** (df = 4; 314)  \n===============================================\nNote:               *p<0.1; **p<0.05; ***p<0.01\n\n\nstargazer 패키지를 사용하면, 회귀분석 결과를 논문에서 많이 사용되는 테이블 형식으로 손쉽게 출력과 저장을 할 수 있습니다.테이블이 출력과 함께 reg_table.html 이름으로 HTML 파일도 저장됩니다."
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "포트폴리오 구성하기",
    "section": "",
    "text": "퀀트 투자는 크게 포트폴리오 운용 전략과 트레이딩 전략으로 나눌 수 있습니다. 포트폴리오 운용 전략은 과거 주식 시장을 분석해 좋은 주식의 기준을 찾아낸 후 해당 기준에 만족하는 종목을 매수하거나, 이와 반대에 있는 나쁜 주식을 공매도하기도 합니다. 투자의 속도가 느리며, 다수의 종목을 하나의 포트폴리오로 구성해 운용하는 특징이 있습니다. 반면 트레이딩 전략은 주식이 오르거나 내리는 움직임을 연구한 후 각종 지표를 이용해 매수 혹은 매도하는 전략입니다. 투자의 속도가 빠르며 소수의 종목을 대상으로 합니다. 본 수업에서는 퀀트 전략을 이용한 종목선정에 대해 알아보겠습니다."
  },
  {
    "objectID": "portfolio.html#팩터-이해하기",
    "href": "portfolio.html#팩터-이해하기",
    "title": "포트폴리오 구성하기",
    "section": "팩터 이해하기",
    "text": "팩터 이해하기\n하나 혹은 소수의 주식만을 연구해서 주식이 오르거나 내리는 공통적인 이유를 찾는 것은 불가능에 가깝지만, 그룹으로 살펴보면 어느 정도 파악이 가능합니다. 어떠한 특성, 예를 들어 기업의 크기 별로 주식들을 묶은 후 수익률을 살펴보면, 크기가 큰 기업의 수익률이 좋았는지 아니면 작은 기업의 수익률이 좋았는지 알 수 있습니다. 즉, 오르는 주식과 내리는 주식은 애초에 가지고 있는 특성이 다르며 그로 인해 수익률에도 차이가 있습니다. 이처럼 주식의 수익률에 영향을 미치는 특성들을 ’팩터(Factor)’라고 하며, 주식의 수익률은 이러한 팩터들로 대부분 설명됩니다. 주식이 가지고 있는 특성만 제대로 알아도 오를만한 주식을 선별하거나, 혹은 내릴만한 주식을 걸러낼 수 있습니다.\n그러나 단순히 특성을 기준으로 수익률이 높거나 낮다고 해서 팩터로 인정되는 것은 아닙니다. 팩터로 인정되고 전략으로 사용되기 위해서는 아래의 조건을 충족해야 합니다.\n\n지속성: 오랜 기간, 그리고 여러 경제 상황에서도 꾸준히 작동해야 합니다. 몇 달 혹은 몇 년 동안의 기간에서만 작동한다면 우연의 결과일 가능성이 매우 큽니다.\n범용성: 특정 국가에서만 작동하는 것이 아닌 다양한 국가, 지역, 섹터, 자산군에서도 작동해야 합니다. 전세계 중 한국에서만 작동하는 전략이라면 이 역시 우연일 가능성이 큽니다.\n이해 가능성: 전략이 작동하는 이유 및 지속 가능한지에 대한 설명이 가능해야 합니다. 수익률이 높은 이유를 경제학이나 이론적으로 설명할 수 있어야 앞으로도 수익률이 높을 것이라 믿을 수 있습니다. 이유가 없는 효과는 우연 혹은 과최적화의 결과일 가능성이 매우 높습니다.\n강건성: 같은 팩터라면 비슷한 정의(예: 가치주를 정의하는 PBR, PER, PSR 등) 모두에서 작동해야 합니다. 전략이 작동하는 이유가 명확하다면 정의가 약간씩 달라도 당연히 작동해야 하며, 결과 역시 비슷해야 합니다.\n투자 가능성: 이론적으로만 작동하는 것이 아닌 실제로 투자가 가능해야 합니다. 아무리 좋은 전략도 수수료, 세금, 법률적인 문제 등으로 실제 투자가 불가능하다면 돈을 벌 수 없기 때문입니다.\n\n퀀트 운용 전략에서는 팩터의 강도가 양인 종목들로 구성한 포트폴리오는 향후 수익률이 높을 것으로 예상되어 매수를 하며, 팩터의 강도가 음인 종목들로 구성한 포트폴리오는 반대로 향후 수익률이 낮을 것으로 예상되어 매수를 하지 않거나 공매도를 합니다. 기본적인 팩터들에 대해 알아보고, 우리가 구한 데이터를 바탕으로 각 팩터별 투자 종목을 선택하는 방법을 알아보겠습니다."
  },
  {
    "objectID": "portfolio.html#데이터-불러오기",
    "href": "portfolio.html#데이터-불러오기",
    "title": "포트폴리오 구성하기",
    "section": "데이터 불러오기",
    "text": "데이터 불러오기\n먼저 샘플로 사용할 주가 및 재무제표 데이터를 다운로드 받습니다. 데이터는 아래 링크에 .sql 파일로 업로드 되어 있습니다.\nhttps://drive.google.com/file/d/13KLFlZTGJvyrlXQYQ_mR0RgAbfYtufti/view?usp=share_link\n[다운로드] 버튼을 눌러 파일을 다운로드 합니다. 그 후 SQL에서 해당 데이터베이스를 불러옵니다.\n\n\n\n\n\n\nNavigator에서 Administration 부분을 클릭한 후 Data Import를 선택합니다.\nImport from Self-Contained File를 선택한 후 […]을 눌러 다운로드 받은 파일을 선택합니다.\nDefault Target Schema 우측의 New를 누른 후 저장될 데이터베이스 이름을 입력합니다.\n하단의 Start Import를 클릭합니다.\n\n\n\n\n\n\n데이터베이스를 확인해보면 티커, 주가, 재무제표 데이터가 들어와 있습니다."
  },
  {
    "objectID": "portfolio.html#밸류-전략",
    "href": "portfolio.html#밸류-전략",
    "title": "포트폴리오 구성하기",
    "section": "밸류 전략",
    "text": "밸류 전략\n가치주 효과란 내재 가치 대비 낮은 가격의 주식(저PER, 저PBR 등)이, 내재 가치 대비 비싼 주식(고PER, 고PBR)보다 수익률이 높은 현상을 뜻합니다. 가치주 효과가 발생하는 원인은 바로 사람들이 가치주(저밸류에이션)를 기피하고, 성장주(고밸류에이션)를 선호하기 때문입니다. 달리 말하면 사람들이 기피한 주식이 가치주가 되었다고 할 수도 있습니다. 가치주는 일반적으로 차입비율이 높고, 수익의 변동성이 크며, 경기가 좋지 않을 때 더 위험한 경향이 있습니다. 사람들은 이처럼 위험한 주식에 필요 이상으로 과민 반응을 보입니다. 그로 인해 주가가 하락하고 가치주가 되는 것입니다. 반면 인간은 익숙한 것을 안전하다고 착각하는 경향이 있습니다. 최근 성과가 좋은 주식은 여러 매체를 통해 접하기 쉬운데, 이런 주식을 안전하다고 착각해 많은 사람이 매수에 나섭니다. 그로 인해 주가가 상승하고 고평가주가 됩니다. 보고 싶은 것만 보는 확증 편향으로 인해 투자자들은 위험하다고 생각되는 가치주가 망할 것 같은 이유만 찾아 더욱 기피하고, 안전하다고 생각되는 성장주는 영원히 상승할 것 같은 이유만 찾아 더욱 선호합니다. 그러나 가치주가 생각보다 위험하지 않다는 것을, 성장주가 너무 많이 상승해 안전하지 않다는 것을 깨닫는 순간 주가는 원래 수준으로 회귀하기 마련이고, 이로 인해 가치주 효과가 발생합니다.\n\nFrench Library 데이터 불러오기\n파마-프렌치 모형으로 유명한 프렌치 교수가 제공하는 라이브러리에서는 다양한 팩터 데이터를 다운로드 받을 수 있습니다.\nhttps://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n해당 데이터를 분석하기 위해 사이트에 접속하여 데이터를 내려받아 압축을 푼 후 csv 파일을 불러오는 방법 보다는, R 내에서 데이터를 다운로드 받은 후 불러오는 것이 훨씬 효율적입니다. 또한 이미 개발된 패키지를 사용할 경우 이러한 작업을 매우 쉽게 할수도 있습니다.\nhttps://nareal.github.io/frenchdata/articles/basic_usage.html\nR에서 해당 패키지를 사용해 팩터 데이터를 다운로드 받은 후 성과를 확인해보도록 하겠습니다.\n\nlibrary(frenchdata)\ndata_sets = get_french_data_list()\n\ndata_sets$files_list\n\n# A tibble: 297 × 3\n   name                                                file_url          detai…¹\n   <chr>                                               <chr>             <chr>  \n 1 Fama/French 3 Factors                               ftp/F-F_Research… Data_L…\n 2 Fama/French 3 Factors [Weekly]                      ftp/F-F_Research… Data_L…\n 3 Fama/French 3 Factors [Daily]                       ftp/F-F_Research… Data_L…\n 4 Fama/French 5 Factors (2x3)                         ftp/F-F_Research… Data_L…\n 5 Fama/French 5 Factors (2x3) [Daily]                 ftp/F-F_Research… Data_L…\n 6 Portfolios Formed on Size                           ftp/Portfolios_F… Data_L…\n 7 Portfolios Formed on Size [ex.Dividends]            ftp/Portfolios_F… Data_L…\n 8 Portfolios Formed on Size [Daily]                   ftp/Portfolios_F… Data_L…\n 9 Portfolios Formed on Book-to-Market                 ftp/Portfolios_F… Data_L…\n10 Portfolios Formed on Book-to-Market [ex. Dividends] ftp/Portfolios_F… Data_L…\n# … with 287 more rows, and abbreviated variable name ¹​details_url\n\n\n먼저 필요한 패키지들을 불러온 후, get_french_data_list() 함수를 사용해 다운로드 받을 수 있는 데이터를 조회합니다. data_sets의 files_list에는 다운로드 받을 수 있는데 데이터와 해당 url이 표시되어 있습니다. 이 중 우리는 name 컬럼의 데이터 이름을 알면 됩니다. 이 중 밸류에 해당하는 데이터의 이름은 [Portfolios Formed on Book-to-Market] 입니다. B/M에서 B는 장부가치(Book Value), M는 시장가치(Market Value)로써, 이는 PBR의 역수라고 생각해도 됩니다. 즉 해당값이 높을수록 저PBR 주식을 의미합니다. 해당 데이터를 다운로드 받도록 하겠습니다.\n\nff_value = download_french_data('Portfolios Formed on Book-to-Market')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_value$subsets\n\n# A tibble: 8 × 2\n  name                                                    data                \n  <chr>                                                   <list>              \n1 Value Weight Returns -- Monthly                         <spc_tbl_>          \n2 Equal Weight Returns -- Monthly                         <spc_tbl_>          \n3 Value Weight Returns -- Annual from January to December <spc_tbl_ [95 × 20]>\n4 Equal Weight Returns -- Annual from January to December <spc_tbl_ [95 × 20]>\n5 Number of Firms in Portfolios                           <spc_tbl_>          \n6 Average Firm Size                                       <spc_tbl_>          \n7 Sum of BE / Sum of ME                                   <spc_tbl_ [97 × 20]>\n8 Value Weight Average of BE / ME                         <spc_tbl_ [97 × 20]>\n\n\n리스트 중 subsets를 확인해보면 월간수익률(시가총액가중평균, 동일가중평균), 연간수익률(시가총액가중평균, 동일가중평균) 및 기타 데이터가 포함되어 있습니다. 이 중 일반적으로 많이 사용하는 시가총액가중포트폴리오의 월간 수익률 (Value Weighted Returns – Monthly)를 확인해보겠습니다.\n\nff_value_vw = ff_value$subsets$data[[1]]\nhead(ff_value_vw)\n\n# A tibble: 6 × 20\n    date `<= 0` `Lo 30` `Med 40` `Hi 30` `Lo 20` `Qnt 2` `Qnt 3` `Qnt 4` `Hi 20`\n   <dbl>  <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 192607  12.1     5.55     1.86    1.54    3.18    5.41    1.78    2.41    0.6 \n2 192608  -9.73    2.65     2.67    5.61    1       4.01    2.05    4.59    7.1 \n3 192609 -15.2     1.28     0.07   -0.71   -1.04    3.04   -0.29   -0.19   -1.46\n4 192610  -5.63   -3.6     -2.41   -3.55   -2.89   -2.96   -2.2    -4.2    -4.28\n5 192611   5.58    3.13     2.95    2.94    4.12    2.56    1.9     3.96    2.48\n6 192612  -6.13    2.96     2.59    2.52    1.68    3.33    1.82    5.2     2.06\n# … with 10 more variables: `Lo 10` <dbl>, `Dec 2` <dbl>, `Dec 3` <dbl>,\n#   `Dec 4` <dbl>, `Dec 5` <dbl>, `Dec 6` <dbl>, `Dec 7` <dbl>, `Dec 8` <dbl>,\n#   `Dec 9` <dbl>, `Hi 10` <dbl>\n\n\n\n<=0: PBR이 0 이하인 기업들의 포트폴리오\nLo 30, Med 40, Hi 30: PBR 기준 상위 30%, 30-70%, 하위 30%로 나눈 포트폴리오\nLo 20, Qnt 2, Qnt 3, Qnt 4, Hi 20: PBR 기준 상위 20%, 20-40%, 40-60%, 60-80%, 80-100%로 나눈 포트폴리오\nLo 10, Dec 2, Dec 3, …, Dec 9, Hi 19: PBR 기준 상위 10% 씩으로 나눈 포트폴리오\n\n이 중 20%씩 나눈 [Lo 20, Qnt 2, Qnt 3, Qnt 4, Hi 20] 열만 선택하여 누적 수익률을 확인보도록 하겠습니다.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\nLoading required package: timechange\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\ndata_to_plot = function(data) {\n  \n  data %>%\n    mutate(date = as.character(date)) %>%\n    mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n    mutate(across(!date, ~.x / 100)) %>%\n    mutate(across(!date, ~log(1+.x))) %>%\n    mutate(across(!date, ~cumsum(.x))) %>%\n    pivot_longer(-date) %>%\n    mutate(name = factor(name, levels = .$name %>% unique)) %>%\n    ggplot(aes(x = date, y = value, color = name)) +\n    geom_line() +\n    xlab('') +\n    ylab('') +\n    theme_bw() +\n    theme(legend.title=element_blank())\n  \n}\n\n먼저 데이터를 클렌징한 후 그림으로 나타내는 함수를 만듭니다.\n\ndate열을 yyyy-mm-dd로 변경\n해당 데이터에서는 1이 1%를 의미하므로, 올바른 계산을 위해 100으로 나누어 줌\n로그수익률로 치환\ncumsum() 함수를 통해 누적합 계산\npivot_longer() 함수를 통해 형태 변경\nname 열의 순서 지정을 위해 팩터 levels 재설정\n그림으로 나타내기\n\n이제 PBR 기준 5분위 열만 선택한 후 해당 함수를 적용합니다.\n\nff_value_vw %>% select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\nHi 20, 즉 B/M이 높은(PBR이 낮은) 포트폴리오의 누적 수익률이 가장 높으며, B/M이 낮을수록(PBR이 높을수록) 누적 수익률이 낮아집니다.\n\nff_value_vw %>% select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  pivot_longer(-date) %>%\n  mutate(name = factor(name, levels = .$name %>% unique)) %>%\n  ggplot(aes(x = name, y = value)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n박스 플랏을 분석해 보면 PBR이 낮을수록 수익률의 변동성은 크지만, 큰 수익이 나는 경우가 더 많습니다.\n이번에는 고PBR 대비 저PBR 수익률인 HML 팩터의 수익률을 살펴보겠습니다. 흔히 롱숏 모델을 비교할때는 상하위 30% 수익률을 이용합니다.\n\nff_value_vw %>% select(date, `Lo 30`, `Hi 30`) %>%\n  mutate(HML = `Hi 30` - `Lo 30`) %>%\n  select(date, HML) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n1940년 이후 꾸준히 상향하며 저PBR이 고PBR 대비 뛰어난 성과를 기록하였습니다. 반면 2008년 이후 10여년 동안 하락하다가, 2020년을 기점으로 다시 반등하는 모습입니다.\nFrench 라이브러리에서는 PBR외에도 PER나 PCR 팩터의 수익률도 확인할 수 있으며, 미국이 아닌 글로벌 수익률도 확인할 수 있습니다.\n\n\n밸류 포트폴리오 구하기\n가치주에 투자하는 것이 훨씬 수익률이 높다는 점을 확인하였으니, 국내 종목들 중 가치주에는 어떠한 것이 있는 확인해보도록 합니다. 먼저 전통적인 가치지표인 PER와 PBR이 낮은 종목을 선정해보도록 합니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\n\n먼저 DB에서 티커 테이블과 가치지표 테이블을 불러옵니다. 티커는 최신일 기준 및 보통주에 해당하는 종목만 불러오며, 가치지표는 최신일 기준 데이터를 불러옵니다.\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일)\n\nvalue_bind = ticker %>% \n  left_join(value)\n\nJoining, by = \"종목코드\"\n\nvalue_bind %>% head()\n\n  종목코드     종목명 시장구분  종가    시가총액     기준일   EPS 선행EPS\n1   000020   동화약품    KOSPI  8650 2.41607e+11 2022-10-14   647      NA\n2   000040   KR모터스    KOSPI   599 5.75869e+10 2022-10-14    NA      NA\n3   000050       경방    KOSPI 10800 2.96085e+11 2022-10-14   872      NA\n4   000060 메리츠화재    KOSPI 29600 3.36798e+12 2022-10-14  5768    6808\n5   000070 삼양홀딩스    KOSPI 63800 5.46401e+11 2022-10-14 30711      NA\n6   000080 하이트진로    KOSPI 24650 1.72879e+12 2022-10-14  1031    1984\n     BPS 주당배당금 종목구분     DY    PBR    PCR     PER    PSR\n1  12534        180   보통주 0.0208 0.6718 5.7117 12.5185 0.7600\n2    385          0   보통주     NA 1.1705     NA      NA 0.4359\n3  30033        125   보통주 0.0116 0.3900 4.7602 15.1838 0.7365\n4  22086        620   보통주 0.0209 1.8143 2.7349  4.1457     NA\n5 226314       3000   보통주 0.0470 0.2223 3.3317  2.8518 0.1653\n6  15657        800   보통주 0.0325 1.5829 4.2258 18.0647 0.7408\n\n\n\n일부 종목은 가치지표가 0보다 작은 경우(예: 적자기업의 경우 PER가 음수, 혹은 배당수익률이 0%인 종목)가 있으며 이러한 데이터는 NA로 변경합니다.\n테이블을 가로로 긴 형태로 변경합니다.\n두 테이블을 합칩니다.\n\n이제 PER와 PBR이 낮은 종목을 찾아보도록 합니다.\n\nvalue_bind %>%\n  mutate(across(c(PBR, PER), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank = min_rank(rank_PBR + rank_PER)) %>%\n  filter(rank <= 20) \n\n   종목코드           종목명 시장구분   종가    시가총액     기준일   EPS\n1    000880             한화    KOSPI  24000 1.79901e+12 2022-10-14  9781\n2    001390         KG케미칼    KOSPI  21450 2.97428e+11 2022-10-14  5749\n3    001940      KISCO홀딩스    KOSPI  12150 1.96543e+11 2022-10-14  8106\n4    002030           아세아    KOSPI 110500 2.42108e+11 2022-10-14 56785\n5    003380         하림지주   KOSDAQ   6630 7.42597e+11 2022-10-14  4129\n6    006200   한국전자홀딩스    KOSPI   1155 5.40576e+10 2022-10-14   531\n7    007860             서연    KOSPI   5270 1.23739e+11 2022-10-14  1091\n8    008060             대덕    KOSPI   5990 2.03002e+11 2022-10-14    NA\n9    009970   영원무역홀딩스    KOSPI  51200 6.98142e+11 2022-10-14 19026\n10   023590         다우기술    KOSPI  17150 7.69463e+11 2022-10-14  8693\n11   032190       다우데이타   KOSDAQ  13850 5.30455e+11 2022-10-14  3838\n12   037400 우리엔터프라이즈   KOSDAQ   2220 5.82158e+10 2022-10-14   899\n13   052300     초록뱀컴퍼니   KOSDAQ    570 6.55956e+10 2022-10-14   942\n14   088350         한화생명    KOSPI   2020 1.75443e+12 2022-10-14  1455\n15   090740       연이비앤티   KOSDAQ     75 1.68446e+09 2022-10-14  1328\n16   101360         이엔드디   KOSDAQ  26000 2.75825e+11 2022-10-14   992\n17   106240     파인테크닉스   KOSDAQ   2190 3.48715e+10 2022-10-14   983\n18   139480           이마트    KOSPI  84900 2.36666e+12 2022-10-14 56152\n19   151860           KG ETS   KOSDAQ   8410 3.02760e+11 2022-10-14  1389\n20   296640         이노룰스   KOSDAQ  19850 1.02064e+11 2022-10-14   813\n   선행EPS    BPS 주당배당금 종목구분     DY    PBR    PCR    PER    PSR\n1     8821  52527        750   보통주 0.0312 0.0943 0.3589 0.9098 0.0323\n2       NA  34343        500   보통주 0.0233 0.1539 1.1798 0.5282 0.0531\n3       NA  68463        400   보통주 0.0329 0.1393 4.7589 1.2965 0.1053\n4       NA 491013       3000   보통주 0.0271 0.1407 1.2185 1.3473 0.1211\n5       NA  27945        100   보통주 0.0151 0.1684 0.6366 1.0822 0.0572\n6       NA   2900          0   보통주     NA 0.1777 1.2175 1.5314 0.1492\n7       NA  21587        100   보통주 0.0190 0.1320 0.4529 1.9579 0.0451\n8       NA  16976        300   보통주 0.0501 0.1455 0.6002 1.6945 0.1296\n9    22866 140307       2000   보통주 0.0391 0.2158 1.7153 1.0987 0.1846\n10      NA  45679        600   보통주 0.0350 0.1673     NA 1.1148 0.0962\n11      NA  24053        300   보통주 0.0217 0.1085     NA 0.7750 0.0619\n12      NA   4170          0   보통주     NA 0.2277 0.9153 1.0267 0.0375\n13      NA   2655          0   보통주     NA 0.1442 3.9515 1.1137 0.3827\n14     556  15004          0   보통주     NA 0.1488 0.4769 1.5061     NA\n15      NA   2489          0   보통주     NA 0.0363 0.3584 0.0952 0.0148\n16      NA   7068          0   보통주     NA 0.1615 0.1615 0.1615 0.1615\n17      NA   2512         25   보통주 0.0114 0.2265 0.7647 0.6086 0.0716\n18   14456 369202       2000   보통주 0.0236 0.1873 3.6898 1.3550 0.0866\n19      NA   8862        120   보통주 0.0143 0.2211 4.0584 0.6047 0.0734\n20      NA   3492         25   보통주 0.0013 0.2438     NA 0.2438 0.2438\n   rank_PBR rank_PER rank\n1         3       38    5\n2        20       12    3\n3        11       65    7\n4        12       68    9\n5        31       45    7\n6        36       79   17\n7         9      117   20\n8        17       93   15\n9        65       48   16\n10       30       50    9\n11        5       31    4\n12       76       43   19\n13       16       49    6\n14       19       76   14\n15        1        1    1\n16       26        2    2\n17       73       18   12\n18       47       70   18\n19       67       17   11\n20       89        3   13\n\n  # select(종목코드, 종목명, PBR, PER)\n\n\nmin_rank() 함수를 통해 PER와 PBR 열의 순위를 구하며, rank_열 이름으로 저장합니다.\n앞서 구한 두 열을 합한 후 다시 순위를 구합니다.\n순위가 낮은 20종목을 선택합니다. 이는 PER와 PBR이 낮은 종목이라고 볼 수 있습니다.\n\n\n\n여러 지표 결합하기\n이번에는 가치지표에 해당하는 모든 지표, 즉 PER, PBR, PCR, PSR, DY를 고려한 밸류 포트폴리오를 만들어보도록 하겠다. 먼저 각 지표 별 상관관계를 살펴보도록 합니다.\n\nvalue_bind_rank = value_bind %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\nvalue_bind_rank %>%\n  select(contains('rank')) %>%\n  cor(., use = 'complete.obs') %>%\n  round(., 2)\n\n         rank_PBR rank_PER rank_PCR rank_PSR rank_DY\nrank_PBR     1.00     0.49     0.42     0.74    0.41\nrank_PER     0.49     1.00     0.53     0.50    0.33\nrank_PCR     0.42     0.53     1.00     0.46    0.26\nrank_PSR     0.74     0.50     0.46     1.00    0.36\nrank_DY      0.41     0.33     0.26     0.36    1.00\n\n\nPER, PBR, PCR, PSR의 경우 값이 낮을수록 가치주에 해당하지만, DY의 경우 값이 높을수록 배당수익률이 높은 가치주에 해당한다. 따라서 DY는 desc() 함수를 통해 내림차순으로 순위를 매겨줍니다. 비슷한 가치지표임에도 불구하고 서로 간의 상관관계가 꽤 낮은 지표도 있습니다. 따라서 지표를 통합적으로 고려하면 분산효과를 기대할 수도 있습니다.\n\nvalue_bind_rank %>%\n  mutate(rank_sum = rowSums(across(contains('rank')))) %>%\n  mutate(rank_final = min_rank(rank_sum)) %>%\n  filter(rank_final <= 20) \n\n   종목코드           종목명 시장구분   종가    시가총액     기준일   EPS\n1    000140 하이트진로홀딩스    KOSPI  10050 2.33228e+11 2022-10-14  1529\n2    000880             한화    KOSPI  24000 1.79901e+12 2022-10-14  9781\n3    001040               CJ    KOSPI  71200 2.07740e+12 2022-10-14  8197\n4    001390         KG케미칼    KOSPI  21450 2.97428e+11 2022-10-14  5749\n5    002030           아세아    KOSPI 110500 2.42108e+11 2022-10-14 56785\n6    002990         금호건설    KOSPI   7300 2.69761e+11 2022-10-14  4130\n7    003300       한일홀딩스    KOSPI  10250 3.16037e+11 2022-10-14  1462\n8    005990       매일홀딩스   KOSDAQ   7130 9.78115e+10 2022-10-14  3575\n9    007860             서연    KOSPI   5270 1.23739e+11 2022-10-14  1091\n10   008060             대덕    KOSPI   5990 2.03002e+11 2022-10-14    NA\n11   009410         태영건설    KOSPI   4580 1.78158e+11 2022-10-14  1920\n12   009970   영원무역홀딩스    KOSPI  51200 6.98142e+11 2022-10-14 19026\n13   010100       한국프랜지    KOSPI   2220 6.75999e+10 2022-10-14   612\n14   013580         계룡건설    KOSPI  17600 1.57184e+11 2022-10-14 17601\n15   016450 한세예스24홀딩스    KOSPI   4190 1.67600e+11 2022-10-14  1026\n16   034730               SK    KOSPI 206000 1.52748e+13 2022-10-14 37408\n17   036530        SNT홀딩스    KOSPI  13900 2.26624e+11 2022-10-14  5329\n18   078930               GS    KOSPI  45950 4.26946e+12 2022-10-14 15304\n19   092230        KPX홀딩스    KOSPI  52700 2.22639e+11 2022-10-14 11573\n20   267290     경동도시가스    KOSPI  20050 1.18203e+11 2022-10-14  3756\n   선행EPS    BPS 주당배당금 종목구분     DY    PBR    PCR    PER    PSR\n1       NA  23538        450   보통주 0.0448 0.2128 0.5890 2.6030 0.1004\n2     8821  52527        750   보통주 0.0312 0.0943 0.3589 0.9098 0.0323\n3    12727 151085       2300   보통주 0.0323 0.1244 0.7088 2.4128 0.0553\n4       NA  34343        500   보통주 0.0233 0.1539 1.1798 0.5282 0.0531\n5       NA 491013       3000   보통주 0.0271 0.1407 1.2185 1.3473 0.1211\n6     2203  18202        800   보통주 0.1096 0.4132 2.0671 2.8100 0.1295\n7       NA  44782        550   보통주 0.0537 0.1627 3.6368 2.9509 0.1634\n8       NA  26268        150   보통주 0.0210 0.1473 0.8296 2.3741 0.0521\n9       NA  21587        100   보통주 0.0190 0.1320 0.4529 1.9579 0.0451\n10      NA  16976        300   보통주 0.0501 0.1455 0.6002 1.6945 0.1296\n11      NA  17753        350   보통주 0.0764 0.2518 0.6446 4.2419 0.0627\n12   22866 140307       2000   보통주 0.0391 0.2158 1.7153 1.0987 0.1846\n13      NA   8412         90   보통주 0.0405 0.2529 1.8270 3.1296 0.0589\n14   14985  78914        800   보통주 0.0455 0.2109 2.6687 1.3527 0.0564\n15      NA  12066        250   보통주 0.0597 0.1796 4.0581 2.9611 0.0522\n16   34166 375047       8000   보통주 0.0388 0.2290 1.7970 1.7034 0.1304\n17      NA  65710        700   보통주 0.0504 0.1274 2.6537 2.1604 0.1669\n18   19446 108672       2000   보통주 0.0435 0.2967 2.3272 1.7018 0.1657\n19      NA 208904       3000   보통주 0.0569 0.1607 3.7481 2.9179 0.1744\n20      NA  63687        875   보통주 0.0436 0.3095 1.0442 3.9533 0.0632\n   rank_PBR rank_PER rank_PCR rank_PSR rank_DY rank_sum rank_final\n1        60      170       20       83     179      512          3\n2         3       38        7        4     364      416          2\n3         7      144       31       21     348      551          6\n4        20       12       69       20     510      631          7\n5        12       68       74      117     423      694         12\n6       316      195      136      126      12      785         18\n7        28      216      283      184     115      826         19\n8        18      140       45       17     556      776         15\n9         9      117       12       10     611      759         14\n10       17       93       21      127     131      389          1\n11       99      347       25       33      44      548          5\n12       65       48      112      218     247      690         11\n13      100      240      120       28     231      719         13\n14       58       69      197       22     169      515          4\n15       39      217      320       18      78      672          9\n16       77       95      117      129     254      672          9\n17        8      125      196      191     130      650          8\n18      146       94      155      190     198      783         17\n19       25      213      291      205      92      826         19\n20      161      326       58       34     197      776         15"
  },
  {
    "objectID": "portfolio.html#모멘텀-전략",
    "href": "portfolio.html#모멘텀-전략",
    "title": "포트폴리오 구성하기",
    "section": "모멘텀 전략",
    "text": "모멘텀 전략\n투자에서 모멘텀이란 주가 혹은 이익의 추세로서, 상승 추세의 주식은 지속적으로 상승하며 하락 추세의 주식은 지속적으로 하락하는 현상을 말합니다. 모멘텀의 종류는 크게 기업의 이익에 대한 추세를 나타내는 이익 모멘텀과 주가의 모멘텀에 대한 가격 모멘텀이 있으며, 이 중에서 3개월에서 12개월 가격 모멘텀을 흔히 모멘텀이라고 합니다. 즉 과거 12개월 수익률이 높았던 종목이 계속해서 상승하는 현상을 모멘텀이라 합니다.\n모멘텀 효과가 발생하는 이유는 기업의 가치 변화에 대한 사람들의 반응 때문입니다. 기업의 이익이 증가하면 내재가치(펀더멘털 가치) 역시 증가하고, 이러한 가치는 즉각적으로 변합니다. 반면 주식의 가격은 늘 새로운 정보에 반응해 상승하기는 하지만, 초기에는 이익에 대한 과소 반응으로 인해 상승폭이 낮으며 그 이후 계속해서 상승합니다. 주식의 가격이 가치에 수렴하기 위해 상승하다 보면 투자자들의 주목을 끌기 마련이며, 양떼 효과로 인해 따라서 투자하는 이들이 많아집니다. 그 결과, 과잉 반응이 발생해 주가는 계속해서 상승하며 모멘텀 효과가 발생합니다. 그러나 투자자들이 기업의 가치에 비해 주가가 너무 비싸졌다고 판단하는 순간 주가는 하락하기 시작하며 반전이 이루어집니다.\n\n\n\n\n\n\n모멘텀별 포트폴리오의 수익률\n프렌치 라이브러리 데이터를 이용해 최근 12개월 수익률을 기준으로 구성된 포트폴리오의 수익률을 비교해보겠습니다.\n\nlibrary(frenchdata)\nff_mom = download_french_data('10 Portfolios Formed on Momentum')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_mom_vw = ff_mom$subsets$data[[1]]\nff_mom_vw %>% data_to_plot() + scale_colour_manual(values = rainbow(10))\n\n\n\n\n\n\n\n\n모멘텀별 포트폴리오의 누적수익률을 확인해보면, 최근 12개월 수익률이 높을수록(Hi PRIOR) 향후에도 지속적으로 수익률이 높으며, 최근 12월 수익률이 낮을수록(Lo PRIOR) 향후에도 수익률이 낮은 ’모멘텀 현상’이 존재합니다. 이번에는 저모멘텀 대비 고모멘텀 수익률인 UMD 팩터의 수익률을 살펴보겠습니다.\n\nff_umd = download_french_data('Momentum Factor (Mom)')\n\nNew names:\nNew names:\n• `` -> `...1`\n\nff_umd$subsets$data[[1]] %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n장기적으로 우상향 하는 모습을 보이지만 시장이 급락한 이후 반등할 때 모멘텀 팩터가 무너지는 현상이 발생하며, 이를 ’모멘텀 크래쉬’라 합니다.\n\n\n모멘텀 포트폴리오 구하기\n최근 12개월 수익률이 높은 주식에 투자하는 것이 훨씬 수익률이 높다는 점을 확인하였으니, 국내 종목들 중 모멘텀 주식에는 어떠한 것이 있는 확인해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\n\n먼저 티커 테이블과 가격 테이블을 불러옵니다. 가격 테이블은 최근 1년에 해당하는 데이터만 불러옵니다.\n가격 테이블에서 종목코드 별로 그룹을 묶습니다.\n최근 종가를 1년전 종가로 나누어 1년간의 수익률을 계산합니다.\n\n이제 12개월 수익률이 높은 종목을 찾아보도록 합니다.\n\nmomentum_bind = ret_1yr %>% mutate(rank = min_rank(desc(ret))) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker)\n\nJoining, by = \"종목코드\"\n\nmomentum_bind\n\n# A tibble: 20 × 13\n   종목…¹   ret  rank 종목명  시장…²   종가 시가총액 기준일   EPS 선행EPS    BPS\n   <chr>  <dbl> <int> <chr>   <chr>   <dbl>    <dbl> <chr>  <dbl>   <dbl>  <dbl>\n 1 001570  2.47     5 금양    KOSPI   18650  1.08e12 2022-…   295      NA   2530\n 2 003610  1.38    15 방림    KOSPI    5780  2.45e11 2022-…   191      NA   5145\n 3 004690  1.83     8 삼천리  KOSPI  272500  1.10e12 2022-… 17385      NA 392735\n 4 005860  1.95     7 한일사… KOSDAQ   6260  2.47e11 2022-…   183      NA   1751\n 5 016710  1.41    14 대성홀… KOSPI   93400  1.50e12 2022-…  1040      NA  29257\n 6 016790  5.17     2 카나리… KOSDAQ  21100  9.38e11 2022-…    NA      NA   1876\n 7 025770  1.01    20 한국정… KOSDAQ  13350  5.00e11 2022-…   295      NA   6019\n 8 030960  2.99     3 양지사  KOSDAQ  43100  6.89e11 2022-…    96      NA  13794\n 9 043090  1.13    17 한창바… KOSDAQ   4270  1.88e11 2022-…    NA      NA    881\n10 052020  2.02     6 에스티… KOSDAQ  24750  1.07e12 2022-…    NA      NA    460\n11 053690  1.41    13 한미글… KOSPI   31400  3.44e11 2022-…  1537    2266  14014\n12 079810  1.04    19 디이엔… KOSDAQ  10200  1.57e11 2022-…    62     886   1711\n13 090710  1.55    11 휴림로… KOSDAQ   2150  3.52e11 2022-…    NA      NA    443\n14 095500  2.82     4 미래나… KOSDAQ  14950  4.64e11 2022-…   940      NA   8392\n15 101670  6.87     1 코리아… KOSDAQ  15500  2.98e11 2022-…    NA      NA   1470\n16 179290  1.58    10 엠아이… KOSDAQ  13050  4.19e11 2022-…   392     968   2081\n17 249420  1.05    18 일동제… KOSPI   26800  7.18e11 2022-…    NA      NA   6429\n18 322000  1.49    12 현대에… KOSPI   56400  6.32e11 2022-…    NA    5743  28600\n19 366030  1.26    16 공구우… KOSDAQ   7140  1.57e11 2022-…   581      NA   1797\n20 373200  1.75     9 하인크… KOSDAQ   5410  1.02e11 2022-…    NA      NA   1872\n# … with 2 more variables: 주당배당금 <dbl>, 종목구분 <chr>, and abbreviated\n#   variable names ¹​종목코드, ²​시장구분\n\n\nmin_rank() 함수를 통해 수익률의 순위를 구하며, 모멘텀의 경우 지표가 높을수록 좋으므로 desc() 함수를 통해 내림차순으로 순위를 구합니다. 마지막으로 해당 종목들의 가격 그래프를 확인해보도록 하겠습니다.\n\nprice %>% filter(종목코드 %in% (momentum_bind %>% select(종목코드) %>% pull())) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  ggplot(aes(x = as.Date(날짜), y = 종가)) +\n  geom_line() +\n  facet_wrap(. ~종목코드, scales = 'free') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme(axis.text.x=element_blank())\n\n\n\n\n\n\n\n\n\n\nK-Ratio\n12개월 수익률 기준 모멘텀 종목들의 주가 그래프를 보면 단순히 수익률 만으로 종목을 선택할 경우 다음과 같은 종목 또한 포함됩니다.\n\n장기간 수익률이 횡보하다가 최근 주가가 급등하여 누적수익률 역시 높게 나타나는 종목\n이미 몇달전에 주가가 급등한 후 최근에는 하락세이지만, 누적수익률 자체는 높게 나타나는 종목\n\n반면 좋은 모멘텀 주식이란 단순히 많이 상승한 것이 아닌, 꾸준하게 상승하는 종목이다. 하나의 예를 살펴봅시다.\n\n\n\n\n\n동일한 누적수익률을 가진 두 종목이 있다고 가정해봅시다. A의 경우 상승폭이 작다가 최근 급등하여 누적수익률이 높아진 경우입니다. 반면 B의 경우 꾸준하게 상승하여 누적수익률이 높아진 경우입니다. 이 중 꾸준하게 상승한 B가 더 뛰어난 모멘텀 주식이라고 볼 수 있습니다. 이처럼 꾸준한 상승을 측정하기 위해 실무에서는 단순 12개월 수익률이 아닌 3~12개월 수익률을 같이 보거나, 변동성을 함께 고려하기도 합니다. 그 중 모멘텀의 꾸준함을 측정하는 지표 중 하나가 ’K-Ratio’입니다. 해당 지표는 다음과 같습니다.\n\\[K-Ratio = \\frac{누적수익률의\\ 기울기}{표준\\ 오차}\\] 누적수익률이 높을수록 기울기도 커져 분자는 커집니다. 또한 추세가 꾸준할수록 표준 오차가 작아 분모는 작아집니다. 따라서 추세가 꾸준하게 많이 상승할수록 K-Ratio는 증가합니다. 먼저 K-Ratio를 측정하는 법을 살펴봅시다.\n\nlibrary(tidyr)\nlibrary(broom)\n\ntbl = price %>% filter(종목코드 == '005930') %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number()) \n\nreg = lm(cumret ~ id, data = tbl)\nsummary(reg)\n\n\nCall:\nlm(formula = cumret ~ id, data = tbl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.11585 -0.02906  0.01277  0.03074  0.08558 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.200e-01  6.377e-03   18.82   <2e-16 ***\nid          -1.396e-03  4.458e-05  -31.31   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04996 on 245 degrees of freedom\nMultiple R-squared:  0.8001,    Adjusted R-squared:  0.7993 \nF-statistic: 980.5 on 1 and 245 DF,  p-value: < 2.2e-16\n\n\n\n먼저 삼성전자에 해당하는 데이터만 뽑아 수익률을 계산합니다.\n로그수익률로 변경한 후 로그 누적수익률을 계산합니다.\nrow_number() 함수를 통해 순서를 입력합니다.\nlm() 함수를 통해 \\(x\\) 축에는 기간, \\(y\\) 축에는 로그 누적수익률로 회귀분석을 실행합니한다.\n\n결과표의 ’Estimate’는 기울기를, ’std err’는 표준 오차를 나타냅니다.\n\ncat(coef(summary(reg))[2, 1],\n    coef(summary(reg))[2, 2],\n    coef(summary(reg))[2, 1] / coef(summary(reg))[2, 2]\n)\n\n-0.001395999 4.458329e-05 -31.31215\n\n\n기울기와 표준오차를 추출한 후, 이 두개를 나눈 값이 K-Ratio 입니다. 이를 이용해 모든 종목의 K-Ratio를 계산하도록 하겠습니다.\n\nlibrary(purrr)\nlibrary(broom)\n\nstep_1 = price %>%\n  group_by(종목코드) %>%\n  filter(n() >= 200) %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number()) \n\nstep_2 = step_1 %>% \n  ungroup() %>%\n  nest(data = -종목코드) %>%\n  mutate(model = map(data, ~lm(cumret~id, data = .)),\n         tidied = map(model, tidy))\n\nk_ratio = step_2 %>%\n  unnest(tidied) %>%\n  filter(term == 'id') %>%\n  mutate(k_ratio = estimate / `std.error`) \n\n# k_ratio = price %>%\n#   group_by(종목코드) %>%\n#   filter(n() == t) %>%\n#   mutate(ret = 종가 / lag(종가) - 1) %>%\n#   mutate(ret = log(1+ret)) %>%\n#   slice(-1) %>%\n#   mutate(cumret = cumsum(ret)) %>%\n#   mutate(id = row_number()) %>%\n#   do({model = lm(cumret ~ id, data = .);\n#        data.frame(slope =  coef(summary(model))[2, 1], std_err =coef(summary(model))[2, 2])}) %>%\n#   mutate(k_ratio = slope / std_err) %>%\n#   ungroup()\n\n\n상장한지 200일 이상 된 종목만 선택합니다.\n수익률을 계산합니다.\nK-Ratio를 구합니다.\n\n이를 토대로 K-Ratio 상위 종목을 구해보겠습니다.\n\nk_bind = k_ratio %>% mutate(rank = min_rank(desc(k_ratio))) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker)\n\nJoining, by = \"종목코드\"\n\nprice %>% filter(종목코드 %in% (k_bind %>% select(종목코드) %>% pull())) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  ggplot(aes(x = as.Date(날짜), y = 종가)) +\n  geom_line() +\n  facet_wrap(. ~종목코드, scales = 'free') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme(axis.text.x=element_blank())\n\n\n\n\n\n\n\n\n기존 단순 모멘텀이 비해 훨씬 더 꾸준하게 우상향하는 종목들이 선택되었습니다."
  },
  {
    "objectID": "portfolio.html#퀄리티-전략",
    "href": "portfolio.html#퀄리티-전략",
    "title": "포트폴리오 구성하기",
    "section": "퀄리티 전략",
    "text": "퀄리티 전략\n벤자민 그레이엄 이후 유지되고 있는 기본적 분석 혹은 가치 투자자들의 가장 중요한 투자 지표 중 하나는 기업의 우량성(퀄리티)입니다. 벤저민 그레이엄은 종목 선정에 있어 유동 자산이 풍부하여 재무적으로 건전하고, 꾸준하게 이익을 달성하는 기업을 강조했습니다. 최고의 투자자로 꼽히는 워런 버핏의 종목 선정 기준 역시 실적의 강력한 성장 추세와 높은 자기자본 이익률로 알려져 있습니다.\n그러나 어떠한 지표가 기업의 우량성을 나타내는지 한 마디로 정의하기에는 너무나 주관적이고 광범위해 쉽지 않습니다. 연구에 따르면 수익성, 성장성, 안정성이 높을 주식일수록 수익률이 높은 경향이 있습니다. 이 외에도 학계 혹은 업계에서 사용되는 우량성 관련 지표는 다음과 같이 요약할 수 있습니다.\n\n수익성: 기업이 돈을 얼마나 잘 버는가(ROE, ROA, 매출총이익률 등).\n수익의 안정성: 기업이 얼마나 안정적으로 돈을 버는가(ROE의 변동성 등).\n재무 구조: 기업의 재무 구조가 얼마나 안전한가(차입비율 등).\n이익의 성장: 기업의 이익 증가율이 얼마나 되는가(전년 대비 ROE 증가율 등).\n재무 신뢰도: 재무제표를 얼마나 신뢰할 수 있는가(회계 처리 방법 등).\n배당: 얼마나 주주 친화적인가(배당금, 신주발행, 자사주 매입 등.)\n투자: 얼마나 신사업에 투자를 하는가(총자산의 증가 등)\n\n이 중 사람들이 가장 중요하게 여기는 것은 바로 수익성입니다. 돈을 벌지 못하는 기업은 지속될 수 없기 때문입니다. 기업의 규모가 크면 당연히 돈을 더 많이 벌기 때문에 단순히 수익의 양이 아닌, 기업의 규모에 비해 얼마를 버는지 표준화를 통해 비교해야 합니다.\n\n\n\n지표\n설명\n분자\n분모\n\n\n\n\nROE\n자기자본이익률\n당기순이익\n자본\n\n\nROA\n총자산이익률\n당기순이익\n자산\n\n\nROIC\n투하자본이익률\n당기순이익\n투하자본\n\n\nGP\n매출총이익률\n매출총이익\n자산 혹은 자본\n\n\n\n우량주 효과가 발생하는 이유 역시 사람들의 반응과 관계가 있습니다. 기업의 수익성이 높을 경우, 투자자들은 이익이 다시 원래 수준으로 빠르게 돌아갈 것이라 생각하지만, 실제로는 수익성이 높은 기업은 계속해서 높은 수익성을 보이는 경향이 있습니다. 반대로 기업의 수익성이 낮은 경우, 투자자들은 이익이 반등할 것이라 생각하지만 나쁜 기업은 계속해서 나쁜 경향이 있습니다.\n\n수익성별 포트폴리오의 수익률\n프렌치 라이브러리 데이터를 이용해 영업수익성을 기준으로 구성된 포트폴리오의 수익률을 비교해보겠습니다.\n\nff_op = download_french_data('Portfolios Formed on Operating Profitability')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_op_vw = ff_op$subsets$data[[1]]\nff_op_vw %>%select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n누적수익률을 확인해보면 수익성이 높을수록(Hi 20) 향후에도 지속적으로 수익률이 높으며, 수익성이 낮을수록(Lo 20) 향후에도 수익률이 낮은 ’퀄리티 현상’이 존재합니다. 이번에는 저수익성 대비 고수익성 수익률인 QMJ 팩터의 수익률을 살펴보겠습니다.\n\nff_op_vw %>%\n  select(date, `Lo 30`, `Hi 30`) %>%\n  mutate(QMJ = `Hi 30` - `Lo 30`) %>%\n  select(date, QMJ) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n역시나 장기간 우상향하는 모습입니다.\n\n\n우량성 포트폴리오 구하기\n이번에는 국내 종목들 중 우량성(수익성)이 높은 종믁은 어떠한 것이 있는지 확인해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\nlibrary(RcppRoll)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nfs = dbGetQuery(con ,\n\"select * from kor_fs\nwhere 계정 in ('당기순이익', '매출총이익', '영업활동으로인한현금흐름', '자산', '자본')\nand 공시구분 = 'q';\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nfs_roll = fs %>% arrange(종목코드, 계정, 기준일) %>%\n  group_by(종목코드, 계정) %>%\n  mutate(rollsum = roll_sum(값, n = 4, align = 'right', fill = NA)) %>%\n  slice(n()) %>%\n  mutate(rollsum = case_when(\n    계정 %in% c('자본', '자산') ~ rollsum / 4,\n    TRUE ~ rollsum\n  )) %>%\n  ungroup()\n\nfs_roll\n\n# A tibble: 11,384 × 6\n   계정                     기준일        값 종목코드 공시구분 rollsum\n   <chr>                    <chr>      <dbl> <chr>    <chr>      <dbl>\n 1 당기순이익               2022-06-30    65 000020   q           193 \n 2 매출총이익               2022-06-30   468 000020   q          1666 \n 3 영업활동으로인한현금흐름 2022-06-30    48 000020   q           423 \n 4 자본                     2022-06-30  3652 000020   q          3596.\n 5 자산                     2022-06-30  4639 000020   q          4549 \n 6 당기순이익               2022-06-30    12 000040   q          -104 \n 7 매출총이익               2022-06-30    42 000040   q           158 \n 8 영업활동으로인한현금흐름 2022-06-30    -2 000040   q          -130 \n 9 자본                     2022-06-30   479 000040   q           492 \n10 자산                     2022-06-30  1640 000040   q          1698.\n# … with 11,374 more rows\n\n\n\n티커와 재무제표 테이블을 가져오고, 수익성을 계산하는데 필요한 계정(당기순이익, 매출총이익, 영업활동으로인한현금흐름, 자산, 자본 / 분기 데이터)을 불러옵니다.\n종목코드와 계정별로 그룹을 묶은 후, roll_sum() 함수를 이용해 최근 4분기 데이터의 합을 구합니다.\nslice(n()) 함수를 통해 그룹에서 가장 최근 데이터만 선택합니다.\n자산과 자본의 경우 재무상태표 항목이므로 합이 아닌 평균을 구하며, 나머지 항목은 합을 그대로 사용합니다.\n\n이제 각종 수익성 지표를 계산하겠습니다.\n\nfs_roll_pivot = fs_roll %>% select(계정, 종목코드, rollsum) %>%\n  pivot_wider(names_from = 계정, values_from = rollsum) %>%\n  mutate(ROE = 당기순이익 / 자본,\n         GPA = 매출총이익 / 자산,\n         CFO = 영업활동으로인한현금흐름 / 자산)\n\n마지막으로 수익성 지표의 순위를 구한 후, 상위 20 종목을 선택합니다.\n\nfs_roll_pivot %>%\n  mutate(across(c(ROE, GPA, CFO), .fns = ~rank(desc(.)), .names = \"rank_{col}\")) %>%\n  mutate(rank = rank(rank_ROE + rank_GPA + rank_CFO)) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker) %>%\n  select(종목명, 종목코드, ROE, GPA, CFO)\n\nJoining, by = \"종목코드\"\n\n\n# A tibble: 20 × 5\n   종목명           종목코드   ROE   GPA   CFO\n   <chr>            <chr>    <dbl> <dbl> <dbl>\n 1 DB하이텍         000990   0.447 0.495 0.339\n 2 HMM              011200   0.905 0.574 0.570\n 3 엠게임           058630   0.266 0.703 0.226\n 4 아프리카TV       067160   0.358 0.739 0.305\n 5 랩지노믹스       084650   0.520 0.649 0.386\n 6 이크레더블       092130   0.285 0.647 0.259\n 7 씨젠             096530   0.402 0.606 0.390\n 8 위메이드맥스     101730   0.349 0.776 0.260\n 9 LX세미콘         108320   0.435 0.642 0.281\n10 에스디바이오센서 137310   0.466 0.482 0.301\n11 파수             150900   0.330 0.699 0.387\n12 휴마시스         205470   1.32  1.17  0.932\n13 골프존           215000   0.343 0.674 0.295\n14 삼양옵틱스       225190   0.348 0.554 0.263\n15 수젠텍           253840   0.670 0.574 0.371\n16 제이시스메디칼   287410   0.555 0.882 0.258\n17 비올             335890   0.291 0.545 0.32 \n18 넥스틴           348210   0.439 0.640 0.239\n19 원티드랩         376980   0.259 0.903 0.269\n20 F&F              383220   0.654 1.01  0.315"
  },
  {
    "objectID": "portfolio.html#섹터-중립-포트폴리오",
    "href": "portfolio.html#섹터-중립-포트폴리오",
    "title": "포트폴리오 구성하기",
    "section": "섹터 중립 포트폴리오",
    "text": "섹터 중립 포트폴리오\n팩터 전략의 단점 중 하나는 선택된 종목들이 특정 섹터로 쏠리는 경우가 있다는 점입니다. 특히 과거 수익률을 토대로 종목을 선정하는 모멘텀 전략은 특정 섹터의 호황기에 동일한 섹터의 모든 종목이 함께 움직이는 경향이 있어 이러한 쏠림이 심할 수 있습니다.\n실제 연구 결과를 살펴보아도 섹터 중립 포트폴리오의 수익률이 일반적인 포트폴리오의 수익률 보다 높습니다.\n\n\n\n\n\n먼저 12개월 모멘텀을 이용한 포트폴리오 구성 방법을 다시 살펴봅시다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nsector = dbGetQuery(con,\n                    \"select * from kor_sector\nwhere 기준일 = (select max(기준일) from kor_sector);\"\n)\n                  \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\nret_1yr %>% mutate(rank = min_rank(desc(ret))) %>%\n  filter(rank <= 20) %>%\n  left_join(sector, by = (c(\"종목코드\" = \"CMP_CD\"))) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  arrange(n) %>%\n  mutate(SEC_NM_KOR = factor(SEC_NM_KOR, levels = .$SEC_NM_KOR %>% unique)) %>%\n  ggplot(aes(x = SEC_NM_KOR, y = n)) +\n  geom_col() +\n  geom_text(aes(label = n, hjust = -1)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n12개월 기준 모멘텀 상위 종목을 선택한 후, 섹터 테이블을 이용해 섹터별 갯수를 구합니다. 간혹 특정 섹터의 모멘텀이 매우 좋을 경우, 해당 섹터에 쏠림이 심한 경우가 있습니다. 이러한 섹터 쏠림 현상을 제거한 섹터 중립 포트폴리오를 구성해보도록 하겠습니다.\n\nret_1yr_neutral = ret_1yr %>%\n  left_join(sector, by = (c(\"종목코드\" = \"CMP_CD\"))) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(scale_per_sector = scale(ret),\n         scale_per_sector = ifelse(is.na(`SEC_NM_KOR`),\n                                   NA, scale_per_sector)) %>%\n  ungroup()\n         \nhead(ret_1yr_neutral)\n\n# A tibble: 6 × 7\n  종목코드     ret IDX_CD CMP_KOR    SEC_NM_KOR     기준일     scale_per_sector\n  <chr>      <dbl> <chr>  <chr>      <chr>          <chr>                 <dbl>\n1 000020   -0.493  G35    동화약품   건강관리       2022-10-14           -0.572\n2 000040   -0.399  G25    KR모터스   경기관련소비재 2022-10-14           -0.342\n3 000050   -0.159  G25    경방       경기관련소비재 2022-10-14            0.523\n4 000060    0.0549 G40    메리츠화재 금융           2022-10-14            1.82 \n5 000070   -0.412  G30    삼양홀딩스 필수소비재     2022-10-14           -0.422\n6 000080   -0.299  G30    하이트진로 필수소비재     2022-10-14           -0.238\n\n\n\ngroup_by() 함수를 통해 섹터별 그룹을 만들어줍니다.\nscale() 함수를 이용해 그룹별 정규화를 해줍니다. 정규화는 \\(\\frac{x-\\mu}{\\sigma}\\)로 계산됩니다.\n섹터 정보가 없을 경우 NA로 변경합니다.\n\n위의 정규화 과정을 살펴보면, 전체 종목에서 12개월 수익률을 비교하는 것이 아닌 각 섹터별로 수익률의 강도를 비교하게 됩니다. 따라서 특정 종목의 과거 수익률이 전체 종목과 비교해서 높았더라도 해당 섹터 내에서의 순위가 낮다면, 정규화된 값은 낮아집니다.\n따라서 섹터별 정규화 과정을 거친 값으로 비교 분석을 한다면, 섹터 효과가 제거된 포트폴리오를 구성할 수 있습니다.\n\nret_1yr_neutral %>%\n  mutate(rank = min_rank(desc(scale_per_sector))) %>%\n  filter(rank <= 20)\n\n# A tibble: 20 × 8\n   종목코드   ret IDX_CD CMP_KOR          SEC_NM_KOR        기준일 scale…¹  rank\n   <chr>    <dbl> <chr>  <chr>            <chr>             <chr>    <dbl> <int>\n 1 000230   0.833 G35    일동홀딩스       건강관리          2022-…    3.97    18\n 2 001570   2.47  G15    금양             소재              2022-…    8.74     3\n 3 003610   1.38  G25    방림             경기관련소비재    2022-…    6.06     9\n 4 016790   5.17  G30    카나리아바이오   필수소비재        2022-…    8.68     4\n 5 025770   1.01  G50    한국정보통신     커뮤니케이션서비… 2022-…    4.90    12\n 6 030960   2.99  G20    양지사           산업재            2022-…    6.08     8\n 7 043090   1.13  G25    한창바이오텍     경기관련소비재    2022-…    5.18    11\n 8 052020   2.02  G45    에스티큐브       IT                2022-…    7.08     5\n 9 056090   0.939 G35    이노시스         건강관리          2022-…    4.33    16\n10 079810   1.04  G45    디이엔티         IT                2022-…    4.02    17\n11 095500   2.82  G45    미래나노텍       IT                2022-…    9.60     2\n12 101670   6.87  G20    코리아에스이     산업재            2022-…   13.5      1\n13 179290   1.58  G35    엠아이텍         건강관리          2022-…    6.52     6\n14 205470   0.746 G35    휴마시스         건강관리          2022-…    3.67    19\n15 215100   0.707 G25    로보로보         경기관련소비재    2022-…    3.64    20\n16 249420   1.05  G35    일동제약         건강관리          2022-…    4.70    13\n17 322000   1.49  G10    현대에너지솔루션 에너지            2022-…    4.44    15\n18 366030   1.26  G25    공구우먼         경기관련소비재    2022-…    5.64    10\n19 373200   1.75  G45    하인크코리아     IT                2022-…    6.26     7\n20 376180   0.938 G25    피코그램         경기관련소비재    2022-…    4.48    14\n# … with abbreviated variable name ¹​scale_per_sector\n\n\n\nret_1yr_neutral %>%\n  mutate(rank = min_rank(desc(scale_per_sector))) %>%\n  filter(rank <= 20) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  arrange(n) %>%\n  mutate(SEC_NM_KOR = factor(SEC_NM_KOR, levels = .$SEC_NM_KOR %>% unique)) %>%\n  ggplot(aes(x = SEC_NM_KOR, y = n)) +\n  geom_col() +\n  geom_text(aes(label = n, hjust = -1)) +\n  coord_flip()\n\n\n\n\n\n\n\n\ngroup_by() 함수를 통해 손쉽게 그룹별 중립화를 할 수 있으며, 글로벌 투자를 하는 경우에는 지역, 국가, 섹터별로도 중립화된 포트폴리오를 구성하기도 합니다."
  },
  {
    "objectID": "portfolio.html#이상치-데이터-처리-및-팩터의-결합",
    "href": "portfolio.html#이상치-데이터-처리-및-팩터의-결합",
    "title": "포트폴리오 구성하기",
    "section": "이상치 데이터 처리 및 팩터의 결합",
    "text": "이상치 데이터 처리 및 팩터의 결합\n안정적인 퀀트 포트폴리오를 구성하기 위해서는 팩터 데이터를 어떻게 처리하여 결합할지에 대해서도 알고 있어야 하므로, 이러한 점에 대해 살펴보도록 하겠습니다.\n모든 데이터 분석에서 중요한 문제 중 하나가 이상치(극단치, Outlier) 데이터를 어떻게 처리할 것인가입니다. 과거 12개월 수익률이 10배인 주식이 과연 모멘텀 관점에서 좋기만 한 주식인지, ROE가 100%를 넘는 주식이 과연 퀄리티 관점에서 좋기만 한 주식인지 고민이 되기 마련입니다. 따라서 이러한 이상치를 제외하고 분석할지, 포함해서 분석할지를 판단해야 합니다. 만일 이상치를 포함한다면 그대로 사용할 것인지, 보정해 사용할 것인지도 판단해야 합니다.\n우리가 가지고 있는 PBR 데이터에서 이상치 데이터를 탐색해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nPBR = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  filter(지표 == 'PBR') %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일)\n\nPBR %>% summarize(max_pbr = max(PBR, na.rm = T), min_pbr = min(PBR, na.rm = T))\n\n# A tibble: 1 × 2\n  max_pbr min_pbr\n    <dbl>   <dbl>\n1    40.4  0.0363\n\n\n먼저 밸류 테이블을 불러온 후 PBR 데이터만 선택합니다. PBR의 최대값과 최소값을 확인해보면 값이 매우 큰 것을 확인할 수 있습니다.\n\nPBR %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n국내 종목들의 PBR을 히스토그램으로 그려보면 오른쪽으로 꼬리가 매우 긴 분포를 보입니다. 이는 PBR이 극단적으로 큰 이상치 데이터가 있기 때문입니다. 이처럼 모든 팩터 데이터에는 극단치가 있기 마련이며, 이를 처리하는 방법을 알아보도록 하겠습니다.\n\n트림(Trim): 이상치 데이터 삭제\n트림은 이상치 데이터를 삭제하는 방법입니다. 위의 예제에서 이상치에 해당하는 상하위 1% 데이터를 삭제하겠습니다.\n\nPBR %>%\n  mutate(PBR = ifelse(percent_rank(PBR) > 0.99, NA, PBR),\n         PBR = ifelse(percent_rank(PBR) < 0.01, NA, PBR)) %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 50 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\npercent_rank() 함수를 통해 백분위를 구한 후 상하위 1%에 해당하는 데이터를 제외한 데이터만 선택합니다. 결과적으로 지나치게 PBR이 낮은 종목과 높은 종목은 제거되어 \\(x\\)축의 스케일이 많이 줄어든 모습입니다.\n평균이나 분산 같이 통계값을 구하는 과정에서는 이상치 데이터를 제거하는 것이 바람직할 수 있습니다. 그러나 팩터를 이용해 포트폴리오를 구하는 과정에서 해당 방법은 조심스럽게 사용되어야 합니다. 데이터의 손실이 발생하게 되며, 제거된 종목 중 정말로 좋은 종목이 있을 수도 있기 때문입니다.\n\n\n윈저라이징(Winsorizing): 이상치 데이터 대체\n이상치 데이터를 다른 데이터로 대체하는 윈저라이징 방법을 사용할 수도 있습니다. 예를 들어 상위 1%를 초과하는 데이터는 1% 값으로 대체하며, 하위 1% 미만의 데이터는 1% 데이터로 대체합니다. 즉, 좌우로 울타리를 쳐놓고 해당 범위를 넘어가는 값을 강제로 울타리에 맞춰줍니다.\n\nPBR %>%\n  mutate(PBR = ifelse(percent_rank(PBR) > 0.99,\n                      quantile(.$PBR, 0.99, na.rm = TRUE), PBR),\n         PBR = ifelse(percent_rank(PBR) < 0.01,\n                      quantile(.$PBR, 0.01, na.rm = TRUE), PBR)) %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n이번에는 값이 상하위 1%를 벗어나는 경우, 1%에 해당하는 값으로 대체하였습니다. 그림을 살펴보면 축 양 끝부분의 막대(붉은색)가 길어진 것을 확인할 수 있습니다.\n\n\n팩터의 결합방법\n앞서 밸류 지표의 결합, 퀄리티 지표의 결합, 마법공식 포트폴리오를 구성할 때는 단순히 순위를 더하는 방법을 사용했습니다. 물론 투자 종목수가 얼마 되지 않거나, 개인 투자자의 입장에서는 이러한 방법이 가장 단순하면서도 효과적일수 있습니다. 그러나 전문투자자가 포트폴리오를 구성하거나 팩터를 분석하는 업무를 할 경우 이처럼 단순히 순위를 더하는 방법은 여러 가지 문제를 안고 있습니다.\n각 밸류 지표의 순위를 구한 후 히스토그램으로 나타내보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\nvalue %>%\n  select(종목코드, contains('rank_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(name ~. , ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2729 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n그림에서 알 수 있듯이 순위를 구하는 것의 가장 큰 장점은 극단치로 인한 효과가 사라진다는 점과 균등한 분포를 가진다는 점입니다. 그러나 각 지표의 \\(x\\)축을 보면 최댓값이 서로 다릅니다. 이는 지표별 결측치로 인해 유효 데이터의 갯수가 달라 나타나는 현상입니다.\n\nvalue %>%\n  select(종목코드, contains('rank_')) %>%\n  pivot_longer(-종목코드) %>%\n  group_by(name) %>%\n  summarize(na_count = sum(is.na(value)))\n\n# A tibble: 5 × 2\n  name     na_count\n  <chr>       <int>\n1 rank_DY      1130\n2 rank_PBR        4\n3 rank_PCR      828\n4 rank_PER      681\n5 rank_PSR       86\n\n\n밸류 지표 별 NA 개수를 확인해보면 그 결과가 모두 다르며, 특히 배당 수익률의 경우 절반 정도가 NA 데이터입니다. 따라서 서로 다른 범위의 분포를 단순히 합치는 것은 좋은 방법이 아닙니다. 예를 들어 A, B, C, D 팩터에 각각 비중을 25%, 25%, 25%, 25% 부여해 포트폴리오를 구성한다고 가정해봅시다. 각 순위는 분포의 범위가 다르므로, 순위와 비중의 가중평균을 통해 포트폴리오를 구성하면 왜곡된 결과를 발생시킵니다.\n이러한 문제를 해결하는 가장 좋은 방법은 순위를 구한 후 이를 Z-Score로 정규화하는 것입니다.\n\nvalue_z_score = value %>%\n  select(1:6) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY))) %>%\n  mutate(across(c(rank_PBR, rank_PER, rank_PCR, rank_PSR, rank_DY), scale, .names = \"z_{col}\")) \n\nvalue_z_score %>%\n  select(종목코드, contains('z_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(name ~. , ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2729 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n앞서 구해진 순위에 scale 함수를 통해 정규화를 해줍니다. 기본적으로 순위의 분포가 가진 극단치 효과가 사라지는 점과 균등 분포의 장점을 유지하고 있으며, 분포의 범위 역시 거의 동일하게 바뀌었습니다. 이처럼 여러 팩터를 결합해 포트폴리오를 구성하고자 하는 경우, 먼저 각 팩터(지표)별 순위를 구한 후 이를 정규화한 뒤 더해야 왜곡 효과가 제거되어 안정적인 포트폴리오가 됩니다.\n\\[Z-Score(Rank(Factor\\ A)) + Z-Score(Rank(Factor\\ B)) + \\dots + Z-Score(Rank(Factor\\ N))\\]"
  },
  {
    "objectID": "portfolio.html#멀티팩터-포트폴리오",
    "href": "portfolio.html#멀티팩터-포트폴리오",
    "title": "포트폴리오 구성하기",
    "section": "멀티팩터 포트폴리오",
    "text": "멀티팩터 포트폴리오\n앞에서 배웠던 팩터 이론들과 결합 방법들을 응용해 멀티팩터 포트폴리오를 구성해봅시다. 각 팩터에 사용되는 지표는 다음과 같습니다.\n\n퀄리티: 자기자본이익률(ROE), 매출총이익(GPA), 영업활동현금흐름(CFO)\n밸류: PER, PBR, PSR, PCR, DY\n모멘텀: 12개월 수익률, K-Ratio\n\n\nlibrary(DBI)\nlibrary(RMySQL)\n\n# 연결\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\n# 티커\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n      \n# 주가            \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\n# 밸류\nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\n# 재무제표\nfs = dbGetQuery(con ,\n\"select * from kor_fs\nwhere 계정 in ('당기순이익', '매출총이익', '영업활동으로인한현금흐름', '자산', '자본')\nand 공시구분 = 'q';\n\")\n\n# 섹터\nsector = dbGetQuery(con,\n                    \"select * from kor_sector\nwhere 기준일 = (select max(기준일) from kor_sector);\"\n)\n\ndbDisconnect(con)\n\n[1] TRUE\n\n\n티커, 섹터, 주가, 재무제표, 가치지표 데이터를 불러옵니다.\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\n가치지표를 핸들링합니다.\n\nlibrary(RcppRoll)\n\nfs_roll = fs %>% arrange(종목코드, 계정, 기준일) %>%\n  group_by(종목코드, 계정) %>%\n  mutate(rollsum = roll_sum(값, n = 4, align = 'right', fill = NA)) %>%\n  slice(n()) %>%\n  mutate(rollsum = case_when(\n    계정 %in% c('자본', '자산') ~ rollsum / 4,\n    TRUE ~ rollsum\n  )) %>%\n  ungroup()\n\nfs_roll_pivot = fs_roll %>% select(계정, 종목코드, rollsum) %>%\n  pivot_wider(names_from = 계정, values_from = rollsum) %>%\n  mutate(ROE = 당기순이익 / 자본,\n         GPA = 매출총이익 / 자산,\n         CFO = 영업활동으로인한현금흐름 / 자산)\n\n퀄리티 지표를 계산하기 위해 TTM 기준 ROE, GPA, CFO를 계산합니다.\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\nk_ratio = price %>%\n  group_by(종목코드) %>%\n  filter(n() >= 200) %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number())  %>%\n  ungroup() %>%\n  nest(data = -종목코드) %>%\n  mutate(model = map(data, ~lm(cumret~id, data = .)),\n         tidied = map(model, tidy)) %>%\n  unnest(tidied) %>%\n  filter(term == 'id') %>%\n  mutate(k_ratio = estimate / `std.error`) \n\n최근 12개월 수익률과 K-Ratio를 계산합니다. 이제 모든 테이블을 하나로 합치도록 합니다.\n\nlibrary(tibble)\n\ndata_bind  = \n  ticker %>%\n  left_join(sector, by = c('종목코드' = 'CMP_CD')) %>%\n  left_join(fs_roll_pivot %>% select(종목코드, ROE, GPA, CFO)) %>%\n  left_join(value) %>%\n  left_join(ret_1yr) %>%\n  left_join(k_ratio %>% select(종목코드, k_ratio)) \n\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\n\ndata_bind = data_bind %>%\n  mutate(SEC_NM_KOR = replace_na(SEC_NM_KOR, '기타')) %>% as_tibble()\n\ndata_bind\n\n# A tibble: 2,294 × 30\n   종목코드 종목명    시장…¹  종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>     <chr>  <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000020   동화약품  KOSPI   8650  2.42e11 2022-1…   647      NA  12534    180\n 2 000040   KR모터스  KOSPI    599  5.76e10 2022-1…    NA      NA    385      0\n 3 000050   경방      KOSPI  10800  2.96e11 2022-1…   872      NA  30033    125\n 4 000060   메리츠화… KOSPI  29600  3.37e12 2022-1…  5768    6808  22086    620\n 5 000070   삼양홀딩… KOSPI  63800  5.46e11 2022-1… 30711      NA 226314   3000\n 6 000080   하이트진… KOSPI  24650  1.73e12 2022-1…  1031    1984  15657    800\n 7 000100   유한양행  KOSPI  55000  4.03e12 2022-1…  1496    1673  28297    400\n 8 000120   CJ대한통… KOSPI  81000  1.85e12 2022-1…  1841   10250 178766      0\n 9 000140   하이트진… KOSPI  10050  2.33e11 2022-1…  1529      NA  23538    450\n10 000150   두산      KOSPI  78600  1.30e12 2022-1… 11890   12800 121631   2000\n# … with 2,284 more rows, 20 more variables: 종목구분 <chr>, IDX_CD <chr>,\n#   CMP_KOR <chr>, SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>,\n#   CFO <dbl>, DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>,\n#   rank_PBR <int>, rank_PER <int>, rank_PCR <int>, rank_PSR <int>,\n#   rank_DY <int>, ret <dbl>, k_ratio <dbl>, and abbreviated variable names\n#   ¹​시장구분, ²​기준일.x, ³​주당배당금\n\n\n테이블을 합친 후, 섹터 정보가 없는 경우 ’기타’를 입력합니다.\n이번에는 각 섹터별로 아웃라이어를 제거한 후 순위와 Z-Score를 구하도록 하겠습니다. 첫번째로 퀄리티 지표의 Z-Score를 계산합니다.\n\nz_quality = data_bind %>% select(종목코드, SEC_NM_KOR, ROE, GPA, CFO) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(across(c(ROE, GPA, CFO), .fns = ~min_rank(desc(.)), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_ROE, rank_GPA, rank_CFO), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_quality = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_quality %>% select(종목코드, z_quality))\n\nJoining, by = \"종목코드\"\n\ndata_bind\n\n# A tibble: 2,294 × 31\n   종목코드 종목명    시장…¹  종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>     <chr>  <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000020   동화약품  KOSPI   8650  2.42e11 2022-1…   647      NA  12534    180\n 2 000040   KR모터스  KOSPI    599  5.76e10 2022-1…    NA      NA    385      0\n 3 000050   경방      KOSPI  10800  2.96e11 2022-1…   872      NA  30033    125\n 4 000060   메리츠화… KOSPI  29600  3.37e12 2022-1…  5768    6808  22086    620\n 5 000070   삼양홀딩… KOSPI  63800  5.46e11 2022-1… 30711      NA 226314   3000\n 6 000080   하이트진… KOSPI  24650  1.73e12 2022-1…  1031    1984  15657    800\n 7 000100   유한양행  KOSPI  55000  4.03e12 2022-1…  1496    1673  28297    400\n 8 000120   CJ대한통… KOSPI  81000  1.85e12 2022-1…  1841   10250 178766      0\n 9 000140   하이트진… KOSPI  10050  2.33e11 2022-1…  1529      NA  23538    450\n10 000150   두산      KOSPI  78600  1.30e12 2022-1… 11890   12800 121631   2000\n# … with 2,284 more rows, 21 more variables: 종목구분 <chr>, IDX_CD <chr>,\n#   CMP_KOR <chr>, SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>,\n#   CFO <dbl>, DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>,\n#   rank_PBR <int>, rank_PER <int>, rank_PCR <int>, rank_PSR <int>,\n#   rank_DY <int>, ret <dbl>, k_ratio <dbl>, z_quality <dbl>, and abbreviated\n#   variable names ¹​시장구분, ²​기준일.x, ³​주당배당금\n\n\n두번째로 밸류 지표의 Z-Score를 계산합니다.\n\nz_value =\n  data_bind %>% select(종목코드, SEC_NM_KOR, DY, PBR, PCR, PER, PSR) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(rank_DY = min_rank(desc(DY))) %>%\n  mutate(across(c(PBR, PCR, PER, PSR), .fns = ~min_rank(.), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_DY, rank_PBR, rank_PCR, rank_PER, rank_PSR), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_value = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_value %>% select(종목코드, z_value))\n\nJoining, by = \"종목코드\"\n\n\n마지막으로 모멘텀 지표의 Z-Score를 구합니다.\n\nz_momentum =\n  data_bind %>% select(종목코드, SEC_NM_KOR, ret, k_ratio) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(across(c(ret, k_ratio), .fns = ~min_rank(desc(.)), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_ret, rank_k_ratio), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_momentum = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_momentum %>% select(종목코드, z_momentum))\n\nJoining, by = \"종목코드\"\n\n\n각 팩터의 분포를 시각화해보도록 하겠습니다.\n\ndata_bind %>%\n  select(종목코드, contains('z_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_grid(name ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1768 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n각각 퀄리티 지표는 3개, 밸류 지표는 5개, 모멘텀 지표는 2개 기준을 이용해 계산했습니다. 그림에서 알 수 있듯이 기준을 많이 사용할 수록 Z-Score가 넓게 퍼져있는 모습을 보이며, 각 팩터별 분포가 동일하지 않습니다. 따라서 다시 Z-Score를 계산해 분포의 넓이를 비슷하게 맞춰주도록 합니다.\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\ndata_bind_final  = data_bind %>%\n  select(종목코드, z_quality, z_value, z_momentum) %>%\n  mutate(across(c(z_quality, z_value, z_momentum), .fns = ~scale(.))) %>%\n  set_colnames(c('종목코드', 'quality', 'value', 'momentum'))\n\ndata_bind_final %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_grid(name ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1768 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n재계산된 Z-Score의 분포의 넓이를 살펴보면 이전에 비해 훨씬 비슷해진 것을 알 수 있습니다. 각 팩터들 간의 상관관계를 살펴보겠습니다.\n\ndata_bind_final %>%\n  select(-종목코드) %>%\n  cor(., use = 'complete.obs') %>%\n  round(., 2)\n\n         quality value momentum\nquality     1.00  0.08     0.08\nvalue       0.08  1.00    -0.15\nmomentum    0.08 -0.15     1.00\n\n\n각 팩터간 상관관계가 매우 낮으며, 여러 팩터를 동시에 고려함으로서 분산효과를 기대할 수 있습니다. 이제 계산된 팩터들을 토대로 최종 포트폴리오를 구성해보도록 하겠습니다.\n\nwts = c(0.3, 0.3, 0.3)\n\ndata_bind_final = data_bind_final %>%\n  column_to_rownames('종목코드') %>%\n  multiply_by(wts) %>% \n  mutate(qvm = rowSums(.)) %>%\n  rownames_to_column(var = '종목코드') %>%\n  select(종목코드, qvm)\n  \ndata_bind = data_bind %>%\n  left_join(data_bind_final) %>%\n  mutate(invest = ifelse(min_rank(qvm) <= 20, 'Y', 'N'))\n\nJoining, by = \"종목코드\"\n\ndata_bind %>%\n  filter(invest == 'Y')\n\n# A tibble: 20 × 35\n   종목코드 종목명   시장…¹   종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>    <chr>   <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000700   유수홀…  KOSPI    6350  1.65e11 2022-1…   991      NA  13108    400\n 2 001120   LX인터…  KOSPI   42750  1.66e12 2022-1…  9733   11746  49349   2300\n 3 005010   휴스틸   KOSPI    5810  2.28e11 2022-1…   987      NA  15984    160\n 4 009970   영원무…  KOSPI   51200  6.98e11 2022-1… 19026   22866 140307   2000\n 5 017670   SK텔레콤 KOSPI   49700  1.09e13 2022-1…  7191    5167  53218   3295\n 6 030200   KT       KOSPI   34800  9.09e12 2022-1…  5759    5188  63512   1910\n 7 036710   심텍홀…  KOSDAQ   3140  1.52e11 2022-1…   695      NA   4051     50\n 8 049070   인탑스   KOSDAQ  27800  4.78e11 2022-1…  4436    4244  32446    470\n 9 058860   KTis     KOSPI    2430  8.46e10 2022-1…   767      NA   5909    100\n10 065510   휴비츠   KOSDAQ  10000  1.19e11 2022-1…   848    2383   8297    200\n11 078930   GS       KOSPI   45950  4.27e12 2022-1… 15304   19446 108672   2000\n12 084650   랩지노…  KOSDAQ   7110  2.42e11 2022-1…  2497      NA   4747    300\n13 093050   LF       KOSPI   15450  4.52e11 2022-1…  4169      NA  46904    600\n14 094970   제이엠티 KOSDAQ   3115  5.22e10 2022-1…   908      NA   4505    150\n15 124560   태웅로…  KOSDAQ   4805  1.85e11 2022-1…  1726      NA   3292    100\n16 200880   서연이화 KOSPI    6630  1.79e11 2022-1…   973      NA  24588    150\n17 205470   휴마시스 KOSDAQ  17850  6.11e11 2022-1…  4422      NA   5908    200\n18 225220   제놀루션 KOSDAQ   9700  9.30e10 2022-1…  3626      NA   9083    400\n19 306200   세아제강 KOSPI  142000  4.03e11 2022-1… 32640   64527 242703   3500\n20 319660   피에스…  KOSDAQ  17150  2.48e11 2022-1…  2615    2896   9888    600\n# … with 25 more variables: 종목구분 <chr>, IDX_CD <chr>, CMP_KOR <chr>,\n#   SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>, CFO <dbl>,\n#   DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>, rank_PBR <int>,\n#   rank_PER <int>, rank_PCR <int>, rank_PSR <int>, rank_DY <int>, ret <dbl>,\n#   k_ratio <dbl>, z_quality <dbl>, z_value <dbl>, z_momentum <dbl>, qvm <dbl>,\n#   invest <chr>, and abbreviated variable names ¹​시장구분, ²​기준일.x,\n#   ³​주당배당금\n\n\n\n각 팩터별 비중을 리스트로 만들며, 0.3으로 동일한 비중을 입력합니다다. 비중을 [0.2, 0.4, 0.4]와 같이 팩터별로 다르게 줄 수도 있으며, 이는 어떠한 팩터를 더욱 중요하게 생각하는지 혹은 더욱 좋게 보는지에 따라 조정이 가능합니다.\n팩터별 Z-Score와 비중의 곱을 구한 후 이를 합합니다.\n기존 테이블(data_bind)과 합칩니다.\n최종 Z-Score의 합(qvm) 기준 순위가 1~20인 경우는 투자 종목에 해당하므로 ‘Y’, 그렇지 않으면 ’N’으로 표시합니다.\n\n최종 선택된 종목들을 보면 전반적으로 퀄리티가 높고, 밸류에이션이 낮으며, 최근 수익률이 높습니다. 물론 특정 팩터(예: 모멘텀)가 좋지 않아도 다른 팩터(예: 밸류)가 지나치게 좋아 선택되는 경우도 있습니다. 이제 선택된 종목들과 그렇지 않은 종목들간의 특성을 그림으로 표현해보겠습니다.\n\ndata_bind %>%\n  select(ROE, GPA, CFO, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = min_rank(desc(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n퀄리티 지표가 포함된 데이터를 선택한다.\n각 지표(name)별 그룹을 묶은 후 순위를 계산합니다.\n그림으로 나타냅니다.\n\n붉은색 ▲ 마크는 투자하는 종목, 회색 ● 마크는 투자하지 않는 종목입니다. 전반적으로 멀티팩터 기준으로 선정된 종목들의 퀄리티 순위가 높음을 알 수 있습니다.\n이번에는 동일한 방법으로 밸류 지표의 차이를 살펴보겠습니다.\n\ndata_bind %>%\n  select(DY, PBR, PER, PCR, PSR, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = \n           ifelse(name == 'DY', min_rank(desc(value)), min_rank(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n밸류 지표 역시 멀티팩터 기준으로 선정된 종목들의 순위가 높습니다. 그러나 사용되는 지표가 많은 만큼 일부 지표에서는 순위가 낮은 종목들이 선정되기도 합니다.\n이번에는 모멘텀 지표의 차이를 살펴보겠습니다.\n\ndata_bind %>%\n  select(ret, k_ratio, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = min_rank(desc(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n모멘텀 지표 역시 멀티팩터 기준으로 선정된 종목들의 순위가 높습니다.\n이처럼 멀티팩터 기준으로 종목을 선정할 경우 각 팩터가 골고루 좋은 종목을 선택할 수 있습니다. 이 외에도 팩터를 만들 수 있는 기본 데이터가 모두 있으므로 최근 적자기업 제외, 매출 증가 등 다양한 전략을 추가할 수도 있습니다."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "",
    "section": "",
    "text": "두물머리 데이터 기반 퀀트 투자 전문가\n두물머리에서 제공하는 ‘퀀트 투자 전문가’ 과정 강의록 입니다.\n소개: https://festa.io/events/2997\n\n\n목차\n\n데이터 분석 프로세스\nSQL 기초\nR 기초 및 데이터분석 실습\nR와 SQL 연결해 사용하기\nAPI를 이용한 데이터 수집\n크롤링 기초\n퀀트 전략을 이용한 포트폴리오 구성하기\n백테스트 실습\n성과 및 위험 평가하기\n\n\n\n참고자료\n\nR을 이용한 퀀트 투자 포트폴리오 만들기\n파이썬을 이용한 퀀트 투자 포트폴리오 만들기\n감으로 하는 투자, 데이터로 하는 투자\n\n\n\n퀀트대학 링크"
  },
  {
    "objectID": "r_basic.html",
    "href": "r_basic.html",
    "title": "R 기초 배우기",
    "section": "",
    "text": "이번 장에서는 R과 R 스튜디오의 설치, R 스튜디오의 화면 구성과 간단한 사용법에 대해서 배우도록 하겠습니다. 본 장은 R의 기초 중에서도 핵심만을 추린 것으로써, 기초에 대해 세세하게 다루지는 않습니다. 좀 더 탄탄한 기본기를 배우고 싶으신 분은 시중에 나와있는 훌륭한 R 기본 서적을 추가로 보실 것을 추천드립니다."
  },
  {
    "objectID": "r_basic.html#r과-r-스튜디오-설치하기",
    "href": "r_basic.html#r과-r-스튜디오-설치하기",
    "title": "R 기초 배우기",
    "section": "R과 R 스튜디오 설치하기",
    "text": "R과 R 스튜디오 설치하기\n\nR 설치하기\n먼저 R 프로젝트 공식 사이트인 https://cran.r-project.org/ 에 접속하여 본인의 OS에 맞는 설치 파일을 다운로드 합니다.\n\n\n\n\n\nCRAN 사이트\n\n\n\n\n가장 상단의 [base]를 선택합니다.\n\n\n\n\n\nR 다운로드 화면\n\n\n\n\n[Download R x.x.x for Windows] 항목을 클릭하면 설치 파일이 다운로드 됩니다. 다운로드 받은 파일을 실행해 설치를 하며, 옵션은 수정하지 않아도 됩니다.\n\n\n\n\n\nR 설치파일 다운로드\n\n\n\n\n\n\nR 스튜디오 설치하기\n위에서 설치한 R GUI를 그대로 쓰는 사용자는 거의 없습니다. 대부분의 경우 R을 사용하기 편리하게 만들어주는 IDE 소프트웨어인 R 스튜디오를 사용하므로, 해당 프로그램을 설치하도록 합니다. R 스튜디오를 사용하려면 R이 먼저 설치되어 있어야 하며, R과 마찬가지로 무료로 사용할 수 있습니다. 먼저 아래 사이트에 접속합니다.\n\nhttps://posit.co/download/rstudio-desktop/\n\n하단의 [All Installers] 항목에서 본인의 OS에 해당하는 파일을 다운로드 받아 설치합니다.\n\n\n\n\n\n윈도우 사용자의 경우 간혹 R 스튜디오를 실행하는데 있어 오류가 발생할 수 있습니다.\n\nR 스튜디오가 관리자 권한으로 실행되지 않으면 오류가 발생할 수 있으며, 이 경우 아래와 같은 방법으로 해결이 가능합니다.\n\n\nR 스튜디오 바로가기 아이콘을 마우스 우클릭으로 연 후, [속성] → [호환성]을 클릭합니다.\n[관리자 권한으로 이 프로그램 실행]에 체크한 후 [확인]을 누릅니다.\n\n 2. 윈도우 사용자 계정이 한글인 경우 기존 사용자 계정을 영문으로 변경하거나, 영문으로 된 사용자 계정을 새로 추가합니다."
  },
  {
    "objectID": "r_basic.html#r-스튜디오-화면-구성",
    "href": "r_basic.html#r-스튜디오-화면-구성",
    "title": "R 기초 배우기",
    "section": "R 스튜디오 화면 구성",
    "text": "R 스튜디오 화면 구성\n처음으로 R 스튜디오를 실행하면 다음과 같은 화면으로 구성되어 있습니다. 이 중 소스 창을 열기 위해 네모 2개가 겹쳐 있는 모양()의 버튼을 클릭합니다.\n\n\n\n\n\nR 스튜디오 화면구성\n\n\n\n\n소스 창이 활성화되면 총 4개의 창으로 화면이 구성되며, 각 창의 크기는 경계선 부분을 드래그하여 조절할 수 있습니다.\n\n\n\n\n\nR 스튜디오 화면구성 (2)\n\n\n\n\n1. 콘솔 창\n좌측 하단에 있는 콘솔 창은 코드를 입력하고 결과물을 출력하는 곳입니다.\n\n\n\n\n\nR 스튜디오 콘솔 창\n\n\n\n\n콘솔 창의 > 기호 뒤에 1+1을 입력하면 그 결과값인 2가 출력됩니다.\n이 외에도 [Terminal] 탭에서는 시스템 쉘을 이용해 운영 체제를 조작할 수 있습니다.\n2. 소스 창\n좌측 상단에 있는 소스 창은 코드를 기록할 수 있는 공간이며, 이를 저장한 파일을 스크립트라고 합니다. 콘솔 창과는 다르게 코드를 입력하여도 바로 실행이 되지 않으며, 엔터를 누르면 행이 바뀝니다. 실행하고자 하는 코드가 있는 행을 선택한 후, [Ctrl + Enter]키를 누르면 해당 코드가 실행됩니다.\n\n\n\n\n\nR 스튜디오 소스 창의 실행\n\n\n\n\n3*7이란 코드가 있는 곳에 커서를 둔 후 [Ctrl + Enter]키를 누르면 해당 코드가 콘솔 창에서 실행됩니다. 만일 여러줄의 명령어를 한번에 실행하고 할 경우, 원하는 부분의 코드를 마우스로 드래그하여 선택한 후 [Ctrl + Enter]키를 누르면 코드가 순차적으로 콘솔 창에 입력되면서 실행됩니다.\n\n\n\n\n\nR 스튜디오 소스 저장하기\n\n\n\n\n위에서 작성한 코드를 저장해보도록 하겠습니다. 저장 버튼()을 클릭한 후 원하는 폴더 및 파일 이름을 입력 한 후 [Save] 버튼을 누릅니다.\n\n\n\n\n\nR 스튜디오 소스 저장하기 (2)\n\n\n\n\nUntitled1로 되어 있던 스크립트의 이름이 저장한 이름으로 바뀌며, 스크립트가 저장되어 있는 것이 확인됩니다. 이처럼 코딩을 한 후 스크립트를 저장할 경우, 나중에 해당 내역을 그대로 불러올 수 있습니다.\n3. 환경 창\n우측 상단에 있는 환경 창은 생성된 데이터를 보여주는 화면입니다.\n\n\n\n\n\nR 스튜디오 환경 창\n\n\n\n\n스크립트 창에서 a = 1을 입력하면, 환경 창의 Values 목록에 a가 생기며 그 값은 1로 표시됩니다.\n이 외에도 환경 창의 [History] 탭은 이제까지 실행했던 코드의 내역을 볼 수 있으며, [Connections] 탭은 SQL이나 Spark 등 데이터베이스와의 연결을 도와줍니다.\n4. 파일 창\n우측 하단에 있는 파일 창은 윈도우의 파일 탐색기와 비슷한 역할을 하며, 워킹 디렉터리 내의 파일을 보여줍니다. 이 외에도 [Plots] 탭은 그래프를 보여주며 [Packages] 탭은 설치된 패키지의 목록을 보여줍니다. [Help] 탭은 도움말을 보여주며, [Viewer] 탭은 분석 결과를 HTML 등 웹 문서로 출력한 모습을 보여줍니다."
  },
  {
    "objectID": "r_basic.html#r-스튜디오-설정하기",
    "href": "r_basic.html#r-스튜디오-설정하기",
    "title": "R 기초 배우기",
    "section": "R 스튜디오 설정하기",
    "text": "R 스튜디오 설정하기\nR 스튜디오는 기본적으로 흰색 바탕에 검은색 글씨로 설정되어 있습니다. 그러나 흰 화면에서 작업을 하게 되면 눈이 쉽게 피로해지며, 시력에도 좋지 않습니다. 이를 방지하기 위해 어두운 화면으로 설정을 변경해주는 것이 좋습니다.\n\n\n\n\n\nR 스튜디오의 테마 선택\n\n\n\n\n상단 탭에서 [Tools] → [Global Options]를 선택한 후, Options의 [Appearance] 탭의 [Editor theme]을 통해 각종 테마를 적용할 수 있습니다. 이 중 본인의 마음에 드는 테마를 선택한 후, [OK] 버튼을 누릅니다.\n\n\n\n\n\nR 스튜디오의 다크모드 적용\n\n\n\n\n화면의 배경이 어두워져 눈이 한결 편해졌습니다."
  },
  {
    "objectID": "r_basic.html#프로젝트-만들기",
    "href": "r_basic.html#프로젝트-만들기",
    "title": "R 기초 배우기",
    "section": "프로젝트 만들기",
    "text": "프로젝트 만들기\nR 스튜디오에서 코딩을 하기 전에 프로젝트(Project)를 만들면 하나의 프로젝트에 사용되는 소스 코드, 이미지, 문서 등의 파일을 폴더별로 관리하여 효율적으로 관리할 수 있습니다.\n먼저 R 스튜디오 상단의 육각형 모양 버튼()을 클릭하거나 [File → New Project]를 클릭합니다.\n\n\n\n\n\n프로젝트 생성\n\n\n\n\n[Create Project] 화면에서 가장 상단의 [New Directory]를 클릭합니다. 참고로 Existing Directory는 기존 폴더에 새로운 프로젝트를 만들때, Version Control은 깃허브 등의 버전 관리 시스템을 이용할 때 사용됩니다.\n\n\n\n\n\n새 프로젝트 생성\n\n\n\n\n[Project Type]에서 가장 상단의 [New Project]를 클릭합니다.\n\n\n\n\n\n새 프로젝트 생성 (2)\n\n\n\n\n[Create New Project] 창에서 [Directory name] 항목에 새로 만들 프로젝트 이름을 입력합니다. [Create project as subdirectory of] 항목에는 프로젝트 폴더를 만들 위치를 선택하며, [Browse]를 클릭해 원하는 위치를 선택합니다. 그 후 하단의 [Creage Project]를 클릭합니다.\n\n\n\n\n\n새 프로젝트 생성 (3)\n\n\n\n\nR 스튜디오가 재시작되면 우측 상단 부분이 프로젝트 이름으로 바뀌며, 파일 창의 윗부분도 프로젝트 폴더의 위치로 바뀝니다. 또한 폴더 내에 fin_ds.Rpoj 라는 파일이 생성됩니다. 스크립트 및 각종 파일들을 해당 프로젝트 폴더에 저장하여, 효율적으로 각종 작업을 관리할 수 있습니다.\n\n\n\n\n\n새 프로젝트 생성 (4)\n\n\n\n\n프로젝트 이름과 폴더 경로에 한글이 들어가면 오류가 발생할 수 있으니, 영문으로 입력하는 것이 좋습니다."
  },
  {
    "objectID": "r_basic.html#데이터-타입별-다루기",
    "href": "r_basic.html#데이터-타입별-다루기",
    "title": "R 기초 배우기",
    "section": "데이터 타입별 다루기",
    "text": "데이터 타입별 다루기\nR과 R 스튜디오 설치가 끝났으면 본격적으로 R의 기본적인 사용법에 대해 배워보겠으며, 먼저 데이터의 타입별로 다루는 법부터 시작하겠습니다.\nR 뿐만 아니라 각종 프로그래밍에는 여러가지 데이터 타입이 있으며, 이를 다루는 방법은 각각 다릅니다. 예를 들어 같은 ’3’도 숫자 3인지 문자 3인지에 따라 다루는 방법이 다릅니다. 따라서 데이터 타입의 종류와 이들을 어떻게 다루어야 하는지를 아는 것이 프로그래밍의 기초라고 할 수 있습니다.\n\n숫자 형태\nR에서 숫자(Numbers) 형태는 크게 integer와 double로 나눌 수 있습니다. 이 중 integer는 정수를 의미하며, double은 부동소수점 실수를 의미합니다.\n\ndbl_var = c(1, 2.5, 4.5)\n\nprint(dbl_var)\n\n[1] 1.0 2.5 4.5\n\n\n위와 같이 입력하면 double, 즉 소수점 형태의 숫자가 만들어 집니다.\n\nint_var = c(1L, 6L, 5L)\n\nprint(int_var)\n\n[1] 1 6 5\n\n\n만일 숫자 뒤에 L을 붙이면, integer(정수) 형태의 숫자가 만들어 집니다.\ndouble 형태를 integer 형태로 바꾸려면 할 경우, as.integer() 함수를 사용해 쉽게 변경할 수 있습니다. 이처럼 R에서는 as.*() 함수의 형태로 각 데이터의 형태를 바꿀 수 있습니다.\n\nas.integer(dbl_var)\n\n[1] 1 2 4\n\n\n[1.0 2.5 4.5] 이던 dbl_var 값이 as.integer() 함수를 통해 소수점이 사라지고 정수 형태인 [1 2 4]로 변경되었습니다.\n\n숫자 생성하기\nR에서는 콜론(:)과 c() 함수를 통해 순서가 있는 숫자 벡터를 생성할 수 있습니다.\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n시작숫자:끝숫자의 형태로 입력하여 1에서 10까지 숫자가 생성됩니다.\n\nc(1, 5, 10)\n\n[1]  1  5 10\n\n\nc() 함수 내부에 각각의 숫자를 입력할 경우, 이로 구성된 숫자 벡터가 생성됩니다.\nseq() 함수를 이용할 경우 더욱 다양하게 숫자 벡터를 생성할 수 있습니다. seq는 Sequence 즉 ’순서’의 약어입니다. 이처럼 R이나 여타 프로그래밍에서는 함수의 이름을 통해 대략적인 기능을 추론할 수 있습니다.\n\nseq(from = 1, to = 21, by = 2)\n\n [1]  1  3  5  7  9 11 13 15 17 19 21\n\n\nseq() 함수 내부에 from에는 시작 숫자, to에는 종료 숫자, by에는 간격을 입력합니다. 즉 1에서 21까지 2 단위로 숫자가 생성됩니다.\n\nseq(0, 21, length.out = 15)\n\n [1]  0.0  1.5  3.0  4.5  6.0  7.5  9.0 10.5 12.0 13.5 15.0 16.5 18.0 19.5 21.0\n\n\n만일 입력값에 by 대신 length.out을 쓸 경우 from에서 to 까지 동일한 증가폭으로 length.out 만큼의 숫자를 생성하며, 해당 예제에서는 총 15개의 숫자가 만들어집니다.\nrep() 함수 역시 숫자를 생성해주는 함수입니다.\n\nrep(1:4, times = 2)\n\n[1] 1 2 3 4 1 2 3 4\n\n\nrep는 Replicate 즉 ’복제하다’의 약어 입니다. 해당 함수 내에 times라는 입력값을 추가해줄 경우, 해당 숫자만큼 반복되어 벡터가 생성됩니다.\n\nrep(1:4, each = 2)\n\n[1] 1 1 2 2 3 3 4 4\n\n\n만일 each라는 입력값을 추가할 경우, 각각의 숫자를 n번 반복하여 벡터가 생성됩니다.\n\n\n올림, 내림, 반올림\n함수를 통해 간단하게 숫자의 올림, 내림, 반올림을 할 수도 있습니다. 먼저 다음과 같이 숫자를 입력합니다.\n\nx = c(1, 1.35, 1.7, 2.053, 2.4, 2.758, 3.1, 3.45,\n      3.8, 4.15, 4.5, 4.855, 5.2, 5.55, 5.9)\n\n\nround(x)\n\n [1] 1 1 2 2 2 3 3 3 4 4 4 5 5 6 6\n\n\nround() 함수는 가장 가까운 정수로 반올림을 합니다.\n\nround(x, digits = 2)\n\n [1] 1.00 1.35 1.70 2.05 2.40 2.76 3.10 3.45 3.80 4.15 4.50 4.86 5.20 5.55 5.90\n\n\n함수 내부에 digits 입력값을 추가해 줄 경우, 해당 자리수 만큼 반올림을 합니다. 위 예제에서는 소수 둘째자리 만큼 반올림을 하였습니다.\n\nceiling(x)\n\n [1] 1 2 2 3 3 3 4 4 4 5 5 5 6 6 6\n\nfloor(x)\n\n [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5\n\n\nceiling() 함수는 올림을, floor() 함수는 내림을 실행합니다.\n\n\n\n문자열 형태\n일반적인 글자 혹은 텍스트를 문자열(Character Strings)이라고 합니다.\n\na = 'learning to create'\nb = 'character strings'\npaste(a, b)\n\n[1] \"learning to create character strings\"\n\n\n먼저 a와 b 변수에 각각의 문자를 입력한 후, R의 기본함수인 paste() 함수를 이용해 두 문자를 붙일 수 있습니다.\n\nprint(pi)\n\n[1] 3.141593\n\npaste('pi is', pi)\n\n[1] \"pi is 3.14159265358979\"\n\n\n원주율을 의미하는 pi는 원래 3.14159 라는 숫자가 입력되어 있습니다. 그러나 paste() 함수를 통해 문자열과 숫자를 합칠 경우, 그 결과값은 문자열이 됩니다.\n\npaste('I', 'love', 'R', sep = ',')\n\n[1] \"I,love,R\"\n\n\npaste() 함수 내부에 sep 인자를 추가할 경우, 각 단어를 구분하는 문자를 입력할 수 있습니다. 기존에는 각 문자가 공백을 기준으로 합쳐졌다면, 이번에는 콤마(,)를 기준으로 합쳐졌습니다.\n\npaste0('I', 'love', 'R')\n\n[1] \"IloveR\"\n\n\npaste0() 함수는 구분 문자가 없이 결합됩니다.\n\nstringr 패키지를 이용한 문자열 다루기\nR의 기본함수를 이용하여도 문자열을 다룰 수 있지만, stringr 패키지를 이용할 경우 더욱 다양한 작업을 수행할 수 있습니다. 패키지를 설치하는 방법은 다음과 같습니다.\n\ninstall.packages('패키지이름')\n\nstringr 패키지를 설치한 후 다음과 같이 입력합니다.\n\nlibrary(stringr)\n\nstr_c('Learning', 'to', 'use', 'the', 'stringr', 'package', sep = ' ')\n\n[1] \"Learning to use the stringr package\"\n\n\nstr_c() 함수는 paste() 함수와 기능이 동일하며, sep 인자를 통해 구분자를 추가할 수 있습니다.\n\ntext = c('Learning', 'to', NA, 'use', 'the', NA, 'stringr', 'package')\nstr_length(text)\n\n[1]  8  2 NA  3  3 NA  7  7\n\n\nstr_length() 함수는 문자열 각각의 텍스트 갯수를 세줍니다.\n\nx = 'Learning to use the stringr package'\n\nstr_sub(x, start = 1, end = 15)\n\n[1] \"Learning to use\"\n\nstr_sub(x, start = -7, end = -1)\n\n[1] \"package\"\n\n\nstr_sub() 함수는 start부터 end까지의 문자를 출력합니다. 만일 start 혹은 end에 음수를 입력하면, 문장의 뒤에서부터 start/end 지점이 계산됩니다. 즉, start와 end에 각각 -7와 -1을 입력하면 끝에서부터 일곱번째와 첫번째 지점이 시작점과 끝점이 됩니다.\n텍스트 데이터를 다룰때는 빈 공백이 따라오는 경우가 많으며, 이는 대부분 제거해주어야 할 대상입니다.\n\ntext = c('Text ', ' with', ' whitespace ', ' on', 'both ', 'sides ')\nprint(text)\n\n[1] \"Text \"        \" with\"        \" whitespace \" \" on\"          \"both \"       \n[6] \"sides \"      \n\n\n각 단어를 자세히 살펴보면 좌/우 혹은 양쪽에 공백이 있습니다. 이를 제거하도록 하겠습니다.\n\nstr_trim(text, side = 'left')\n\n[1] \"Text \"       \"with\"        \"whitespace \" \"on\"          \"both \"      \n[6] \"sides \"     \n\nstr_trim(text, side = 'right')\n\n[1] \"Text\"        \" with\"       \" whitespace\" \" on\"         \"both\"       \n[6] \"sides\"      \n\nstr_trim(text, side = 'both')\n\n[1] \"Text\"       \"with\"       \"whitespace\" \"on\"         \"both\"      \n[6] \"sides\"     \n\n\nstr_trim() 함수는 공백을 제거해주는 기능을 합니다. side 인자에 left를 입력할 경우 각 텍스트 왼쪽의 공백을, right를 입력할 경우 오른쪽의 공백을, both를 입력할 경우 양쪽의 공백을 제거해줍니다.\n마지막으로 원하는 자리수를 채우기 위해 문자열에 공백 혹은 특정 문자를 입력할 수도 있으며, str_pad() 함수를 통해 손쉽게 작업을 할 수 있습니다.\n\nstr_pad('beer', width = 10, side = 'left')\n\n[1] \"      beer\"\n\n\nwidth에 해당하는 10자리를 맞추기 위해 side의 입력값인 좌측에 공백이 추가되었습니다.\n\nstr_pad('beer', width = 10, side = 'left', pad = '!')\n\n[1] \"!!!!!!beer\"\n\n\npad 인자를 추가할 경우, 공백이 아닌 입력한 문자가 추가됩니다\n아래 페이지에는 stringr 패키지의 자세한 사용법이 나와 있습니다.\n\nhttps://stringr.tidyverse.org/\n\n\n\n\n날짜 형태\n시계열 작업을 위해서는 날짜(Date), 혹은 시간(Datetime) 형태를 다루어야 합니다.\n\nSys.timezone()\n\n[1] \"Asia/Seoul\"\n\nSys.Date()\n\n[1] \"2023-01-19\"\n\nSys.time()\n\n[1] \"2023-01-19 11:46:42 KST\"\n\n\nSys.timezone() 함수는 현재 타임존을 출력합니다. Sys.Date() 함수는 현재 날짜를, Sys.time() 함수는 날짜와 시간을 출력합니다.\n’2018-12-31’과 같이 사용자가 보기에는 날짜 형태이지만 문자열 형태로 데이터가 들어오는 경우, 이를 날짜 형태로 변경해야 할 경우가 있습니다.\n\nx = c('2021-07-01', '2021-08-01', '2021-09-01')\nx_date = as.Date(x)\n\nstr(x_date)\n\n Date[1:3], format: \"2021-07-01\" \"2021-08-01\" \"2021-09-01\"\n\n\nas.Date() 함수를 이용하면 문자열을 손쉽게 날짜 형태로 변경할 수 있습니다. str() 함수는 데이터의 형태를 확인하는 함수로써, Date 형태임이 확인됩니다.\n\ny = c('07/01/2015', '08/01/2015', '09/01/2015')\n\nas.Date(y, format = '%m/%d/%Y')\n\n[1] \"2015-07-01\" \"2015-08-01\" \"2015-09-01\"\n\n\nYYYY-MM-DD 형태가 아닌 다른 형태(MM/DD/YYYY)로 입력된 경우, format을 직접 입력하여 Date 형태로 변경할 수 있습니다.\nYYYY는 연, MM은 월, DD는 일을 나타냅니다.\n\nlubridate 패키지를 이용한 날짜 다루기\nlubridate 패키지를 이용할 경우 날짜 형태와 관련된 다양한 작업을 수행할 수 있습니다.\n\nlibrary(lubridate)\n\nLoading required package: timechange\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nx = c('2021-07-01', '2021-08-01', '2021-09-01')\ny = c('07/01/2015', '08/01/2015', '09/01/2015')\n\nymd(x)\n\n[1] \"2021-07-01\" \"2021-08-01\" \"2021-09-01\"\n\nmdy(y)\n\n[1] \"2015-07-01\" \"2015-08-01\" \"2015-09-01\"\n\n\nlubridate 패키지를 이용할 경우 YYYY-MM-DD 형태는 ymd(), MM-DD-YYYY 형태는 mdy() 함수를 사용해 손쉽게 Date 형태로 변경할 수 있습니다. 이 외에도 lubridate에는 Date 형태로 변경하기 위한 다양한 함수가 존재합니다.\n\n\n\n\nlubridate 패키지의 Date 형태 변경 함수\n \n  \n    순서 \n    함수 \n  \n \n\n  \n    연, 월, 일 \n    ymd() \n  \n  \n    연, 일, 월 \n    ydm() \n  \n  \n    월, 일, 연 \n    mdy() \n  \n  \n    일, 월, 연 \n    dmy() \n  \n  \n    시, 분 \n    hm() \n  \n  \n    시, 분, 초 \n    hms() \n  \n  \n    연, 월, 일, 시, 분, 초 \n    ymd_hms() \n  \n\n\n\n\n\nlubridate 패키지에는 날짜 관련 정보를 추출할 수 있는 다양한 함수가 존재합니다.\n\n\n\n\nlubridate 패키지의 날짜 관련 정보 추출 함수\n \n  \n    정보 \n    함수 \n  \n \n\n  \n    연 \n    year() \n  \n  \n    월 \n    month() \n  \n  \n    주 \n    week() \n  \n  \n    연도 내 일수 \n    yday() \n  \n  \n    월 내 일수 \n    mday() \n  \n  \n    주 내 일수 \n    wday() \n  \n  \n    시 \n    hour() \n  \n  \n    분 \n    minute() \n  \n  \n    초 \n    second() \n  \n  \n    타임존 \n    tz() \n  \n\n\n\n\n\n\nx = c('2021-07-01', '2021-08-01', '2021-09-01')\n\nyear(x)\n\n[1] 2021 2021 2021\n\nmonth(x)\n\n[1] 7 8 9\n\nweek(x)\n\n[1] 26 31 35\n\n\nyear(), month(), week() 함수를 통해 년도, 월, 주 정보를 확인할 수 있습니다.\n\nz = '2021-09-15'\n\nyday(z)\n\n[1] 258\n\nmday(z)\n\n[1] 15\n\nwday(z)\n\n[1] 4\n\n\nyday(), mday(), wday() 함수는 각각 해당 년도에서 몇번째 일인지, 해당 월에서 몇번째 일인지, 해당 주에서 몇번째 일인지를 계산합니다.\n\nx = ymd('2021-07-01', '2021-08-01', '2021-09-01') \n\nx + years(1) - days(c(2, 9, 21))\n\n[1] \"2022-06-29\" \"2022-07-23\" \"2022-08-11\"\n\n\n날짜에서 연과 월, 일자를 더하거나 빼는 계산 역시 가능합니다. 먼저 year() 함수를 통해 1년씩을 더 하였으며, days() 함수를 통해 각각의 일자 만큼을 뺍니다.\n\n\n날짜 순서 생성하기\n숫자와 마찬가지로 seq() 함수를 이용할 경우 날짜 벡터를 생성할 수 있습니다.\n\nseq(ymd('2015-01-01'), ymd('2021-01-01'), by ='years')\n\n[1] \"2015-01-01\" \"2016-01-01\" \"2017-01-01\" \"2018-01-01\" \"2019-01-01\"\n[6] \"2020-01-01\" \"2021-01-01\"\n\n\n2015년 1월 1일부터 2021년 1월 1일까지 1년을 기준으로 벡터가 생성됩니다.\n\nseq(ymd('2021-09-01'), ymd('2021-09-30'), by ='2 days')\n\n [1] \"2021-09-01\" \"2021-09-03\" \"2021-09-05\" \"2021-09-07\" \"2021-09-09\"\n [6] \"2021-09-11\" \"2021-09-13\" \"2021-09-15\" \"2021-09-17\" \"2021-09-19\"\n[11] \"2021-09-21\" \"2021-09-23\" \"2021-09-25\" \"2021-09-27\" \"2021-09-29\"\n\n\n지정한 일수인 2일 단위로 날짜 벡터를 생성할 수도 있습니다. 이 외에도 by 인자를 통해 원하는 기간 단위의 벡터를 생성할 수 있습니다.\n아래 페이지에는 lubridate 패키지의 자세한 사용법이 나와 있습니다.\n\nhttps://lubridate.tidyverse.org/"
  },
  {
    "objectID": "r_basic.html#데이터-구조-다루기",
    "href": "r_basic.html#데이터-구조-다루기",
    "title": "R 기초 배우기",
    "section": "데이터 구조 다루기",
    "text": "데이터 구조 다루기\nR에서 자주 사용되는 데이터구조는 벡터(Vector), 리스트(List), 데이터프레임(Dataframe) 입니다.\n\n벡터 다루기\n벡터는 R의 가장 기본적인 데이터 구조로써 integer, double, logical, character로 이루어져 있습니다. 벡터를 만드는 방법에 대해서는 앞서 다루었습니다.\n\nvec_integer = 8:17\n\nvec_integer\n\n [1]  8  9 10 11 12 13 14 15 16 17\n\n\n\nvec_double = c(0.5, 0.6, 0.2)\n\nvec_double\n\n[1] 0.5 0.6 0.2\n\n\n\nvec_char = c('a', 'b', 'c')\n\nvec_char\n\n[1] \"a\" \"b\" \"c\"\n\n\ninteger의 경우 start:end 형태를 통해서, 그 외에는 c() 함수를 통해 벡터를 만들 수 있습니다.\n\nc('a', 'b', 'c', 1, 2, 3)\n\n[1] \"a\" \"b\" \"c\" \"1\" \"2\" \"3\"\n\n\n숫자와 문자가 같이 벡터로 묶일 경우, 숫자는 모두 문자 형태로 변경됩니다.\n\nc(1, 2, 3, TRUE, FALSE)\n\n[1] 1 2 3 1 0\n\n\nTRUE와 FALSE는 참 혹은 거짓을 나타내는 논리값(logical) 입니다. 숫자와 논리값이 같이 묶일 경우 TRUE는 1, FALSE는 0으로 치환된 후 숫자 형태로 변경됩니다.\n\nc('a', 'b', 'c', TRUE, FALSE)\n\n[1] \"a\"     \"b\"     \"c\"     \"TRUE\"  \"FALSE\"\n\n\n문자와 논리값이 같이 묶일 경우 모두 문자 형태로 변경됩니다. 이처럼 문자와 다른 형태가 묶일 경우엔 모든 데이터가 문자로 변경됩니다.\n이번에는 기존의 벡터에 새로운 값을 추가해보겠습니다.\n\nv1 = 8:17\n\nc(v1, 18:22)\n\n [1]  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n\n\n기존 8부터 17까지의 숫자로 이루어진 v1 벡터에, c() 함수를 이용하여 새로운 값을 추가할 수 있습니다.\n만약 벡터에서 원하는 부분의 데이터를 추출하려면 대괄호([])를 이용하면 됩니다.\n\nv1[2]\n\n[1] 9\n\nv1[2:4]\n\n[1]  9 10 11\n\nv1[c(2, 4, 6)]\n\n[1]  9 11 13\n\n\n대괄호 안에 숫자를 입력하면, 벡터에서 해당 순서의 데이터가 추출됩니다. c(2,4,6)과 같이 특정 위치를 지정하여 데이터를 추출할 수도 있습니다.\n\nv1[-1]\n\n[1]  9 10 11 12 13 14 15 16 17\n\nv1[-c(2, 4, 6, 8)]\n\n[1]  8 10 12 14 16 17\n\n\n마이너스 기호를 입력하면, 해당 순서를 제외한 데이터가 추출됩니다.\n\nv1 < 12\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\nv1[v1 < 12]\n\n[1]  8  9 10 11\n\nv1[v1 < 12 | v1 > 15]\n\n[1]  8  9 10 11 16 17\n\n\n먼저 v1 < 12를 입력하면 해당 조건에 해당하는 부분은 TRUE, 그렇지 않은 부분은 FALSE를 반환합니다. 그 후 대괄호 안에 다시 결과를 입력하면 TRUE에 해당하는 순서의 데이터만 반환합니다. 이처럼 대괄호 내부에 조건을 설정하여 원하는 데이터를 추출할 수도 있습니다.\n\n\n리스트 다루기\n먼저 리스트를 생성합니다.\n\nl = list(1:3, 'a', c(TRUE, FALSE, TRUE), c(2.5, 4.2))\n\nstr(l)\n\nList of 4\n $ : int [1:3] 1 2 3\n $ : chr \"a\"\n $ : logi [1:3] TRUE FALSE TRUE\n $ : num [1:2] 2.5 4.2\n\n\n첫번째 원소는 정수(int), 두번째 원소는 문자(chr), 세번째 원소는 논리값(logi), 네번째 원소는 숫자(num)로 이루어져 있습니다. 이처럼 리스트는 각 원소간 타입이나 길이가 달라도 데이터가 결합할 수 특징이 있습니다.\n\nl2 = list(1:3, list(letters[1:5], c(TRUE, FALSE, TRUE)))\n\nstr(l2)\n\nList of 2\n $ : int [1:3] 1 2 3\n $ :List of 2\n  ..$ : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ : logi [1:3] TRUE FALSE TRUE\n\n\n위 예제에서 두번째 원소는 리스트로 구성되어 있습니다. 이처럼 리스트 내에 또 다른 리스트를 생성하는 것 역시 가능합니다.\n이번에는 기존 리스트에 새로운 원소를 추가하도록 하겠습니다.\n\nl3 = list(1:3, 'a', c(TRUE, FALSE, TRUE))\nl4 = append(l3, list(c(2.5, 4.2)))\n\nprint(l4)\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[1] 2.5 4.2\n\n\nappend() 함수를 이용하면 기존 리스트에 추가로 원소를 붙일 수 있습니다.\n\nl4$item5 = 'new list item'\n\nprint(l4)\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1]  TRUE FALSE  TRUE\n\n[[4]]\n[1] 2.5 4.2\n\n$item5\n[1] \"new list item\"\n\n\n또한 기존 리스트에 달러 사인($)을 입력할 경우, 원소에 이름이 생성되며 데이터가 추가됩니다.\n리스트에서 원하는 데이터를 추출할 때는, 벡터와 동일하게 대괄호를 이용하면 됩니다.\n\nl4[1]\n\n[[1]]\n[1] 1 2 3\n\nl4[c(1,3)]\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1]  TRUE FALSE  TRUE\n\n\n원소에 이름이 있을 경우, 이를 이용해 추출도 가능합니다.\n\nl4['item5']\n\n$item5\n[1] \"new list item\"\n\n\n원소의 이름인 item5를 입력하면 해당 원소만 반환합니다.\n\nl4[[1]]\n\n[1] 1 2 3\n\nl4$item5\n\n[1] \"new list item\"\n\n\n대괄호를 두번, 혹은 달러 사인($)을 이용해 데이터를 추출할 경우 원소 내의 형태가 반환되며, 위의 예제들과는 다르게 벡터 형태가 반환되었습니다.\n\nl4[[1]]\n\n[1] 1 2 3\n\nl4[[1]][3]\n\n[1] 3\n\n\n특정 원소의 항목을 추출하기 위해서는 [[와 [를 함께 사용합니다. 위 예제는 l4 리스트의 첫번째 원소에서 3번째 항목을 추출하게 됩니다.\n\n\n데이터프레임 다루기\n데이터프레임은 R에서 가장 널리 사용되는 형식으로써, 각 컬럼이 다른 형태를 가질 수 있습니다.\n\ndf = data.frame (col1 = 1:3,\n                 col2 = c (\"this\", \"is\", \"text\"),\n                 col3 = c (TRUE, FALSE, TRUE),\n                 col4 = c (2.5, 4.2, pi))\n\nstr(df)\n\n'data.frame':   3 obs. of  4 variables:\n $ col1: int  1 2 3\n $ col2: chr  \"this\" \"is\" \"text\"\n $ col3: logi  TRUE FALSE TRUE\n $ col4: num  2.5 4.2 3.14\n\n\ncol1은 숫자(int), col2는 문자(chr), col3는 논리연산자(logi), col4는 숫자(num)로 구성되어 있습니다. 또한 벡터 혹은 리스트를 이용해 데이터프레임을 생성할 수도 있습니다.\n\nv1 = 1:3\nv2 = c (\"this\", \"is\", \"text\")\nv3 = c (TRUE, FALSE, TRUE)\n\ndata.frame(col1 = v1, col2 = v2, col3 = v3)\n\n  col1 col2  col3\n1    1 this  TRUE\n2    2   is FALSE\n3    3 text  TRUE\n\n\nv1, v2, v3는 각각 숫자, 문자, 논리연산로 구성된 벡터입니다. 이를 data.frame() 함수 내에 입력할 경우 col1, col2, col3 열 이름에 해당 데이터들이 입력됩니다. 주의해야 할 점은 각 벡터의 길이가 동일해야 데이터프레임 형태를 만들 수 있습니다.\n\nl = list (item1 = 1:3,\n          item2 = c (\"this\", \"is\", \"text\"),\n          item3 = c (2.5, 4.2, 5.1))\nl\n\n$item1\n[1] 1 2 3\n\n$item2\n[1] \"this\" \"is\"   \"text\"\n\n$item3\n[1] 2.5 4.2 5.1\n\ndata.frame(l)\n\n  item1 item2 item3\n1     1  this   2.5\n2     2    is   4.2\n3     3  text   5.1\n\n\n리스트 역시 data.frame() 함수를 이용할 경우, 각 원소명을 열이름으로 한 데이터프레임이 생성됩니다. 이 경우 역시 각 원소의 데이터 길이가 동일해야 합니다.\n기존 데이터프레임에 행방향 혹은 열방향으로 데이터를 추가할 수 있습니다.\n\ndf\n\n  col1 col2  col3     col4\n1    1 this  TRUE 2.500000\n2    2   is FALSE 4.200000\n3    3 text  TRUE 3.141593\n\nv4 = c (\"A\", \"B\", \"C\")\n\ncbind(df, v4)\n\n  col1 col2  col3     col4 v4\n1    1 this  TRUE 2.500000  A\n2    2   is FALSE 4.200000  B\n3    3 text  TRUE 3.141593  C\n\n\ncbind() 함수는 ’column bind’의 약어로써, 기존 데이터프레임에 새로운 열을 추가합니다.\n\nv5 = c (4, \"R\", F, 1.1)\n\nrbind(df, v5)\n\n  col1 col2  col3             col4\n1    1 this  TRUE              2.5\n2    2   is FALSE              4.2\n3    3 text  TRUE 3.14159265358979\n4    4    R FALSE              1.1\n\n\nrbind() 함수는 ’row bind’의 약어로써, 기존 데이터프레임에 새로운 행을 추가합니다. 주의할 점은 각 행의 데이터 형태가 기존 데이터의 형태와 일치해야 합니다.\n데이터프레임 역시 대괄호를 이용해 데이터를 추출할 수 있으며, 공백으로 두면 모든 행(열)을 선택하게 됩니다.\n\ndf\n\n  col1 col2  col3     col4\n1    1 this  TRUE 2.500000\n2    2   is FALSE 4.200000\n3    3 text  TRUE 3.141593\n\ndf[2:3, ]\n\n  col1 col2  col3     col4\n2    2   is FALSE 4.200000\n3    3 text  TRUE 3.141593\n\n\n데이터프레임중 2:3, 즉 두번째부터 세번째까지의 행과 모든 열을 선택하게 됩니다.\n\ndf[ , c('col2', 'col4')]\n\n  col2     col4\n1 this 2.500000\n2   is 4.200000\n3 text 3.141593\n\n\n행이름 혹은 열이름 직접 입력하여 해당값을 추출할 수도 있습니다. 위 예제에서는 열이름이 col2와 col4인 열을 추출합니다.\n\ndf[, 2]\n\n[1] \"this\" \"is\"   \"text\"\n\ndf[, 2, drop = FALSE]\n\n  col2\n1 this\n2   is\n3 text\n\n\n만일 하나의 열만 선택시 결과가 벡터 형태로 추출되며, drop = FALSE 인자를 추가해주면 데이터프레임의 형태가 유지되어 추출됩니다.\n\n\n결측치 처리하기\n결측치란 누락된 데이터를 의미하며, 데이터 분석에서 결측치를 처리하는 것은 매우 중요합니다. R에서 결측치는 NA로 표시되며, is.na() 함수를 통해 결측치 여부를 확인할 수 있습니다.\n\nx = c(1:4, NA, 6:7, NA)\nx\n\n[1]  1  2  3  4 NA  6  7 NA\n\nis.na(x)\n\n[1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n\n\n데이터가 NA인 경우에는 TRUE, 그렇지 않을 경우 FALSE를 반환합니다. 데이터프레임에도 해당 함수를 적용할 수 있습니다.\n\ndf = data.frame (col1 = c (1:3, NA),\n                 col2 = c (\"this\", NA,\"is\", \"text\"),\n                 col3 = c (TRUE, FALSE, TRUE, TRUE),\n                 col4 = c (2.5, 4.2, 3.2, NA)\n                 )\ndf\n\n  col1 col2  col3 col4\n1    1 this  TRUE  2.5\n2    2 <NA> FALSE  4.2\n3    3   is  TRUE  3.2\n4   NA text  TRUE   NA\n\nis.na(df)\n\n      col1  col2  col3  col4\n[1,] FALSE FALSE FALSE FALSE\n[2,] FALSE  TRUE FALSE FALSE\n[3,] FALSE FALSE FALSE FALSE\n[4,]  TRUE FALSE FALSE  TRUE\n\n\n데이터에 결측치가 있는 경우 계산이 불가능하다는 문제가 발생합니다.\n\ny = c(1, 3, NA, 4)\nmean(y)\n\n[1] NA\n\n\n데이터의 중간에 결측치인 NA가 존재하여 평균을 계산할 수 없으며, 이 외에도 모든 연산이 불가능하게 됩니다.\n\nmean(y, na.rm = TRUE)\n\n[1] 2.666667\n\n\nna.rm에서 rm은 ’remove’의 약어입니다. 즉 해당 인자를 TRUE로 설정할 경우 NA를 제외하고 연산을 수행합니다. 따라서 1,3,4의 평균인 \\(\\frac{1+3+4}{3} = 2.6667\\)이 계산됩니다.\n일반적으로 결측치가 있는 경우 해당 데이터는 문제가 있다고 판단하여 제거하거나, 다른 데이터로 대체하여 채워넣기도 합니다. 먼저 결측치가 있는 데이터를 제거하는 법을 알아보겠습니다.\n\ndf = data.frame (col1 = c (1:4),\n                 col2 = c (\"this\", NA,\"is\", \"text\"),\n                 col3 = c (TRUE, FALSE, TRUE, TRUE),\n                 col4 = c (2.5, 4.2, 3.2, 5.0)\n)\ndf\n\n  col1 col2  col3 col4\n1    1 this  TRUE  2.5\n2    2 <NA> FALSE  4.2\n3    3   is  TRUE  3.2\n4    4 text  TRUE  5.0\n\n\n두번째 행 col2 열에 결측치가 있으므로, 해당 부분을 제거해주도록 합니다.\n\nna.omit(df)\n\n  col1 col2 col3 col4\n1    1 this TRUE  2.5\n3    3   is TRUE  3.2\n4    4 text TRUE  5.0\n\n\nna.omit() 함수를 이용하면 NA가 위치한 부분의 데이터가 제거됩니다.\n\nx = c(1:4, NA, 6:7, NA)\nx\n\n[1]  1  2  3  4 NA  6  7 NA\n\n\n이번에는 위와 같이 결측치가 있는 경우, 다른 데이터로 대체하도록 하겠습니다.\n\nx[is.na(x)] = mean(x, na.rm = TRUE)\nx\n\n[1] 1.000000 2.000000 3.000000 4.000000 3.833333 6.000000 7.000000 3.833333\n\n\nmean() 함수 내부를 통해 값들의 평균을 구한 후, is.na() 함수를 통해 결측치가 위치한 부분의 데이터를 평균값인 3.833 으로 대체하였습니다. 이 외에도 결측치를 대체하는데는 다양한 방법이 존재합니다."
  },
  {
    "objectID": "r_basic.html#데이터-불러오기-및-내보내기",
    "href": "r_basic.html#데이터-불러오기-및-내보내기",
    "title": "R 기초 배우기",
    "section": "데이터 불러오기 및 내보내기",
    "text": "데이터 불러오기 및 내보내기\n일반적으로 사람들은 csv 혹은 엑셀 파일로 저장된 데이터를 주고 받으며 데이터 분석을 하는 경우가 많습니다. 해당 형식의 파일을 R로 불러오는 법 그리고 저장하는 법에 대해 알아보겠습니다.\ncsv와 엑셀 샘플 파일의 주소는 다음과 같습니다.\n\nhttps://github.com/hyunyulhenry/dmmr_quant/blob/main/kospi.csv\nhttps://github.com/hyunyulhenry/dmmr_quant/blob/main/kospi.xlsx\n\n아래의 코드를 실행하면 해당 파일을 PC에 다운로드 받을 수 있습니다.\n\ndownload.file('https://raw.githubusercontent.com/hyunyulhenry/dmmr_quant/master/kospi.csv', 'kospi.csv')\n\ndownload.file('https://github.com/hyunyulhenry/dmmr_quant/raw/main/kospi.xlsx', 'kospi.xlsx', mode = 'wb')\n\n\n워킹 디렉터리\n데이터를 불러오거나 내보낼 때 초보자들이 가장 많이 하는 실수가 워킹 디렉터리를 제대로 설정하지 않는 것입니다. 워킹 디렉터리(Working Directory)란 현재 사용중인 폴더를 의미하며, 현재 워킹 디렉터리는 콘솔창 상단 getwd() 함수를 통해 확인할 수 있습니다.\n\ngetwd()\n# [1] \"C:/Users/henry/Documents/R/fin_ds\"\n\n파일들이 A 폴더에 있는데 워킹 디렉터리가 B 폴더인 상태에서는 파일을 불러올 수 없으므로, 해당 파일들이 현재 워킹 디렉터리에 있어야 합니다.\n워킹 디렉터리를 변경할때는 setwd() 함수를 통해 위치를 직접 지정해주어도 되지만, R 스튜디오의 파일 창을 이용하면 손쉽게 변경할 수 있습니다. 먼저 파일 창 상단의 […] 부분을 클릭합니다.\n\n\n\n\n\n워킹 디렉터리 변경\n\n\n\n\n탐색기 화면에서 원하는 폴더를 선택한 후 하단의 [Open]을 클릭합니다.\n\n\n\n\n\n워킹 디렉터리 변경 (2)\n\n\n\n\n탐색기 화면에 선택한 폴더의 파일들이 보입니다. 이제 [Move → Set As Working Directory]를 클릭하면 콘솔창에 해당 폴더를 워킹 디렉터리로 변경하는 코드가 입력되면서, 워킹 디렉터리 위치가 해당 폴더로 변경됩니다.\n\n\n\n\n\n워킹 디렉터리 변경 (3)\n\n\n\n\n\n\ncsv 파일 불러오기 및 저장하기\n먼저 R의 기본함수인 read.csv() 함수를 이용하면 매우 손쉽게 csv 파일을 불러올 수 있습니다.\n\nkospi = read.csv('kospi.csv')\n# kospi = read.csv('kospi.csv', fileEncoding=\"UTF-8-BOM\")\nhead(kospi)\n\n        Date   Close   Ret\n1 2020-01-02 2175.17 -1.02\n2 2020-01-03 2176.46  0.06\n3 2020-01-06 2155.07 -0.98\n4 2020-01-07 2175.54  0.95\n5 2020-01-08 2151.31 -1.11\n6 2020-01-09 2186.45  1.63\n\n\nreadr 패키지의 read._csv() 함수를 이용하면 기본 함수 대비 10배 정도 빠르게 데이터를 불러올 수 있으며, 훨씬 다양한 조건을 입력할 수도 있습니다.\n\nlibrary(readr)\nkospi2 = read_csv('kospi.csv')\n\nRows: 248 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (2): Close, Ret\ndate (1): Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(kospi2)\n\n# A tibble: 6 × 3\n  Date       Close   Ret\n  <date>     <dbl> <dbl>\n1 2020-01-02 2175. -1.02\n2 2020-01-03 2176.  0.06\n3 2020-01-06 2155. -0.98\n4 2020-01-07 2176.  0.95\n5 2020-01-08 2151. -1.11\n6 2020-01-09 2186.  1.63\n\n\nR의 데이터를 csv로 저장하는 법은 기본함수의 write.csv() 혹은 readr 패키지의 write_csv() 함수를 이용하면 됩니다.\n\n# using write.csv\nwrite.csv(kospi, 'kospi2.csv', row.names = FALSE)\n\n# using write_csv\nwrite_csv(kospi2, 'kospi2.csv')\n\n기본함수인 write.csv() 의 경우 행이름이 자동으로 새로운 열로 추가되어 저장되므로, 이를 원하지 않을 경우 row.names = FALSE 를 추가로 입력해주어야 합니다.\n\n\n엑셀 파일 불러오기 및 저장하기\nR의 기본함수 중에는 엑셀 파일을 불러오는 함수가 없지만, 해당 작업을 수행하는 다양한 패키지가 존재합니다. 그 중에서 readr 패키지와 쌍둥이 격인 readxl 패키지를 이용해보겠습니다.\n먼저 해당 패키지의 read_excel() 함수를 이용해 엑셀 파일을 불러올 수 있습니다.\n\nlibrary(readxl)\nkospi_excel = read_excel('kospi.xlsx', sheet = 'kospi')\nhead(kospi_excel)\n\n# A tibble: 6 × 3\n  Date                Close   Ret\n  <dttm>              <dbl> <dbl>\n1 2020-01-02 00:00:00 2175. -1.02\n2 2020-01-03 00:00:00 2176.  0.06\n3 2020-01-06 00:00:00 2155. -0.98\n4 2020-01-07 00:00:00 2176.  0.95\n5 2020-01-08 00:00:00 2151. -1.11\n6 2020-01-09 00:00:00 2186.  1.63\n\n\n엑셀은 여러 시트로 구성된 경우가 많으며, sheet에 특정 시트명을 입력하면 해당 시트의 내용을 불러오게 됩니다. 만일 아무값도 입력하지 않을 경우 가장 첫번째 시트의 데이터를 불러옵니다.\n반대로 R의 데이터를 엑셀로 저장하는 방법은 writexl 패키지의 write_xlsx() 함수를 이용하면 됩니다.\n\nlibrary(writexl)\nwrite_xlsx(kospi_excel, 'kospi_excel.xlsx')"
  },
  {
    "objectID": "r_basic.html#효율성과-가독성-높이기",
    "href": "r_basic.html#효율성과-가독성-높이기",
    "title": "R 기초 배우기",
    "section": "효율성과 가독성 높이기",
    "text": "효율성과 가독성 높이기\n이번에는 프로그래밍의 효율성을 높이기 위해 자주 사용되는 함수와 루프 구문, 그리고 가독성을 높이기 위한 파이프 오퍼레이터에 대해 알아보겠습니다.\n\n함수\n동일하거나 비슷한 작업을 반복해야 하는 경우 매번 실행하거나 복사-붙여넣기 하기 보다는 경우 함수를 작성하여 사용하면 매우 효율적으로 작업이 가능합니다.\n함수는 크게 세가지 요소로 구성됩니다.\n\nbody(): 함수 내부의 코드\nformals(): 인자(argument) 내역\nenvironment(): 함수의 변수에 대한 위치\n\n예를 들어 금융 자산의 현재 가치는 다음과 같이 계산됩니다.\n\\[PV = FV / (1+r)^n\\]\n\nPV: 현재 가치\nFV: 미래 가치\nr: 할인률\nn: 기간\n\n즉, 1년 뒤에 110만원을 받는 돈의 현재가치는 \\(110만원/(1+0.1)^1 = 100만원\\) 이라 볼 수 있습니다. 이러한 값을 구하기 위해 매번 계산기를 사용하기 보다는 함수를 이용하면, 훨씬 효율적인 작업이 가능합니다. 위의 수식을 함수로 나타내면 다음과 같습니다.\n\nPV = function(FV, r, n) {\n  PV = FV / (1+r)^n\n  return(round(PV, 2))\n}\n\nR에서는 함수명 = function(인자) {함수 내용}의 형태로 함수를 만들수 있으며, 반환하고자 하는 결과를 return() 내부에 작성합니다. 함수의 구성요소 세가지를 한번 확인해보도록 하겠습니다.\n\nbody(PV)\n\n{\n    PV = FV/(1 + r)^n\n    return(round(PV, 2))\n}\n\n\n먼저 body는 함수 내부의 코드를 의미합니다.\n\nformals(PV)\n\n$FV\n\n\n$r\n\n\n$n\n\n\nformals에는 함수의 인자인 FV, r, n이 있습니다.\n\nenvironment(PV)\n\n<environment: R_GlobalEnv>\n\n\n함수는 GlobalEnv에 위치하고 있습니다.\n이제 해당함수를 이용해 현재가치를 계산해보도록 하겠습니다.\n\nPV(FV = 1000, r = 0.08, n = 5)\n\n[1] 680.58\n\n\n\\(1000 / (1.08)^5\\)의 값인 680.58이 간단하게 계산됩니다.\n\nPV(1000, 0.08, 5)\n\n[1] 680.58\n\n\n만약 인자의 리스트를 생략하면, 입력한 순서대로 값이 입력됩니다.\n\nPV(r = 0.08, FV = 1000, n = 5)\n\n[1] 680.58\n\n\n인자의 내역을 정확하게 지정해준다면, 순서대로 입력하지 않아도 됩니다.\n\nPV(1000, 0.08)\n\nError in PV(1000, 0.08): argument \"n\" is missing, with no default\n\n\nPV() 함수에 필요한 인자는 3개인 반면, 2개만 입력하였으므로 에러가 발생합니다.\n\nPV = function(FV = 1000, r = .08, n = 5) {\n  PV = FV / (1 + r)^n\n  return(round(PV, 2))\n}\nPV(1000, 0.08)\n\n[1] 680.58\n\n\n만일 함수의 인자에 디폴트 값이 입력되어 있다면, 함수 실행시 이를 생략하여도 디폴트 값이 입력됩니다. 위 예제에서는 n 디폴트 값으로 5가 들어가있으며, PV() 함수 내에 입력값이 3개만 입력될 경우 마지막 인자는 디폴트 값인 5를 적용합니다.\n\n\n루프 구문\n루프 및 각종 구문을 이용하여 휴율적인 작업을 하는것도 가능합니다.\n\nif 구문\n먼저 if 구문은 다음과 같이 구성됩니다.\n\nif (test_expression) {\n  statement\n}\n\n괄호 안의 test_expression이 TRUE일 경우에만 statement 코드가 실행됩니다. 간단한 예제를 살펴보겠습니다.\n\nx = c(8, 3, -2, 5)\nif (any(x < 0)) {\n  print('x contains negative number')\n}\n\n[1] \"x contains negative number\"\n\n\nany() 함수는 적어도 하나의 값이 참이면 참으로 출력하는 함수입니다. 즉, 위의 코드는 x중 하나라도 0보다 작은 값이 있으면 x contains negative number라는 문장을 출력하며, -2가 0보다 작으므로 해당 문장을 출력합니다.\n\ny = c (8, 3, 2, 5)\nif (any (y < 0)) {\n  print (\"y contains negative numbers\")\n}\n\n이번에는 y에 0보다 작은 값이 없으므로, 구문이 실행되지 않아 문장을 출력하지 않습니다. 이처럼 if 구문만 존재할 시 이를 만족하지 않는 경우 아무런 구문도 실행되지 않습니다. 만일 조건을 충족하지 않을 때 동작을 추가하고 싶을 경우 if else 구문을 사용하며, 이는 if의 조건을 만족하지 않을 경우 else에 해당하는 구문이 실행됩니다.\n\nif (test_expression) {\n  statement 1\n} else {\n  statement 2\n}\n\n만일 test_expression 구문이 TRUE이면 statement 1이 실행되며, 그렇지 않을 경우 statement 2가 실행됩니다. 실제 예제를 살펴봅시다.\n\ny = c (8, 3, 2, 5)\nif (any (y < 0)) {\n  print (\"y contains negative numbers\")\n} else {\n  print (\"y contains all positive numbers\")\n}\n\n[1] \"y contains all positive numbers\"\n\n\ny에 음수가 존재하는 if 구문이 FALSE 이므로, else에 해당하는 메세지가 출력됩니다. ifelse 구문은 ifelse() 함수로 간단히 나타낼 수도 있습니다.\n\nx = c (8, 3, 2, 5)\nifelse(any(x < 0), \"x contains negative numbers\", \"x contains all positive numbers\")\n\n[1] \"x contains all positive numbers\"\n\n\n해당 함수는 ifelse(test, yes, no) 형태로 입력되며, test를 충족하면 yes가 그렇지 않으면 no가 실행됩니다. 위의 예에서는 x에 0보다 작은 값이 없으므로, no에 해당하는 내용이 실행됩니다.\n또한 if와 else 사이에 else if 조건을 통해, 여러 조건을 추가할 수도 있습니다.\n\nx = 7\nif (x >= 10) {\n  print (\"x exceeds acceptable tolerance levels\")\n} else if(x >= 0 & x < 10) {\n  print (\"x is within acceptable tolerance levels\")\n} else {\n  print (\"x is negative\")\n}\n\n[1] \"x is within acceptable tolerance levels\"\n\n\n위 조건은 다음과 같습니다.\n\nx가 10 이상일 경우 x exceeds acceptable tolerance levels을 출력합니다.\n만일 x가 10 이상, 10 미만일경우 x is within acceptable tolerance levels을 출력합니다.\n그렇지 않을 경우 x is negative을 출력합니다.\n\nx는 7 이므로 else에 해당하는 내용이 출력됩니다.\n\n\nfor loop 구문\nfor loop 구문은 특정한 부분의 코드가 반복적으로 수행될 수 있도록 하며, 다음과 같이 구성됩니다.\n\nfor (i in 1:100) {\n  <code: do stuff here with i>\n}\n\n먼저 i에 1이 들어간 뒤 code에 해당하는 부분이 실행됩니다. 그 후, i에 2가 들어간 뒤 다시 code가 실행되며 이 작업이 100까지 반복됩니다. 실제 예제를 살펴보도록 하겠습니다.\n\nfor (i in 2016:2020) {\n  output = paste(\"The year is\", i)\n  print(output)\n}\n\n[1] \"The year is 2016\"\n[1] \"The year is 2017\"\n[1] \"The year is 2018\"\n[1] \"The year is 2019\"\n[1] \"The year is 2020\"\n\n\ni에 2010부터 2016 까지 대입되며, The year is라는 문자와 결합해 결과가 출력됩니다.\n\n\napply 계열 함수\napply 계열의 함수는 loop 구문과 비슷한 역할을 하며, 코드를 훨씬 간결하게 표현할 수 있습니다. 먼저 가장 기본이 되는 apply() 함수는 데이터프레임의 행 혹은 열단위 계산에 자주 사용됩니다. 해당 함수는 다음과 같이 구성됩니다.\n\napply(x, MARGIN, FUN, ...)\n\n\nx: 매트릭스, 데이터프레임, 혹은 어레이\nMARGIN: 함수가 적용될 벡. 1은 행을, 2는 열을, c(1, 2)는 행과 열을 의미\nFUN: 적용될 함수\n…: 기타\n\n실제 사용 예제를 살펴보도록 하겠습니다.\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n먼저 위 데이터에서 각 열의 평균을 구하도록 합니다.\n\napply(mtcars, 2, mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\nmtcars에서 2 즉 열의 방향으로 평균(mean)을 구합니다.\nlapply() 함수는 리스트에 적용되며, 결과 또한 리스트로 반환됩니다. 해당 함수는 다음과 같이 구성됩니다.\n\nlapply(x, FUN, ...)\n\n\nx: 리스트\nFUN: 적용될 함수\n…: 기타\n\n실제 사용 예제를 살펴보도록 하겠습니다.\n\ndata = list(item1 = 1:4,\n            item2 = rnorm(10),\n            item3 = rnorm(20, 1),\n            item4 = rnorm(100, 5))\ndata\n\n$item1\n[1] 1 2 3 4\n\n$item2\n [1] -0.07803677  0.34528930  0.24123272  2.12271649 -0.24268921  0.15019808\n [7] -1.29730605 -0.24498821  0.82491208  0.73694285\n\n$item3\n [1]  2.14916389  0.09457198  0.43886226 -0.14178466 -0.08788615  2.17000804\n [7]  1.11730177  2.37215003  1.78099767  2.87371514  0.22884739 -1.13561394\n[13]  0.82305281  2.18234699  0.74901547 -0.07807229  1.27411424 -1.85805396\n[19]  0.50041789  0.29959941\n\n$item4\n  [1] 3.845677 6.346175 5.702130 4.433262 5.143062 5.630058 5.106129 5.712749\n  [9] 5.365632 4.549840 4.703099 3.204055 4.064953 4.053563 3.749023 6.034962\n [17] 5.098655 4.614874 5.430305 7.036957 5.428117 5.655748 5.178410 6.512606\n [25] 4.903527 4.793071 5.944694 5.877035 5.863774 2.977316 3.814279 4.218002\n [33] 5.169310 5.227394 4.180548 4.065250 3.303716 3.584812 5.293762 4.915582\n [41] 5.318408 6.278995 6.190713 5.271649 6.727153 6.774421 5.162596 4.702474\n [49] 3.661957 5.844167 5.419217 5.641847 4.907697 4.818963 5.327333 4.791673\n [57] 4.374438 3.625897 4.671151 3.660372 6.278229 5.185486 5.238512 5.546644\n [65] 5.169373 5.928340 3.963499 5.830896 4.797710 5.673212 4.119432 3.858571\n [73] 5.294791 2.220774 5.778793 5.615639 4.734069 4.445286 4.599742 5.102730\n [81] 6.296583 5.548517 5.334213 3.269071 5.146833 3.609878 4.808975 4.773671\n [89] 5.211274 3.176673 4.889657 3.791547 5.453448 3.566748 3.768427 5.473204\n [97] 5.197567 5.059498 3.923349 5.022317\n\n\n4개의 원소로 구성된 리스트에서 각 원소의 평균을 구하고자 할 경우, 리스트에 적용되는 apply인 lapply() 함수를 사용해야 합니다.\n\nlapply(data, mean)\n\n$item1\n[1] 2.5\n\n$item2\n[1] 0.2558271\n\n$item3\n[1] 0.7876377\n\n$item4\n[1] 4.926064\n\n\nlapply() 함수를 통해 각 항목의 평균을 구할 수 있으며, 결과 또한 리스트 형태로 반환됩니다. 해당 함수는 좀더 복잡한 형태로 응용도 가능합니다.\n\nbeaver_data = list(beaver1 = beaver1, beaver2 = beaver2)\nlapply(beaver_data, head)\n\n$beaver1\n  day time  temp activ\n1 346  840 36.33     0\n2 346  850 36.34     0\n3 346  900 36.35     0\n4 346  910 36.42     0\n5 346  920 36.55     0\n6 346  930 36.69     0\n\n$beaver2\n  day time  temp activ\n1 307  930 36.58     0\n2 307  940 36.73     0\n3 307  950 36.93     0\n4 307 1000 37.15     0\n5 307 1010 37.23     0\n6 307 1020 37.24     0\n\n\n위 데이터의 각 항목에서 열 별 평균을 구하고자 할 경우 lapply() 함수 만으로는 계산이 불가능합니다. 이러한 경우 해당 함수 내부에 새로운 함수인 function()을 정의하여 복잡한 계산을 수행할 수 있습니다.\n\nlapply(beaver_data, function(x) {\n  round(apply(x, 2, mean), 2)\n})\n\n$beaver1\n    day    time    temp   activ \n 346.20 1312.02   36.86    0.05 \n\n$beaver2\n    day    time    temp   activ \n 307.13 1446.20   37.60    0.62 \n\n\nfunction(x)를 통해 각 항목에 적용될 함수를 직접 정의할 수 있습니다. 우리가 정의한 함수는 apply() 함수를 통해 열의 방향으로 평균을 구한 뒤 소수 둘째 자리까지 반올림을 하는 것이며, 해당 함수가 리스트의 모든 원소에 적용됩니다.\n마지막으로 살펴볼 sapply() 함수는 lapply() 함수와 거의 동일하며, 결과가 리스트가 아닌 벡터 혹은 매트릭스로 출력된다는 점만 차이가 있습니다.\n\nlapply(beaver_data, function(x) {\n  round(apply(x, 2, mean), 2)\n})\n\n$beaver1\n    day    time    temp   activ \n 346.20 1312.02   36.86    0.05 \n\n$beaver2\n    day    time    temp   activ \n 307.13 1446.20   37.60    0.62 \n\nsapply(beaver_data, function(x) {\n  round(apply(x, 2, mean), 2)\n})\n\n      beaver1 beaver2\nday    346.20  307.13\ntime  1312.02 1446.20\ntemp    36.86   37.60\nactiv    0.05    0.62\n\n\nsapply() 함수는 각 원소에 적용된 값을 벡터로 하는 매트릭스 형태로 결과값이 출력됩니다.\n\n\n기타 함수\n열과 행이 합계나 평균처럼 일반적으로 많이 사용되는 계산에는 apply() 함수보다 간단하게 표현할 수 있는 함수들이 있습니다.\n\nrowSums(mtcars)\n\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive \n            328.980             329.795             259.580             426.135 \n  Hornet Sportabout             Valiant          Duster 360           Merc 240D \n            590.310             385.540             656.920             270.980 \n           Merc 230            Merc 280           Merc 280C          Merc 450SE \n            299.570             350.460             349.660             510.740 \n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental \n            511.500             509.850             728.560             726.644 \n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla \n            725.695             213.850             195.165             206.955 \n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 \n            273.775             519.650             506.085             646.280 \n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa \n            631.175             208.215             272.570             273.683 \n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E \n            670.690             379.590             694.710             288.890 \n\ncolSums(mtcars)\n\n     mpg      cyl     disp       hp     drat       wt     qsec       vs \n 642.900  198.000 7383.100 4694.000  115.090  102.952  571.160   14.000 \n      am     gear     carb \n  13.000  118.000   90.000 \n\n\nrowSums() 함수는 행의 합계를, colSums() 함수는 열의 합계는 구하며 이는 apply(mtcars, 1 or 2, sum) 과 동일합니다.\n\nrowMeans(mtcars)\n\n          Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive \n           29.90727            29.98136            23.59818            38.73955 \n  Hornet Sportabout             Valiant          Duster 360           Merc 240D \n           53.66455            35.04909            59.72000            24.63455 \n           Merc 230            Merc 280           Merc 280C          Merc 450SE \n           27.23364            31.86000            31.78727            46.43091 \n         Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental \n           46.50000            46.35000            66.23273            66.05855 \n  Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla \n           65.97227            19.44091            17.74227            18.81409 \n      Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 \n           24.88864            47.24091            46.00773            58.75273 \n   Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa \n           57.37955            18.92864            24.77909            24.88027 \n     Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E \n           60.97182            34.50818            63.15545            26.26273 \n\ncolMeans(mtcars)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\nrowMeans() 함수와 colMeans() 함수 역시 각각 행과 열의 평균을 구합니다.\n\n\n\n파이프 오퍼레이터\n파이프 오퍼레이터는 R에서 동일한 데이터를 대상으로 연속으로 작업하게 해주는 오퍼레이터(연산자)입니다.\n흔히 프로그래밍에서 x라는 데이터를 F()라는 함수에 넣어 결괏값을 확인하고 싶으면 F(x)의 방법을 사용합니다. 예를 들어 3과 5라는 데이터 중 큰 값을 찾으려면 max(3,5)를 통해 확인합니다. 이를 통해 나온 결괏값을 또 다시 G()라는 함수에 넣어 결괏값을 확인하려면 비슷한 과정을 거칩니다. max(3,5)를 통해 나온 값의 제곱근을 구하려면 result = max(3,5)를 통해 첫 번째 결괏값을 저장하고, sqrt(result)를 통해 두 번째 결괏값을 계산합니다. 물론 sqrt(max(3,5))와 같은 표현법으로 한 번에 표현할 수 있습니다.\n이러한 표현의 단점은 계산하는 함수가 많아질수록 저장하는 변수가 늘어나거나 괄호가 지나치게 길어진다는 것입니다. 그러나 파이프 오퍼레이터인 %>%를 사용하면 함수 간의 관계를 매우 직관적으로 표현하고 이해할 수 있습니다. 이를 정리하면 아래 표와 같습니다.\n\n\n\n\n파이프 오퍼레이터의 표현과 내용 비교\n \n  \n    내용 \n    표현 방법 \n  \n \n\n  \n    F(x) \n    x %>% F \n  \n  \n    G(F(x)) \n    x %>% F %>% G \n  \n\n\n\n\n\n간단한 예제를 통해 파이프 오퍼레이터의 사용법을 살펴보겠습니다. 먼저 다음과 같은 10개의 숫자가 있다고 가정합니다.\n\nx = c(0.3078, 0.2577, 0.5523, 0.0564, 0.4685,\n      0.4838, 0.8124, 0.3703, 0.5466, 0.1703)\n\n우리가 원하는 과정은 다음과 같습니다.\n\n각 값들의 로그값을 구할 것\n로그값들의 계차를 구할 것\n구해진 계차의 지수값을 구할 것\n소수 둘째 자리까지 반올림할 것\n\n즉 log(), diff(), exp(), round()에 대한 값을 순차적으로 구하고자 합니다.\n\nx1 = log(x)\nx2 = diff(x1)\nx3 = exp(x2)\nround(x3, 2)\n\n[1] 0.84 2.14 0.10 8.31 1.03 1.68 0.46 1.48 0.31\n\n\n첫 번째 방법은 단계별 함수의 결괏값을 변수에 저장하고 저장된 변수를 다시 불러와 함수에 넣고 계산하는 방법입니다. 전반적인 계산 과정을 확인하기에는 좋지만 매번 변수에 저장하고 불러오는 과정이 매우 비효율적이며 코드도 불필요하게 길어집니다.\n\nround(exp(diff(log(x))), 2)\n\n[1] 0.84 2.14 0.10 8.31 1.03 1.68 0.46 1.48 0.31\n\n\n두 번째는 괄호를 통해 감싸는 방법입니다. 앞선 방법에 비해 코드는 짧아졌지만, 계산 과정을 알아보기에는 매우 불편한 방법으로 코드가 짜여 있습니다.\n\nlibrary(magrittr)\n\nx %>% log() %>% diff() %>% exp() %>% round(., 2)\n\n[1] 0.84 2.14 0.10 8.31 1.03 1.68 0.46 1.48 0.31\n\n\n마지막으로 파이프 오퍼레이터를 사용하는 방법입니다. 코드도 짧으며 계산 과정을 한눈에 파악하기도 좋습니다. 맨 왼쪽에는 원하는 변수를 입력하며, %>% 뒤에는 차례대로 계산하고자 하는 함수를 입력합니다. 변수의 입력값을 ()로 비워둘 경우, 오퍼레이터의 왼쪽에 있는 값이 입력 변수가 됩니다. 반면 round()와 같이 입력값이 두 개 이상 필요하면 마침표(.)가 오퍼레이터의 왼쪽 값으로 입력됩니다.\n파이프 오퍼레이터는 크롤링뿐만 아니라 모든 코드에 사용할 수 있습니다. 이를 통해 훨씬 깔끔하면서도 데이터 처리 과정을 직관적으로 이해할 수 있습니다."
  },
  {
    "objectID": "r_basic.html#데이터-구조-변형하기",
    "href": "r_basic.html#데이터-구조-변형하기",
    "title": "R 기초 배우기",
    "section": "데이터 구조 변형하기",
    "text": "데이터 구조 변형하기\n기본적인 R 사용법을 익혔다면 데이터의 모양을 바꾸고 가공하여 내가 원하는 결과물을 출력해야 합니다. 해당 작업은 tidyr 패키지와 dplyr 패키지를 이용해 매우 효율적으로 수행할 수 있으며, dplyr 패키지의 함수 중 일부는 SQL 구문과 매우 유사합니다.\n\ntidyr 패키지를 이용한 데이터 모양 바꾸기\n깔끔한 데이터(tidy data)는 다음과 같이 구성되어 있습니다.\n\n각 변수(variable)는 열로 구성됩니다.\n각 관측값(observation)은 행으로 구성됩니다.\n각 타입의 관측치는 테이블을 구성합니다.\n\n\n\n\n\n\ntidy 데이터 요건\n\n\n\n\ntidyr 패키지에는 이러한 깔끔한 데이터를 만드는데 필요한 여러 함수가 있습니다.\n\npivot_longer(): 세로로 긴 데이터 만들기\n먼저 가로로 긴(Wide) 데이터를 세로로 길게 만드는데는 pivot_longer() 함수가 사용됩니다. 이 함수는 여러 열을 key-value 페어로 변형해줍니다.\n\nlibrary(tidyr)\n\n\nAttaching package: 'tidyr'\n\n\nThe following object is masked from 'package:magrittr':\n\n    extract\n\ntable4a\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n* <chr>        <int>  <int>\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\n위 예제에는 세 국가의 1999, 2000년 데이터가 있습니다. 이 중 country를 제외한 연도별 데이터를 세로로 길게 만들도록 하겠습니다.\n\nlong = table4a %>% pivot_longer(names_to = 'years', values_to = 'cases', -country)\nprint(long)\n\n# A tibble: 6 × 3\n  country     years  cases\n  <chr>       <chr>  <int>\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\n열 이름에 해당하던 1999, 2000 데이터가 names_to에 입력한 years 열에 입력되었습니다. 또한 각 관측값이 values_to에 입력한 cases 열에 입력되었습니다. country 앞에는 마이너스(-) 기호를 붙여 해당 열은 그대로 유지됩니다.\n\n\n\n\n\n  \n    \n\n\n \n  \n    country \n    1999 \n    2000 \n  \n \n\n  \n    Afghanistan \n    745 \n    2666 \n  \n  \n    Brazil \n    37737 \n    80488 \n  \n  \n    China \n    212258 \n    213766 \n  \n\n\n\n \n    \n\n\n \n  \n    country \n    years \n    cases \n  \n \n\n  \n    Afghanistan \n    1999 \n    745 \n  \n  \n    Afghanistan \n    2000 \n    2666 \n  \n  \n    Brazil \n    1999 \n    37737 \n  \n  \n    Brazil \n    2000 \n    80488 \n  \n  \n    China \n    1999 \n    212258 \n  \n  \n    China \n    2000 \n    213766 \n  \n\n\n\n \n  \n\n\n\n\n\n\n\npivot_wider(): 가로로 긴 데이터 만들기\npivot_longer() 함수와 반대로, pivot_wider() 함수를 이용할 경우 세로로 긴 데이터를 가로로 길게 만들 수 있습니다. 위의 데이터에 year 열에 있는 항목들을 열 이름으로, cases 열에 있는 항목들을 가로로 길게 되돌려 보겠습니다.\n\nback2wide = long %>% pivot_wider(names_from = 'years', values_from = 'cases')\nprint(back2wide)\n\n# A tibble: 3 × 3\n  country     `1999` `2000`\n  <chr>        <int>  <int>\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nnames_from와 values_from에 각각 열이름 및 관측값에 해당하는 값을 입력하면, 원래대로 가로로 긴 테이블 형태가 되었습니다.\n\n\nseparate(): 하나의 열을 여러 열로 나누기\n\ntable3\n\n# A tibble: 6 × 3\n  country      year rate             \n* <chr>       <int> <chr>            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\nrate 열에는 데이터가 ###/#### 형태로 들어가 있습니다. / 기호를 기준으로 앞과 뒤로 각각 나누어보도록 하겠습니다.\n\ntable3 %>% \n  separate(rate, into = c(\"cases\", \"population\"))\n\n# A tibble: 6 × 4\n  country      year cases  population\n  <chr>       <int> <chr>  <chr>     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\nseparate() 함수를 사용할 경우 rate 열이 “/”를 기준으로 into에 입력한 cases와 population 열로 분리됩니다.\n\ntable3 %>% \n  separate(rate, into = c(\"cases\", \"population\"), remove = FALSE)\n\n# A tibble: 6 × 5\n  country      year rate              cases  population\n  <chr>       <int> <chr>             <chr>  <chr>     \n1 Afghanistan  1999 745/19987071      745    19987071  \n2 Afghanistan  2000 2666/20595360     2666   20595360  \n3 Brazil       1999 37737/172006362   37737  172006362 \n4 Brazil       2000 80488/174504898   80488  174504898 \n5 China        1999 212258/1272915272 212258 1272915272\n6 China        2000 213766/1280428583 213766 1280428583\n\n\nremove = FALSE 인자를 추가해주면 원래의 열이 사라지지 않고 유지됩니다.\n\n\nunite(): 여러 열을 하나로 합치기\nseparate() 함수와는 반대로, unite() 함수를 이용시 여러 열을 하나로 합칠 수 있습니다.\n\ntable5\n\n# A tibble: 6 × 4\n  country     century year  rate             \n* <chr>       <chr>   <chr> <chr>            \n1 Afghanistan 19      99    745/19987071     \n2 Afghanistan 20      00    2666/20595360    \n3 Brazil      19      99    37737/172006362  \n4 Brazil      20      00    80488/174504898  \n5 China       19      99    212258/1272915272\n6 China       20      00    213766/1280428583\n\n\n이번에는 century와 year 열을 합친 후 새로운 열을 만들어보도록 하겠습니다.\n\ntable5 %>% \n  unite(new, century, year, sep = \"_\")\n\n# A tibble: 6 × 3\n  country     new   rate             \n  <chr>       <chr> <chr>            \n1 Afghanistan 19_99 745/19987071     \n2 Afghanistan 20_00 2666/20595360    \n3 Brazil      19_99 37737/172006362  \n4 Brazil      20_00 80488/174504898  \n5 China       19_99 212258/1272915272\n6 China       20_00 213766/1280428583\n\n\ncentury 열과 year열이 합쳐진 후 new 열에 입력되었으며, sep 인자를 통해 구분자는 “_”로 설정하였습니다.\n\n\ntidyr 패키지의 기타 함수\n먼저 fill() 함수는 결측치를 채워주는 역할을 합니다.\n\nscore = tribble(\n  ~ person, ~ Math, ~ Computer,\n  \"Henry\",  1,         7,\n  NA,       2,         10,\n  NA,       NA,        9,\n  \"David\",  1,         4\n)\n\nscore\n\n# A tibble: 4 × 3\n  person  Math Computer\n  <chr>  <dbl>    <dbl>\n1 Henry      1        7\n2 <NA>       2       10\n3 <NA>      NA        9\n4 David      1        4\n\n\nscore의 2번째와 3번째 행에 NA 데이터가 있어 이를 채워줄 필요가 있습니다.\n\nscore %>% \n  fill(person, Math)\n\n# A tibble: 4 × 3\n  person  Math Computer\n  <chr>  <dbl>    <dbl>\n1 Henry      1        7\n2 Henry      2       10\n3 Henry      2        9\n4 David      1        4\n\n\nfill() 함수는 결측치가 있을 경우, 각 열의 이전 데이터를 이용해 채워줍니다. 반면에 NA 데이터를 특정 값으로 변경할 수도 있습니다.\n\nscore %>% replace_na(replace = list(person = \"unknown\", Math = 0))\n\n# A tibble: 4 × 3\n  person   Math Computer\n  <chr>   <dbl>    <dbl>\n1 Henry       1        7\n2 unknown     2       10\n3 unknown     0        9\n4 David       1        4\n\n\nreplace_na() 함수를 이용해 person 열의 NA 데이터를 unknown으로, Math열의 NA 데이터를 0으로 변경하였습니다.\n\n\n\ndplyr 패키지를 이용한 데이터 변형하기\n데이터를 필터링 하거나, 요약하거나, 정렬하거나, 새로운 변수를 만드는 등 데이터 분석을 위해서는 데이터 변형하고 가공해야 하는 경우가 많습니다. R의 기본 함수도 이러한 기능을 제공하지만, dplyr 패키지를 이용할 경우 훨씬 빠르고 효율적으로 업무를 처리할 수 있습니다.\nnycflights13 패키지의 flights 데이터셋을 예제로 사용하도록 하겠습니다.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:kableExtra':\n\n    group_rows\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(nycflights13)\n\nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      517        515       2     830     819      11 UA     \n 2  2013     1     1      533        529       4     850     830      20 UA     \n 3  2013     1     1      542        540       2     923     850      33 AA     \n 4  2013     1     1      544        545      -1    1004    1022     -18 B6     \n 5  2013     1     1      554        600      -6     812     837     -25 DL     \n 6  2013     1     1      554        558      -4     740     728      12 UA     \n 7  2013     1     1      555        600      -5     913     854      19 B6     \n 8  2013     1     1      557        600      -3     709     723     -14 EV     \n 9  2013     1     1      557        600      -3     838     846      -8 B6     \n10  2013     1     1      558        600      -2     753     745       8 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nselect(): 원하는 열 선택하기\nselect() 함수를 이용해 특정 열만을 선택할 수 있습니다.\n\nflights %>% select(year, month, day) %>% head()\n\n# A tibble: 6 × 3\n   year month   day\n  <int> <int> <int>\n1  2013     1     1\n2  2013     1     1\n3  2013     1     1\n4  2013     1     1\n5  2013     1     1\n6  2013     1     1\n\n\nselect() 함수 내에 선택하고자 하는 열을 입력하여 year, month, day 열을 선택했습니다.\n\nflights %>% select(year:day) %>% head()\n\n# A tibble: 6 × 3\n   year month   day\n  <int> <int> <int>\n1  2013     1     1\n2  2013     1     1\n3  2013     1     1\n4  2013     1     1\n5  2013     1     1\n6  2013     1     1\n\n\n콜론(:)을 이용해 year부터 day 까지의 열을 한번에 선택할 수도 있습니다.\n\nflights %>% select(-(year:day)) %>% head()\n\n# A tibble: 6 × 16\n  dep_time sched…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier flight tailnum origin\n     <int>   <int>   <dbl>   <int>   <int>   <dbl> <chr>    <int> <chr>   <chr> \n1      517     515       2     830     819      11 UA        1545 N14228  EWR   \n2      533     529       4     850     830      20 UA        1714 N24211  LGA   \n3      542     540       2     923     850      33 AA        1141 N619AA  JFK   \n4      544     545      -1    1004    1022     -18 B6         725 N804JB  JFK   \n5      554     600      -6     812     837     -25 DL         461 N668DN  LGA   \n6      554     558      -4     740     728      12 UA        1696 N39463  EWR   \n# … with 6 more variables: dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n마이너스(-)를 이용할 경우 해당 열을 제외한 모든 열이 선택됩니다.\n\nflights %>% select(starts_with(\"dep\")) %>% head()\n\n# A tibble: 6 × 2\n  dep_time dep_delay\n     <int>     <dbl>\n1      517         2\n2      533         4\n3      542         2\n4      544        -1\n5      554        -6\n6      554        -4\n\n\nselect() 함수 내에 starts_with() 함수를 이용할 경우, 해당 문자로 시작하는 열을 모두 선택할 수 있습니다. 이 외에도 ends_with() 함수는 해당 문자로 끝나는 열울, contains() 함수는 해당 문자가 포함되는 열을 선택합니다.\n\n\nrename(): 열이름 바꾸기\n\nflights %>% rename(tail_num = tailnum) %>% select(tail_num) %>% head()\n\n# A tibble: 6 × 1\n  tail_num\n  <chr>   \n1 N14228  \n2 N24211  \n3 N619AA  \n4 N804JB  \n5 N668DN  \n6 N39463  \n\n\nrename() 함수를 이용해 tailnum 이던 열 이름을 tail_num 으로 변경하였습니다. 해당 함수는 rename(변경하고자 하는 이름 = 변경전 이름) 형태로 입력해야 합니다.\n\n\nfilter(): 필터링\n특정 열에 원하는 데이터가 있는 부분만 필터링을 해야하는 경우가 많으며, filter() 함수를 사용해 손쉽게 해결할 수 있습니다.\n\nflights %>% filter(month == 3, day == 1) %>% head()\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     3     1        4        2159     125     318      56     142 B6     \n2  2013     3     1       50        2358      52     526     438      48 B6     \n3  2013     3     1      117        2245     152     223    2354     149 B6     \n4  2013     3     1      454         500      -6     633     648     -15 US     \n5  2013     3     1      505         515     -10     746     810     -24 UA     \n6  2013     3     1      521         530      -9     813     827     -14 UA     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nfilter() 함수 내에 필터링 하고자 하는 조건, 즉 month가 3이고 day가 1인 조건을 입력하면 해당 조건에 부합하는 행만 선택됩니다.\n\n\nsummarize(): 요약값 계산하기\n요약 통계값은 summarize() 함수를 통해 쉽게 계산할 수 있습니다.\n\nflights %>% summarize(max_dep = max(dep_time, na.rm = TRUE),\n                      min_dep = min(dep_time, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  max_dep min_dep\n    <int>   <int>\n1    2400       1\n\n\nsummarize() 함수를 통해 max_dep에는 dep_time의 최대값을, min_dep에는 dep_time의 최소값을 구해줍니다. na.rm 인자를 TRUE로 설정하여 NA 데이터는 제거해 줍니다.\n\n\ngroup_by(): 원하는 조건으로 그룹화\n각 그룹별 통계량을 계산할 때는 group_by() 함수를 통해 그룹을 묶고, 계산하는 것이 편합니다.\n\nby_day = flights %>% group_by(year, month, day)\nby_day %>% head()\n\n# A tibble: 6 × 19\n# Groups:   year, month, day [1]\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     1      517         515       2     830     819      11 UA     \n2  2013     1     1      533         529       4     850     830      20 UA     \n3  2013     1     1      542         540       2     923     850      33 AA     \n4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n5  2013     1     1      554         600      -6     812     837     -25 DL     \n6  2013     1     1      554         558      -4     740     728      12 UA     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nyear, month, day를 기준으로 그룹을 묶었습니다. 아직 계산을 하지 않았으므로 출력되는 데이터프레임 자체는 원래와 동일하며, Groups를 통해 어떠한 조건으로 그룹이 묶여있는지 확인됩니다.\n\nby_day %>%\n  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%\n  head()\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 4\n# Groups:   year, month [1]\n   year month   day delay\n  <int> <int> <int> <dbl>\n1  2013     1     1 11.5 \n2  2013     1     2 13.9 \n3  2013     1     3 11.0 \n4  2013     1     4  8.95\n5  2013     1     5  5.73\n6  2013     1     6  7.15\n\n\n해당 데이터는 그룹별로 묶여 있으므로, summarise() 함수를 적용하면 각 그룹(year, month, day) 별로 dep_delay의 평균을 구합니다.\n\nflights %>% group_by(dest) %>%\n  summarize(\n    count = n(),\n    dist = mean(distance, na.rm = TRUE),\n    delay = mean(arr_delay, na.rm = TRUE)\n)\n\n# A tibble: 105 × 4\n   dest  count  dist delay\n   <chr> <int> <dbl> <dbl>\n 1 ABQ     254 1826   4.38\n 2 ACK     265  199   4.85\n 3 ALB     439  143  14.4 \n 4 ANC       8 3370  -2.5 \n 5 ATL   17215  757. 11.3 \n 6 AUS    2439 1514.  6.02\n 7 AVL     275  584.  8.00\n 8 BDL     443  116   7.05\n 9 BGR     375  378   8.03\n10 BHM     297  866. 16.9 \n# … with 95 more rows\n\n\n한 번에 여러 통계량을 계산할 수도 있으며, n()은 데이터의 갯수를 의미합니다.\n\n\narrange(): 데이터 정렬하기\narrange() 함수를 통해 원하는 열을 기준으로 데이터를 순서대로 정렬할 수 있으며, 오름차순을 기본으로 합니다.\n\nflights %>% arrange(year, month, day) %>% head()\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     1      517         515       2     830     819      11 UA     \n2  2013     1     1      533         529       4     850     830      20 UA     \n3  2013     1     1      542         540       2     923     850      33 AA     \n4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n5  2013     1     1      554         600      -6     812     837     -25 DL     \n6  2013     1     1      554         558      -4     740     728      12 UA     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\narrange() 함수 내에 입력한 [year -> month -> day] 순으로 오름차순 정렬이 됩니다.\n\nflights %>% arrange(desc(dep_delay)) %>% head()\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     9      641         900    1301    1242    1530    1272 HA     \n2  2013     6    15     1432        1935    1137    1607    2120    1127 MQ     \n3  2013     1    10     1121        1635    1126    1239    1810    1109 MQ     \n4  2013     9    20     1139        1845    1014    1457    2210    1007 AA     \n5  2013     7    22      845        1600    1005    1044    1815     989 MQ     \n6  2013     4    10     1100        1900     960    1342    2211     931 DL     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n정렬하고자 하는 열에 desc() 함수를 추가할 경우, 오름차순이 아닌 내림차순으로 정렬됩니다.\n\n\n*_join(): 데이터 합치기\n여러 테이블을 하나로 합치기 위해 *_join() 함수를 이용합니다. 합치는 방법은 그림 @ref(fig:joinimg2)과 표 @ref(tab:joindesc2) 같이 크게 네가지 종류가 있습니다.\n\n\n\n\n\n*_ join() 함수의 종류\n\n\n\n\n\n\n\n\njoin 함수의 종류\n \n  \n    함수 \n    내용 \n  \n \n\n  \n    inner_join() \n    교집합 \n  \n  \n    full_join() \n    합집합 \n  \n  \n    left_join() \n    좌측 기준 \n  \n  \n    right_join() \n    우측 기준 \n  \n\n\n\n\n\n다음 두개의 데이터 테이블을 이용하도록 합니다.\n\nflights2 = flights %>% \n  select(year:day, hour, tailnum, carrier)\nflights2 %>% head()\n\n# A tibble: 6 × 6\n   year month   day  hour tailnum carrier\n  <int> <int> <int> <dbl> <chr>   <chr>  \n1  2013     1     1     5 N14228  UA     \n2  2013     1     1     5 N24211  UA     \n3  2013     1     1     5 N619AA  AA     \n4  2013     1     1     5 N804JB  B6     \n5  2013     1     1     6 N668DN  DL     \n6  2013     1     1     5 N39463  UA     \n\nairlines %>% head()\n\n# A tibble: 6 × 2\n  carrier name                    \n  <chr>   <chr>                   \n1 9E      Endeavor Air Inc.       \n2 AA      American Airlines Inc.  \n3 AS      Alaska Airlines Inc.    \n4 B6      JetBlue Airways         \n5 DL      Delta Air Lines Inc.    \n6 EV      ExpressJet Airlines Inc.\n\n\nflights2 데이터에는 항공사 명의 약자인 carrier가 있으며, airlines 데이터는 해당 약자의 풀 네임이 적혀있습니다. left_join() 함수를 이용해 왼쪽 데이터프레임을 기준으로 데이터를 합치도록 하며, 두 데이터 모두 carrier 열이 있으므로 이를 기준으로 데이터가 합치도록 하겠습니다.\n\nflights2 %>%\n  left_join(airlines, by = \"carrier\") %>%\n  head()\n\n# A tibble: 6 × 7\n   year month   day  hour tailnum carrier name                  \n  <int> <int> <int> <dbl> <chr>   <chr>   <chr>                 \n1  2013     1     1     5 N14228  UA      United Air Lines Inc. \n2  2013     1     1     5 N24211  UA      United Air Lines Inc. \n3  2013     1     1     5 N619AA  AA      American Airlines Inc.\n4  2013     1     1     5 N804JB  B6      JetBlue Airways       \n5  2013     1     1     6 N668DN  DL      Delta Air Lines Inc.  \n6  2013     1     1     5 N39463  UA      United Air Lines Inc. \n\n\nflights2에서 모든 데이터를 가져오며, airlines의 name 열이 기존 테이블에 추가됩니다. join 구문에 대한 더욱 상세한 예제 및 애니메이션은 다음 주소를 참조하시기 바랍니다.\n\nhttps://github.com/gadenbuie/tidyexplain\n\n\n\nmutate(): 새로운 열 생성하기\nmutate() 함수를 사용해 기존 열끼리 계산을 하여 새로운 열을 생성할 수 있습니다.\n\nflights_sml = flights %>%\n  select(\n    year:day, \n    ends_with(\"delay\"), \n    distance, \n    air_time\n    )\n\nflights_sml %>%\n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60\n    ) %>%\n  head()\n\n# A tibble: 6 × 9\n   year month   day dep_delay arr_delay distance air_time  gain speed\n  <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl> <dbl> <dbl>\n1  2013     1     1         2        11     1400      227    -9  370.\n2  2013     1     1         4        20     1416      227   -16  374.\n3  2013     1     1         2        33     1089      160   -31  408.\n4  2013     1     1        -1       -18     1576      183    17  517.\n5  2013     1     1        -6       -25      762      116    19  394.\n6  2013     1     1        -4        12      719      150   -16  288.\n\n\n먼저 flights에서 일부 열을 선택하여 flights_sml에 저장합니다.그 후, mutate() 함수를 이용해 새로운 열을 만들어 줍니다. gain 열에는 dep_delay와 arr_delay의 차이가, speed 열에는 distance와 air_time 비에 60을 곱한 값이 새롭게 생성됩니다.\n\nflights_sml %>%\n  mutate(\n    across(c('dep_delay', 'arr_delay'), ~ .x * 60)\n    ) %>%\n  head()\n\n# A tibble: 6 × 7\n   year month   day dep_delay arr_delay distance air_time\n  <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl>\n1  2013     1     1       120       660     1400      227\n2  2013     1     1       240      1200     1416      227\n3  2013     1     1       120      1980     1089      160\n4  2013     1     1       -60     -1080     1576      183\n5  2013     1     1      -360     -1500      762      116\n6  2013     1     1      -240       720      719      150\n\n\n동일한 함수를 한번에 여러행에 적용해야 할 때는 mutate() 함수 내에 across() 함수를 입력합니다. 위 예제에서는 dep_delay과 arr_delay열의 데이터에 60을 곱해주었습니다. across() 함수의 자세한 사용법은 다소 생소하고 어려울 수 있으므로 아래 페이지의 내용을 따라가며 익히시는게 좋습니다.\n\nhttps://dplyr.tidyverse.org/reference/across.html"
  },
  {
    "objectID": "r_basic.html#그래픽-문법",
    "href": "r_basic.html#그래픽-문법",
    "title": "R 기초 배우기",
    "section": "그래픽 문법",
    "text": "그래픽 문법\nR에서 기본적으로 제공하는 plot() 함수를 이용해도 시각화가 충분히 가능합니다. 다음 사이트에는 기본 함수를 이용해 표현할 수 있는 다양한 그림이 나와 있습니다.\n\nhttp://www.sthda.com/english/wiki/r-base-graphs\n\n그러나 기본 함수를 이용하여 시각화를 할 경우 다음과 같은 문제가 있습니다.\n\n서로 다른 형태의 그림을 나타내기 위해 각각 다른 함수를 이용해야 함\n표현할 수 있는 그림에 한계가 있음\n원하는 형태로 꾸미기가 복잡함\n\nggplot2 패키지는 데이터 과학자들에게 가장 많이 사랑받는 패키지 중 하나이며, ggplot() 함수를 사용하면 그림을 훨씬 아름답게 표현할 수 있으며 다양한 기능들을 매우 쉽게 사용할 수도 있습니다. 처음에는 함수의 문법이 다소 어색하지만, 해당 패키지의 근본이 되는 철학인 그래픽 문법(The Grammar of Graphics)를 이해하고 조금만 연습해본다면, 충분히 손쉽게 사용이 가능합니다.\n그래픽 문법(Grammar of Graphics)은 릴랜드 윌킨스(Leland Wilkinson)의 책 The Grammar of Graphics(Wilkinson 2012)에서 따온 것으로써, 데이터를 어떻게 표현할 것인지에 대한 내용입니다.\n\n문법은 언어의 표현을 풍부하게 만든다. 단어만 있고 문법이 없는 언어가 있다면(단어 = 문장), 오직 단어의 갯수만큼만 생각을 표현할 수 있다. 문장 내에서 단어가 어떻게 구성되는 지를 규정함으로써, 문법은 언어의 범위를 확장한다.\n— Leland Wilkinson, 《The Grammar of Graphics》 그래픽 문법에서 말하는 요소는 다음과 같습니다.\n\n\nData: 시각화에 사용될 데이터\nAesthetics: 데이터를 나타내는 시각적인 요소(x축, y축, 사이즈, 색깔, 모양 등)\nGeometrics: 데이터를 나타내는 도형\nFacets: 하위 집합으로 분할하여 시각화\nStatistics: 통계값을 표현\nCoordinates: 데이터를 표현 할 이차원 좌표계\nTheme: 그래프를 꾸밈\n\n\n\n\n\n\nThe Grammar of Graphics\n\n\n\n\nggplot2 패키지의 앞글자가 gg인 것에서 알 수 있듯이, 해당 패키지는 그래픽 문법을 토대로 시각화를 표현하며, 전반적인 시각화의 순서는 그래픽 문법의 순서와 같습니다. ggplot2 패키지의 특징은 각 요소를 연결할 때 플러스(+) 기호를 사용한다는 점이며, 이는 그래픽 문법의 순서에 따라 요소들을 쌓아나간 후 최종적인 그래픽을 완성하는 패키지의 특성 때문입니다.\n아래 사이트에는 R에서 ggplot2와 기타 패키지를 이용해 표현할 수 있는 그림이 정리되어 있습니다.\n\nhttps://www.r-graph-gallery.com/"
  },
  {
    "objectID": "r_basic.html#데이터셋-다이아몬드",
    "href": "r_basic.html#데이터셋-다이아몬드",
    "title": "R 기초 배우기",
    "section": "데이터셋: 다이아몬드",
    "text": "데이터셋: 다이아몬드\nggplot2 패키지에는 데이터분석 및 시각화 연습을 위한 각종 데이터셋이 있으며, 그 중에서도 diamonds 데이터셋이 널리 사용됩니다. 먼저 해당 데이터를 불러오도록 하겠습니다.\n\nlibrary(ggplot2)\ndata(diamonds)\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\n데이터의 각 변수는 다음과 같습니다.\n\ncarat: 다이아몬드 무게\ncut: 컷팅의 가치\ncolor: 다이아몬드 색상\nclarity: 깨끗한 정도\ndepth: 깊이 비율, z / mean(x, y)\ntable: 가장 넓은 부분의 너비 대비 다이아몬드 꼭대기의 너비\nprice: 가격\nx: 길이\ny: 너비\nz: 깊이\n\n\n\n\n\n\ncolor\n\n\n\n\n\n\n\n\n\nclarity\n\n\n\n\n\n\n\n\n\ntable\n\n\n\n\n이 외에도 R에서 제공하는 다양한 데이터셋은 다음의 함수를 통해 확인할 수 있습니다.\n\ndata()\n\n\n\n [1] \"band_instruments\"       \"band_instruments2\"      \"band_members\"          \n [4] \"starwars\"               \"storms\"                 \"diamonds\"              \n [7] \"economics\"              \"economics_long\"         \"faithfuld\"             \n[10] \"luv_colours\"            \"midwest\"                \"mpg\"                   \n[13] \"msleep\"                 \"presidential\"           \"seals\"                 \n[16] \"txhousing\"              \"lakers\"                 \"airlines\"              \n[19] \"airports\"               \"flights\"                \"planes\"                \n[22] \"weather\"                \"fruit\"                  \"sentences\"             \n[25] \"words\"                  \"billboard\"              \"construction\"          \n[28] \"fish_encounters\"        \"population\"             \"relig_income\"          \n[31] \"smiths\"                 \"table1\"                 \"table2\"                \n[34] \"table3\"                 \"table4a\"                \"table4b\"               \n[37] \"table5\"                 \"us_rent_income\"         \"who\"                   \n[40] \"world_bank_pop\"         \"AirPassengers\"          \"BJsales\"               \n[43] \"BJsales.lead (BJsales)\" \"BOD\"                    \"CO2\"                   \n[46] \"ChickWeight\"            \"DNase\"                  \"EuStockMarkets\"        \n[49] \"Formaldehyde\"           \"HairEyeColor\""
  },
  {
    "objectID": "r_basic.html#data-aesthetics-geometrics",
    "href": "r_basic.html#data-aesthetics-geometrics",
    "title": "R 기초 배우기",
    "section": "Data, Aesthetics, Geometrics",
    "text": "Data, Aesthetics, Geometrics\n그래픽 문법의 순서에 맞춰 그림을 쌓아나가보도록 하겠습니다. 먼저 Data는 사용될 데이터이며, Aesthetics는 \\(x\\)축, \\(y\\)축, 사이즈 등 시각적인 요소를 의미합니다.\n\nggplot(data = diamonds, aes(x = carat, y = price))\n\n\n\n\n\n\n\n\n\\(x\\)축과 \\(y\\)축에 우리가 매핑한 carat과 price가 표현되었지만, 어떠한 모양(Geometrics)으로 시각화를 할지 정의하지 않았으므로 빈 그림이 생성됩니다. 다음으로 Geometrics을 통해 데이터를 그림으로 표현해주도록 하겠습니다.\n\nggplot(data = diamonds, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n사전에 정의된 Data와 Aesthetics 위에, 플러스(+) 기호를 통해 geom_point() 함수를 입력하여 산점도가 표현되었습니다. geom은 Geometrics의 약자이며, 이처럼 geom_*() 함수를 통해 원하는 형태로 시각화를 할 수 있습니다.\n일반적으로 Data는 ggplot() 함수 내에서 정의하기 보다는, dplyr 패키지의 함수들을 이용하여 데이터를 가공한 후 파이프 오퍼레이터(%>%)를 통해 연결합니다.\n\nlibrary(magrittr)\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_point(aes(color = cut, shape = cut))\n\nWarning: Using shapes for an ordinal variable is not advised\n\n\n\n\n\n\n\n\n\ndiamonds 데이터를 파이프 오퍼레이터로 이을 경우 그대로 시각화가 가능하며, ggplot() 함수 내에 데이터를 입력하지 않아도 됩니다.\ngeom_point() 내부에서 aes()를 통해 점의 색깔을 매핑해줄 수 있습니다. color = cut, shape = cut을 지정하여 cut에 따라 점의 색깔과 형태를 다르게 표현하였습니다. 이 외에도 size 등을 통해 그룹별로 그래프를 각각 다르게 표현할 수 있습니다."
  },
  {
    "objectID": "r_basic.html#facets",
    "href": "r_basic.html#facets",
    "title": "R 기초 배우기",
    "section": "Facets",
    "text": "Facets\nFacets은 여러 집합을 하나의 그림에 표현하기 보다 하위 집합으로 나누어 시각화하는 요소입니다.\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_point() +\n  facet_grid(. ~ cut)\n\n\n\n\n\n\n\n\nfacet_grid() 혹은 facet_wrap() 함수를 통해 그림을 분할할 수 있습니다. 물결 표시(~)를 통해 하위 집합으로 나누고자 하는 변수를 선택할 수 있으며, 위 예제에서는 cut에 따라 각기 다른 그림으로 표현되었습니다.\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_point() +\n  facet_grid(color ~ cut)\n\n\n\n\n\n\n\n\ncolor를 추가해 facet_grid(color ~ cut)를 입력하면 가로는 color, 세로는 cut으로 그림이 나누어집니다."
  },
  {
    "objectID": "r_basic.html#statistics",
    "href": "r_basic.html#statistics",
    "title": "R 기초 배우기",
    "section": "Statistics",
    "text": "Statistics\nStatistics는 통계값을 나타내는 요소입니다. 실무에서는 dplyr 패키지를 이용해 데이터의 통계값을 계산한 후 이를 그림으로 나타냅니다.\n\nlibrary(dplyr)\ndiamonds %>%\n  group_by(color) %>%\n  summarize(carat = mean(carat)) %>%\n  ggplot(aes(x = color, y = carat)) +\n  geom_col()\n\n\n\n\n\n\n\n\n그룹 별 carat의 평균을 계산한 후 시각화를 하였습니다."
  },
  {
    "objectID": "r_basic.html#coordinates",
    "href": "r_basic.html#coordinates",
    "title": "R 기초 배우기",
    "section": "Coordinates",
    "text": "Coordinates\nCoordinates는 좌표를 의미합니다. ggplot2에서는 `coord_*() 함수를 이용하여 \\(x\\)축 혹은 \\(y\\)축 정보를 변형할 수 있습니다.\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_point(aes(color = cut)) +\n  coord_cartesian(xlim = c(0, 3), ylim = c(0, 20000))\n\n\n\n\n\n\n\n\ncoord_cartesian() 함수를 통해 \\(x\\)축과 \\(y\\)축 범위를 지정해 줄 수 있습니다. xlim과 ylim 내부에 범위의 최소 및 최댓값을 지정해주면, 해당 범위의 데이터만을 보여줍니다.\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_boxplot(aes(group = cut))\n\n\n\n\n\n\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_boxplot(aes(group = cut)) +\n  coord_flip() \n\n\n\n\n\n\n\n\ncoord_flip() 함수는 \\(x\\)축과 \\(y\\)축을 뒤집어 표현합니다. 위의 그림은 ggplot() 함수의 aes 내부에서 \\(x\\)축은 carat을, \\(y\\)축은 price를 지정해 주었지만, 아래 그림에서는 coord_flip() 함수를 통해 각 축이 서로 바뀌었습니다."
  },
  {
    "objectID": "r_basic.html#theme",
    "href": "r_basic.html#theme",
    "title": "R 기초 배우기",
    "section": "Theme",
    "text": "Theme\nTheme은 그림의 제목, 축 제목, 축 단위, 범례, 디자인 등 그림을 꾸며주는 역할을 담당합니다.\n\ndiamonds %>%\n  ggplot(aes(x = carat, y = price)) +\n  geom_point(aes(color = cut)) +\n  theme_bw() +\n  labs(title = 'Relation between Carat & Price',\n       x = 'Carat', y = 'Price') +\n  theme(legend.position = 'bottom',\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank()\n        ) +\n  scale_y_continuous(\n    labels = function(x) {\n      paste0('$', \n             format(x, big.mark = ','))\n    })\n\n\n\n\n\n\n\n\ngeom_point() 함수 이후 Theme에 해당하는 부분은 다음과 같습니다.\n\ntheme_bw() 함수를 통해 배경을 흰색으로 설정합니다.\nlabs() 함수를 통해 그래프의 제목 및 \\(x\\)축, \\(y\\)축 제목을 변경합니다.\ntheme() 함수 내 legend.position을 통해 범례를 하단으로 이동합니다.\ntheme() 함수 내 panel.grid를 통해 격자를 제거합니다.\nscale_y_continuous() 함수를 통해 \\(y\\)축에서 천원 단위로 콤마(,)를 붙여주며, 이를 달러($) 표시와 합쳐줍니다.\n\n이 외에도 각종 테마를 적용해 얼마든지 원하는 그림을 꾸밀 수 있습니다. R에서 적용가능한 그래프의 테마는 다음과 같습니다.\n\nhttps://ggplot2.tidyverse.org/reference/ggtheme.html"
  },
  {
    "objectID": "r_basic.html#각종-팁",
    "href": "r_basic.html#각종-팁",
    "title": "R 기초 배우기",
    "section": "각종 팁",
    "text": "각종 팁\n원하는 형태로 그래프를 가공하고자 할 경우, 구글에 검색을 하면 얼마든지 원하는 답을 얻을 수 있습니다. 만약 범례를 지우고 싶을 경우, 구글에서 ’remove legend ggplot’을 검색하도록 합니다.\n\n\n\n\n\n범례 지우기\n\n\n\n\n이를 통해 우리가 원하는 답을 쉽게 얻을 수 있습니다.\n\n\n\n\n\n범례를 지우는 코드\n\n\n\n\n또한 ggplot2 패키지 만으로도 나타낼 수 없는 그래프는 다양한 확장 패키지들을 통해 얼마든지 나타낼 수 있습니다.\n\nhttps://exts.ggplot2.tidyverse.org/gallery/\n\n해당 패키지에 대한 더욱 자세한 설명은 패키지들의 책을 살펴보시기 바랍니다. 해당 책은 온라인에서 무료로 확인할 수 있습니다.\n\nhttps://ggplot2-book.org/"
  },
  {
    "objectID": "r_basic.html#join",
    "href": "r_basic.html#join",
    "title": "R 기초 배우기",
    "section": "*_join()",
    "text": "*_join()\n먼저 두 테이블을 하나로 합쳐줍니다.\n\ndata_market = left_join(KOR_ticker, KOR_sector,\n                         by = c('종목코드' = 'CMP_CD',\n                                '종목명' = 'CMP_KOR')) \n\ndata_market %>% head()\n\n  종목코드           종목명   종가   대비 등락률 시장구분   업종명    시가총액\n1   005930         삼성전자  70400  -1100  -1.54    KOSPI 전기전자 4.20273e+14\n2   000660       SK하이닉스 105500  -2000  -1.86    KOSPI 전기전자 7.68042e+13\n3   035420            NAVER 402500  -7500  -1.83    KOSPI 서비스업 6.61160e+13\n4   207940 삼성바이오로직스 874000      0   0.00    KOSPI   의약품 5.78000e+13\n5   035720           카카오 124500  -3500  -2.73    KOSPI 서비스업 5.54475e+13\n6   051910           LG화학 784000 -47000  -5.66    KOSPI     화학 5.53444e+13\n   EPS    PER    BPS   PBR 주당배당금 배당수익률 IDX_CD              IDX_NM_KOR\n1 3841  18.33  39406  1.79       2994       4.25    G45                 WICS IT\n2 6952  15.18  71275  1.48       1170       1.11    G45                 WICS IT\n3 6877  58.53  44850  8.97        402       0.10    G50 WICS 커뮤니케이션서비스\n4 3642 239.98  69505 12.57          0       0.00    G35           WICS 건강관리\n5  369 337.40  14286  8.71         30       0.02    G50 WICS 커뮤니케이션서비스\n6 6666 117.61 230440  3.40      10000       1.28    G15               WICS 소재\n  ALL_MKT_VAL   MKT_VAL   WGT S_WGT CAL_WGT SEC_CD         SEC_NM_KOR SEQ TOP60\n1   551957421 315204519 57.11 57.11       1    G45                 IT   1     2\n2   551957421  56835145 10.30 67.40       1    G45                 IT   2     2\n3   180662521  51570493 28.55 28.55       1    G50 커뮤니케이션서비스   1     4\n4   136785726  14457053 10.57 26.66       1    G35           건강관리   2    27\n5   180662521  38258764 21.18 49.72       1    G50 커뮤니케이션서비스   2     4\n6   122898119  35420414 28.82 28.82       1    G15               소재   1     8\n  APT_SHR_CNT\n1  4477336913\n2   538721750\n3   128125448\n4    16541250\n5   307299311\n6    45179100\n\n\nleft_join() 함수를 이용해 KOR_ticker와 KOR_sector 데이터를 합쳐줍니다. by 인자는 데이터를 합치는 기준점을 의미하며, x 데이터(KOR_ticker)의 종목코드와 y 데이터(KOR_sector)의 CMP_CD는 같음을, x 데이터의 종목명과 y 데이터의 CMP_KOR는 같음을 정의합니다.\n\ndata_market = data_market %>% as_tibble()\n\n데이터 분석시에는 데이터프레임 보다는 티블 형태가 더욱 깔끔하므로 형태를 변경해줍니다."
  },
  {
    "objectID": "r_basic.html#glimpse",
    "href": "r_basic.html#glimpse",
    "title": "R 기초 배우기",
    "section": "glimpse()",
    "text": "glimpse()\n\nglimpse(data_market)\n\nRows: 2,237\nColumns: 26\n$ 종목코드    <chr> \"005930\", \"000660\", \"035420\", \"207940\", \"035720\", \"051910\"…\n$ 종목명      <chr> \"삼성전자\", \"SK하이닉스\", \"NAVER\", \"삼성바이오로직스\", \"카…\n$ 종가        <dbl> 70400, 105500, 402500, 874000, 124500, 784000, 732000, 208…\n$ 대비        <int> -1100, -2000, -7500, 0, -3500, -47000, 1000, -1500, -1000,…\n$ 등락률      <dbl> -1.54, -1.86, -1.83, 0.00, -2.73, -5.66, 0.14, -0.71, -1.1…\n$ 시장구분    <chr> \"KOSPI\", \"KOSPI\", \"KOSPI\", \"KOSPI\", \"KOSPI\", \"KOSPI\", \"KOS…\n$ 업종명      <chr> \"전기전자\", \"전기전자\", \"서비스업\", \"의약품\", \"서비스업\", …\n$ 시가총액    <dbl> 4.20273e+14, 7.68042e+13, 6.61160e+13, 5.78000e+13, 5.5447…\n$ EPS         <int> 3841, 6952, 6877, 3642, 369, 6666, 8593, 5454, 3710, 3756,…\n$ PER         <dbl> 18.33, 15.18, 58.53, 239.98, 337.40, 117.61, 85.19, 38.23,…\n$ BPS         <int> 39406, 71275, 44850, 69505, 14286, 230440, 184387, 250888,…\n$ PBR         <dbl> 1.79, 1.48, 8.97, 12.57, 8.71, 3.40, 3.97, 0.83, 1.15, 8.6…\n$ 주당배당금  <int> 2994, 1170, 402, 0, 30, 10000, 1000, 3000, 1000, 0, 0, 800…\n$ 배당수익률  <dbl> 4.25, 1.11, 0.10, 0.00, 0.02, 1.28, 0.14, 1.44, 1.18, 0.00…\n$ IDX_CD      <chr> \"G45\", \"G45\", \"G50\", \"G35\", \"G50\", \"G15\", \"G45\", \"G25\", \"G…\n$ IDX_NM_KOR  <chr> \"WICS IT\", \"WICS IT\", \"WICS 커뮤니케이션서비스\", \"WICS 건…\n$ ALL_MKT_VAL <int> 551957421, 551957421, 180662521, 136785726, 180662521, 122…\n$ MKT_VAL     <int> 315204519, 56835145, 51570493, 14457053, 38258764, 3542041…\n$ WGT         <dbl> 57.11, 10.30, 28.55, 10.57, 21.18, 28.82, 6.75, 18.14, 13.…\n$ S_WGT       <dbl> 57.11, 67.40, 28.55, 26.66, 49.72, 28.82, 74.15, 18.14, 31…\n$ CAL_WGT     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1, …\n$ SEC_CD      <chr> \"G45\", \"G45\", \"G50\", \"G35\", \"G50\", \"G15\", \"G45\", \"G25\", \"G…\n$ SEC_NM_KOR  <chr> \"IT\", \"IT\", \"커뮤니케이션서비스\", \"건강관리\", \"커뮤니케이…\n$ SEQ         <int> 1, 2, 1, 2, 2, 1, 3, 1, 2, 1, 4, 2, NA, 3, 3, 1, 1, 5, 1, …\n$ TOP60       <int> 2, 2, 4, 27, 4, 8, 2, 9, 9, 27, 7, 8, NA, 9, 4, 7, 2, 4, 2…\n$ APT_SHR_CNT <dbl> 4477336913, 538721750, 128125448, 16541250, 307299311, 451…\n\n\nglimpse() 함수는 데이터 내용, 구조, 형식을 확인하는 함수입니다. 기본 함수인 str()과 그 역할은 비슷하지만, tidy 형태로 결과물이 훨씬 깔끔하게 출력됩니다. 총 관측값 및 열의 개수, 각 열의 이름과 데이터 형식, 앞부분 데이터를 확인할 수 있습니다."
  },
  {
    "objectID": "r_basic.html#rename-열-이름-바꾸기",
    "href": "r_basic.html#rename-열-이름-바꾸기",
    "title": "R 기초 배우기",
    "section": "rename(): 열 이름 바꾸기",
    "text": "rename(): 열 이름 바꾸기\n\nnames(data_market)\n\n [1] \"종목코드\"    \"종목명\"      \"종가\"        \"대비\"        \"등락률\"     \n [6] \"시장구분\"    \"업종명\"      \"시가총액\"    \"EPS\"         \"PER\"        \n[11] \"BPS\"         \"PBR\"         \"주당배당금\"  \"배당수익률\"  \"IDX_CD\"     \n[16] \"IDX_NM_KOR\"  \"ALL_MKT_VAL\" \"MKT_VAL\"     \"WGT\"         \"S_WGT\"      \n[21] \"CAL_WGT\"     \"SEC_CD\"      \"SEC_NM_KOR\"  \"SEQ\"         \"TOP60\"      \n[26] \"APT_SHR_CNT\"\n\n\n열 이름 중 ’배당수익률’이 있습니다. 해당 이름을 변경해주도록 하겠습니다.\n\ndata_market = data_market %>%\n  rename(`배당수익률(%)` = `배당수익률`)\n\nnames(data_market)\n\n [1] \"종목코드\"      \"종목명\"        \"종가\"          \"대비\"         \n [5] \"등락률\"        \"시장구분\"      \"업종명\"        \"시가총액\"     \n [9] \"EPS\"           \"PER\"           \"BPS\"           \"PBR\"          \n[13] \"주당배당금\"    \"배당수익률(%)\" \"IDX_CD\"        \"IDX_NM_KOR\"   \n[17] \"ALL_MKT_VAL\"   \"MKT_VAL\"       \"WGT\"           \"S_WGT\"        \n[21] \"CAL_WGT\"       \"SEC_CD\"        \"SEC_NM_KOR\"    \"SEQ\"          \n[25] \"TOP60\"         \"APT_SHR_CNT\"  \n\n\nrename() 함수는 열 이름을 바꾸는 함수로서, rename(tbl, new_name = old_name) 형태로 입력합니다. 위의 경우 배당수익률 열 이름이 배당수익률(%)로 변경되었습니다."
  },
  {
    "objectID": "r_basic.html#distinct",
    "href": "r_basic.html#distinct",
    "title": "R 기초 배우기",
    "section": "distinct()",
    "text": "distinct()\n\ndata_market %>%\n  distinct(SEC_NM_KOR) %>% pull()\n\n [1] \"IT\"                 \"커뮤니케이션서비스\" \"건강관리\"          \n [4] \"소재\"               \"경기관련소비재\"     \"금융\"              \n [7] NA                   \"에너지\"             \"산업재\"            \n[10] \"유틸리티\"           \"필수소비재\"        \n\n\ndistinct() 함수는 고유한 값을 반환하며, 기본 함수 중 unique()와 동일한 기능을 합니다. 데이터의 섹터 정보를 확인해보면, WICS 기준 10개 섹터 및 섹터 정보가 없는 종목인 NA 값이 있습니다. 또한 pull() 함수는 열을 벡터로 치환해줍니다."
  },
  {
    "objectID": "r_basic.html#select",
    "href": "r_basic.html#select",
    "title": "R 기초 배우기",
    "section": "select()",
    "text": "select()\n\ndata_market %>%\n  select(종목명) %>% head()\n\n# A tibble: 6 × 1\n  종목명          \n  <chr>           \n1 삼성전자        \n2 SK하이닉스      \n3 NAVER           \n4 삼성바이오로직스\n5 카카오          \n6 LG화학          \n\n\n\ndata_market %>%\n  select(종목명, PBR, SEC_NM_KOR) %>% head()\n\n# A tibble: 6 × 3\n  종목명             PBR SEC_NM_KOR        \n  <chr>            <dbl> <chr>             \n1 삼성전자          1.79 IT                \n2 SK하이닉스        1.48 IT                \n3 NAVER             8.97 커뮤니케이션서비스\n4 삼성바이오로직스 12.6  건강관리          \n5 카카오            8.71 커뮤니케이션서비스\n6 LG화학            3.4  소재              \n\n\nselect() 함수는 원하는 열을 선택해주는 함수이며, 원하는 열 이름을 입력하면 됩니다. 하나의 열뿐만 아니라 다수의 열을 입력하면 해당 열들이 선택됩니다.\n\ndata_market %>%\n  select(starts_with('시')) %>% head()\n\n# A tibble: 6 × 2\n  시장구분 시가총액\n  <chr>       <dbl>\n1 KOSPI     4.20e14\n2 KOSPI     7.68e13\n3 KOSPI     6.61e13\n4 KOSPI     5.78e13\n5 KOSPI     5.54e13\n6 KOSPI     5.53e13\n\n\n\ndata_market %>%\n  select(ends_with('R')) %>% head()\n\n# A tibble: 6 × 4\n    PER   PBR IDX_NM_KOR              SEC_NM_KOR        \n  <dbl> <dbl> <chr>                   <chr>             \n1  18.3  1.79 WICS IT                 IT                \n2  15.2  1.48 WICS IT                 IT                \n3  58.5  8.97 WICS 커뮤니케이션서비스 커뮤니케이션서비스\n4 240.  12.6  WICS 건강관리           건강관리          \n5 337.   8.71 WICS 커뮤니케이션서비스 커뮤니케이션서비스\n6 118.   3.4  WICS 소재               소재              \n\n\n\ndata_market %>%\n  select(contains('가')) %>% head()\n\n# A tibble: 6 × 2\n    종가 시가총액\n   <dbl>    <dbl>\n1  70400  4.20e14\n2 105500  7.68e13\n3 402500  6.61e13\n4 874000  5.78e13\n5 124500  5.54e13\n6 784000  5.53e13\n\n\n해당 함수는 다양한 응용 기능도 제공합니다.starts_with()는 특정 문자로 시작하는 열들을 선택하고, ends_with()는 특정 문자로 끝나는 열들을 선택하며, contains()는 특정 문자가 포함되는 열들을 선택합니다."
  },
  {
    "objectID": "r_basic.html#mutate",
    "href": "r_basic.html#mutate",
    "title": "R 기초 배우기",
    "section": "mutate()",
    "text": "mutate()\n\ndata_market = data_market %>%\n  mutate(PBR = as.numeric(PBR),\n         PER = as.numeric(PER),\n         ROE = PBR / PER,\n         ROE = round(ROE, 4),\n         size = ifelse(시가총액 >=\n                         median(시가총액, na.rm = TRUE),\n                       'big', 'small')\n  )\n\ndata_market %>%\n  select(종목명, ROE, size) %>% head()\n\n# A tibble: 6 × 3\n  종목명              ROE size \n  <chr>             <dbl> <chr>\n1 삼성전자         0.0977 big  \n2 SK하이닉스       0.0975 big  \n3 NAVER            0.153  big  \n4 삼성바이오로직스 0.0524 big  \n5 카카오           0.0258 big  \n6 LG화학           0.0289 big  \n\n\nmutate() 함수는 원하는 형태로 열을 생성하거나 변형하는 함수입니다. 위 예제에 서는 먼저 PBR과 PER 열을 as.numeric() 함수를 통해 숫자형으로 변경한 후 PBR을 PER로 나눈 값을 ROE 열에 생성합니다. 그 후 round() 함수를 통해 ROE 값을 반올림하며, ifelse() 함수를 통해 시가총액의 중앙값보다 큰 기업은 big, 아닐 경우 small임을 size 열에 저장합니다.\n이 외에도 mutate() 함수 내에 across() 함수를 사용해 각 상황에 맞게 데이터를 변형할 수 있습니다.\n\ndata_market %>%\n  mutate(across(where(is.numeric), ~.x * 100))\n\n# A tibble: 2,237 × 28\n   종목코드 종목명        종가   대비 등락률 시장…¹ 업종명   시가…²    EPS   PER\n   <chr>    <chr>        <dbl>  <dbl>  <dbl> <chr>  <chr>     <dbl>  <dbl> <dbl>\n 1 005930   삼성전자    7.04e6 -1.1e5   -154 KOSPI  전기전… 4.20e16 384100  1833\n 2 000660   SK하이닉스  1.06e7 -2  e5   -186 KOSPI  전기전… 7.68e15 695200  1518\n 3 035420   NAVER       4.03e7 -7.5e5   -183 KOSPI  서비스… 6.61e15 687700  5853\n 4 207940   삼성바이오… 8.74e7  0          0 KOSPI  의약품  5.78e15 364200 23998\n 5 035720   카카오      1.25e7 -3.5e5   -273 KOSPI  서비스… 5.54e15  36900 33740\n 6 051910   LG화학      7.84e7 -4.7e6   -566 KOSPI  화학    5.53e15 666600 11761\n 7 006400   삼성SDI     7.32e7  1  e5     14 KOSPI  전기전… 5.03e15 859300  8519\n 8 005380   현대차      2.08e7 -1.5e5    -71 KOSPI  운수장… 4.45e15 545400  3823\n 9 000270   기아        8.5 e6 -1  e5   -116 KOSPI  운수장… 3.45e15 371000  2291\n10 068270   셀트리온    2.1 e7  3.5e5    169 KOSPI  의약품  2.90e15 375600  5591\n# … with 2,227 more rows, 18 more variables: BPS <dbl>, PBR <dbl>,\n#   주당배당금 <dbl>, `배당수익률(%)` <dbl>, IDX_CD <chr>, IDX_NM_KOR <chr>,\n#   ALL_MKT_VAL <dbl>, MKT_VAL <dbl>, WGT <dbl>, S_WGT <dbl>, CAL_WGT <dbl>,\n#   SEC_CD <chr>, SEC_NM_KOR <chr>, SEQ <dbl>, TOP60 <dbl>, APT_SHR_CNT <dbl>,\n#   ROE <dbl>, size <chr>, and abbreviated variable names ¹​시장구분, ²​시가총액\n\n\nacross(where(is.numeric)를 통해 숫자에 해당하는 열만 선택하고, 해당 값들에 100을 곱합니다."
  },
  {
    "objectID": "r_basic.html#filter",
    "href": "r_basic.html#filter",
    "title": "R 기초 배우기",
    "section": "filter()",
    "text": "filter()\n\ndata_market %>%\n  select(종목명, PBR) %>%\n  filter(PBR < 1) \n\n# A tibble: 612 × 2\n   종목명         PBR\n   <chr>        <dbl>\n 1 현대차        0.83\n 2 POSCO         0.59\n 3 현대모비스    0.72\n 4 KB금융        0.54\n 5 삼성물산      0.73\n 6 신한지주      0.46\n 7 LG            0.8 \n 8 한국전력      0.21\n 9 삼성생명      0.32\n10 하나금융지주  0.43\n# … with 602 more rows\n\n\n\ndata_market %>%\n  select(종목명, PBR, PER, ROE) %>%\n  filter(PBR < 1 & PER < 20 & ROE > 0.1 ) %>% head()\n\n# A tibble: 6 × 4\n  종목명         PBR   PER   ROE\n  <chr>        <dbl> <dbl> <dbl>\n1 미래에셋증권  0.75  7.21 0.104\n2 한국금융지주  0.96  5.91 0.162\n3 DB손해보험    0.64  6.36 0.101\n4 메리츠증권    0.76  5.43 0.14 \n5 KCC           0.58  4.39 0.132\n6 키움증권      0.94  3.48 0.270\n\n\nfilter() 함수는 조건을 충족하는 부분의 데이터를 반환하는 함수입니다. 첫 번째 예제와 같이 PBR이 1 미만인 단일 조건을 입력할 수도 있으며, 두 번째 예제와 같이 PBR 1 미만, PER 20 미만, ROE 0.1 초과 등 복수 조건을 입력할 수도 있습니다."
  },
  {
    "objectID": "r_basic.html#summarize",
    "href": "r_basic.html#summarize",
    "title": "R 기초 배우기",
    "section": "summarize()",
    "text": "summarize()\n\ndata_market %>%\n  summarize(PBR_max = max(PBR, na.rm = TRUE),\n            PBR_min = min(PBR, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  PBR_max PBR_min\n    <dbl>   <dbl>\n1     680    0.15\n\n\nsummarize() 혹은 summarise() 함수는 원하는 요약 통곗값을 계산합니다. PBR_max는 PBR 열에서 최댓값을, PBR_min은 최솟값을 계산해줍니다."
  },
  {
    "objectID": "r_basic.html#arrange",
    "href": "r_basic.html#arrange",
    "title": "R 기초 배우기",
    "section": "arrange()",
    "text": "arrange()\n\ndata_market %>%\n  select(PBR) %>%\n  arrange(PBR) %>%\n  head(5)\n\n# A tibble: 5 × 1\n    PBR\n  <dbl>\n1  0.15\n2  0.19\n3  0.2 \n4  0.21\n5  0.24\n\n\n\ndata_market %>%\n  select(ROE) %>%\n  arrange(desc(ROE)) %>%\n  head(5)\n\n# A tibble: 5 × 1\n    ROE\n  <dbl>\n1 2.56 \n2 2.48 \n3 2.17 \n4 1.02 \n5 0.823\n\n\narrange() 함수는 선택한 열을 기준으로 데이터를 정렬해주며, 오름차순으로 정렬합니다. 내림차순으로 데이터를 정렬하려면 arrange() 내에 desc() 함수를 추가로 입력해주면 됩니다."
  },
  {
    "objectID": "r_basic.html#row_number",
    "href": "r_basic.html#row_number",
    "title": "R 기초 배우기",
    "section": "row_number()",
    "text": "row_number()\n\ndata_market %>%\n  mutate(PBR_rank = row_number(PBR)) %>%\n  select(종목명, PBR, PBR_rank) %>%\n  arrange(PBR) %>%\n  head(5)\n\n# A tibble: 5 × 3\n  종목명           PBR PBR_rank\n  <chr>          <dbl>    <int>\n1 지스마트글로벌  0.15        1\n2 세원정공        0.19        2\n3 경동인베스트    0.2         3\n4 한국전력        0.21        4\n5 한화생명        0.24        5\n\n\n\ndata_market %>%\n  mutate(ROE_rank = row_number(desc(ROE))) %>%\n  select(종목명, ROE, ROE_rank) %>%\n  arrange(desc(ROE)) %>%\n  head(5)\n\n# A tibble: 5 × 3\n  종목명             ROE ROE_rank\n  <chr>            <dbl>    <int>\n1 샘씨엔에스       2.56         1\n2 이지바이오       2.48         2\n3 솔브레인홀딩스   2.17         3\n4 한컴라이프케어   1.02         4\n5 에스디바이오센서 0.823        5"
  },
  {
    "objectID": "r_basic.html#ntile",
    "href": "r_basic.html#ntile",
    "title": "R 기초 배우기",
    "section": "ntile()",
    "text": "ntile()\n\ndata_market %>%\n  mutate(PBR_tile = ntile(PBR, n = 5)) %>%\n  select(PBR, PBR_tile) %>%\n  head()\n\n# A tibble: 6 × 2\n    PBR PBR_tile\n  <dbl>    <int>\n1  1.79        3\n2  1.48        3\n3  8.97        5\n4 12.6         5\n5  8.71        5\n6  3.4         4\n\n\nntile() 함수는 분위수를 계산해주며, n 인자를 통해 몇 분위로 나눌지 선택할 수 있습니다. 해당 함수 역시 오름차순으로 분위수를 나눕니다."
  },
  {
    "objectID": "r_basic.html#group_by",
    "href": "r_basic.html#group_by",
    "title": "R 기초 배우기",
    "section": "group_by()",
    "text": "group_by()\n\ndata_market %>%\n  group_by(`SEC_NM_KOR`) %>%\n  summarize(n())\n\n# A tibble: 11 × 2\n   SEC_NM_KOR         `n()`\n   <chr>              <int>\n 1 IT                   579\n 2 건강관리             288\n 3 경기관련소비재       342\n 4 금융                  79\n 5 산업재               349\n 6 소재                 228\n 7 에너지                28\n 8 유틸리티              19\n 9 커뮤니케이션서비스   116\n10 필수소비재           103\n11 <NA>                 106\n\n\ngroup_by() 함수는 선택한 열 중 동일한 데이터를 기준으로 데이터를 묶어줍니다. 위 예제에서는 섹터를 나타내는 SEC_NM_KOR 기준으로 데이터를 묶었으며, n() 함수를 통해 해당 그룹 내 데이터의 개수를 구할 수 있습니다.\n\ndata_market %>%\n  group_by(`SEC_NM_KOR`) %>% \n  summarize(PBR_median = median(PBR, na.rm = TRUE)) %>%\n  arrange(PBR_median)\n\n# A tibble: 11 × 2\n   SEC_NM_KOR         PBR_median\n   <chr>                   <dbl>\n 1 유틸리티                0.65 \n 2 금융                    0.745\n 3 필수소비재              1.05 \n 4 산업재                  1.21 \n 5 소재                    1.24 \n 6 경기관련소비재          1.33 \n 7 에너지                  1.46 \n 8 IT                      2.07 \n 9 <NA>                    2.15 \n10 커뮤니케이션서비스      2.9  \n11 건강관리                3.12 \n\n\n위 예제는 섹터를 기준으로 데이터를 묶은 후 summarize()를 통해 각 섹터에 속하는 종목의 PBR 중앙값을 구한 후 정렬했습니다.\n\ndata_market %>%\n  group_by(`시장구분`, `SEC_NM_KOR`) %>%\n  summarize(PBR_median = median(PBR, na.rm = TRUE)) %>%\n  arrange(PBR_median)\n\n`summarise()` has grouped output by '시장구분'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 22 × 3\n# Groups:   시장구분 [2]\n   시장구분 SEC_NM_KOR     PBR_median\n   <chr>    <chr>               <dbl>\n 1 KOSPI    금융                0.62 \n 2 KOSPI    유틸리티            0.65 \n 3 KOSPI    필수소비재          0.825\n 4 KOSPI    에너지              0.87 \n 5 KOSPI    경기관련소비재      1.02 \n 6 KOSPI    산업재              1.02 \n 7 KOSPI    소재                1.07 \n 8 KOSDAQ   유틸리티            1.34 \n 9 KOSDAQ   소재                1.42 \n10 KOSDAQ   산업재              1.45 \n# … with 12 more rows\n\n\n위 예제는 시장과 섹터를 기준으로 데이터를 그룹화한 후 각 그룹별 PBR 중앙값을 구했습니다. 이처럼 그룹은 하나만이 아닌 원하는 만큼 나눌 수 있습니다."
  },
  {
    "objectID": "r_basic.html#geom_point",
    "href": "r_basic.html#geom_point",
    "title": "R 기초 배우기",
    "section": "geom_point()",
    "text": "geom_point()\n이번에는 종목정보를 시각화하도록 하겠습니다.\n\nlibrary(ggplot2)\n\ndata_market %>% ggplot(aes(x = ROE, y = PBR)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\naes() 인자 내부에 x축은 ROE 열을 사용하고, y축은 PBR 열을 사용하도록 정의합니다.\ngeom_point() 함수를 통해 산점도 그래프를 그려줍니다. 원하는 그림이 그려지기는 했으나, ROE와 PBR에 극단치 데이터가 있어 둘 사이에 관계가 잘 보이지 않습니다.\n\n\ndata_market %>% ggplot(aes(x = ROE, y = PBR)) +\n  geom_point() +\n  coord_cartesian(xlim = c(0, 0.30), ylim = c(0, 3))\n\nWarning: Removed 845 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n이번에는 극단치 효과를 제거하기 위해 coord_cartesian() 함수 내에 xlim과 ylim, 즉 x축과 y축의 범위를 직접 지정해줍니다. 극단치가 제거되어 데이터를 한눈에 확인할 수 있습니다.\n\nggplot(data_market, aes(x = ROE, y = PBR,\n                        color = 시장구분,\n                        shape = 시장구분)) +\n  geom_point() +\n  geom_smooth(method = 'lm') +\n  coord_cartesian(xlim = c(0, 0.30), ylim = c(0, 3))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot() 함수 내부 aes 인자에 color와 shape를 지정해주면, 해당 그룹별로 모양과 색이 나타납니다. 코스피와 코스닥 종목들에 해당하는 데이터의 색과 점 모양을 다르게 표시할 수 있습니다.\ngeom_smooth() 함수를 통해 평활선을 추가할 수도 있으며, 방법으로 lm(linear model)을 지정할 경우 선형회귀선을 그려주게 됩니다. 이 외에도 glm, gam, loess 등의 다양한 회귀선을 그려줄 수 있습니다."
  },
  {
    "objectID": "r_basic.html#geom_histogram",
    "href": "r_basic.html#geom_histogram",
    "title": "R 기초 배우기",
    "section": "geom_histogram()",
    "text": "geom_histogram()\n\ndata_market %>% ggplot(aes(x = PBR)) +\n  geom_histogram(binwidth = 0.1) + \n  coord_cartesian(xlim = c(0, 10))\n\nWarning: Removed 24 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\ngeom_histogram() 함수는 히스토그램을 나타내주며, binwidth 인자를 통해 막대의 너비를 선택해줄 수 있습니다. 국내 종목들의 PBR 데이터는 왼쪽에 쏠려 있고 오른쪽으로 꼬리가 긴 분포를 가지고 있습니다.\n\ndata_market %>% ggplot(aes(x = PBR)) +\n  geom_histogram(aes(y = ..density..),\n                 binwidth = 0.1,\n                 color = 'sky blue', fill = 'sky blue') + \n  coord_cartesian(xlim = c(0, 10)) +\n  geom_density(color = 'red') +\n  geom_vline(aes(xintercept = median(PBR, na.rm = TRUE)),\n             color = 'blue') +\n  geom_text(aes(label = median(PBR, na.rm = TRUE),\n                x = median(PBR, na.rm = TRUE), y = 0.05),\n             col = 'black', size = 6, hjust = -0.5)\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\nWarning: Removed 24 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 24 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\nPBR 히스토그램을 좀 더 자세하게 나타내보겠습니다.\n\ngeom_histogram() 함수 내에 aes(y = ..density..)를 추가해 밀도함수로 바꿉니다.\ngeom_density() 함수를 추가해 밀도곡선을 그려줍니다.\ngeom_vline() 함수는 세로선을 그려주며, xintercept 즉 x축으로 PBR의 중앙값을 선택합니다.\ngeom_text() 함수는 그림 내에 글자를 표현해주며, label 인자에 원하는 글자를 입력해준 후 글자가 표현될 x축, y축, 색상, 사이즈 등을 선택할 수 있습니다."
  },
  {
    "objectID": "r_basic.html#geom_boxplot",
    "href": "r_basic.html#geom_boxplot",
    "title": "R 기초 배우기",
    "section": "geom_boxplot()",
    "text": "geom_boxplot()\n\ndata_market %>% ggplot(aes(x = SEC_NM_KOR, y = PBR)) +\n  geom_boxplot() +\n  coord_flip()\n\nWarning: Removed 24 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n박스 플롯 역시 데이터의 분포와 이상치를 확인하기 좋은 그림이며, geom_boxplot() 함수를 통해 나타낼 수 있습니다.\n\nx축 데이터로는 섹터 정보, y축 데이터로는 PBR을 선택합니다.\ngeom_boxplot()을 통해 박스 플롯을 그려줍니다.\ncoord_flip() 함수는 x축과 y축을 뒤집어 표현해주며 x축에 PBR, y축에 섹터 정보가 나타나게 됩니다.\n\n결과를 살펴보면 유틸리티나 금융 섹터는 PBR이 잘 모여 있는 반면, IT나 건강관리 섹터 등은 매우 극단적인 PBR을 가지고 있는 종목이 있습니다."
  },
  {
    "objectID": "r_basic.html#dplyr과-ggplot을-연결하여-사용하기",
    "href": "r_basic.html#dplyr과-ggplot을-연결하여-사용하기",
    "title": "R 기초 배우기",
    "section": "dplyr과 ggplot을 연결하여 사용하기",
    "text": "dplyr과 ggplot을 연결하여 사용하기\n\ndata_market %>%\n  filter(!is.na(SEC_NM_KOR)) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(ROE_sector = median(ROE, na.rm = TRUE),\n            PBR_sector = median(PBR, na.rm = TRUE)) %>%\n  ggplot(aes(x = ROE_sector, y = PBR_sector,\n             color = SEC_NM_KOR, label = SEC_NM_KOR)) +\n  geom_point() +\n  geom_text(color = 'black', size = 3, vjust = 1.3) +\n  theme(legend.position = 'bottom',\n        legend.title = element_blank())\n\n\n\n\n\n\n\n\n앞에서 배운 데이터 분석과 시각화를 동시에 연결해 사용할 수도 있습니다.\n\n데이터 분석의 단계로 filter()를 통해 섹터가 NA가 아닌 종목을 선택합니다.\ngroup_by()를 통해 섹터별 그룹을 묶습니다.\nsummarize()를 통해 ROE와 PBR의 중앙값을 계산해줍니다.\nx축과 y축을 설정한 후 색상과 라벨을 섹터로 지정해주면 각 섹터별로 색상이 다른 산점도가 그려집니다.\ngeom_text() 함수를 통해 앞에서 라벨로 지정한 섹터 정보들을 출력해줍니다.\ntheme() 함수를 통해 다양한 테마를 지정합니다. legend.position 인자로 범례를 하단에 배치했으며, legend.title 인자로 범례의 제목을 삭제했습니다."
  },
  {
    "objectID": "r_basic.html#geom_bar",
    "href": "r_basic.html#geom_bar",
    "title": "R 기초 배우기",
    "section": "geom_bar()",
    "text": "geom_bar()\n\ndata_market %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  ggplot(aes(x = SEC_NM_KOR, y = n)) +\n  geom_bar(stat = 'identity') +\n  theme_classic()\n\n\n\n\n\n\n\n\ngeom_bar()는 막대 그래프를 그려주는 함수입니다.\n\ngroup_by()를 통해 섹터별 그룹을 묶어줍니다.\nsummarize() 함수 내부에 n()을 통해 각 그룹별 데이터 개수를 구합니다.\nggplot() 함수에서 x축에는 SEC_NM_KOR, y축에는 n을 지정해줍니다.\ngeom_bar()를 통해 막대 그래프를 그려줍니다. y축에 해당하는 n 데이터를 그대로 사용하기 위해서는 stat 인자를 identity로 지정해주어야 합니다. theme_*() 함수를 통해 배경 테마를 바꿀 수도 있습니다.\n\n한편 위 그래프는 데이터 개수에 따라 순서대로 막대가 정렬되지 않아 보기에 좋은 형태는 아닙니다. 이를 반영해 더욱 보기 좋은 그래프로 나타내보겠습니다.\n\ndata_market %>%\n  filter(!is.na(SEC_NM_KOR)) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  ggplot(aes(x = reorder(SEC_NM_KOR, n), y = n, label = n)) +\n  geom_bar(stat = 'identity') +\n  geom_text(color = 'black', size = 4, hjust = -0.3) +\n  xlab(NULL) +\n  ylab(NULL) +\n  coord_flip() +\n  scale_y_continuous(expand = c(0, 0, 0.1, 0)) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\nfilter() 함수를 통해 NA 종목은 삭제해준 후 섹터별 종목 개수를 구해줍니다.\nggplot()의 x축에 reorder() 함수를 적용해 SEC_NM_KOR 변수를 n 순서대로 정렬해줍니다.\ngeom_bar()를 통해 막대 그래프를 그려준 후 geom_text()를 통해 라벨에 해당하는 종목 개수를 출력합니다.\nxlab()과 ylab()에 NULL을 입력해 라벨을 삭제합니다.\ncoord_flip() 함수를 통해 x축과 y축을 뒤집어줍니다.\nscale_y_continuous() 함수를 통해 그림의 간격을 약간 넓혀줍니다.\ntheme_classic()으로 테마를 변경해줍니다.\n\n결과를 보면 종목수가 많은 섹터부터 순서대로 정렬되어 보기도 쉬우며, 종목수도 텍스트로 표현되어 한눈에 확인할 수 있습니다.\n이처럼 데이터 시각화를 통해 정보의 분포나 특성을 한눈에 확인할 수 있으며, ggplot()을 이용하면 복잡한 형태의 그림도 매우 간단하고 아름답게 표현할 수 있습니다."
  },
  {
    "objectID": "r_sql.html",
    "href": "r_sql.html",
    "title": "R과 SQL 연결하기",
    "section": "",
    "text": "R 내에서 SQL을 직접 연결하여 사용이 가능하며, 이를 통해 훨씬 효율적인 작업이 가능합니다. 즉, R을 이용하여 SQL DB에 접속해 데이터를 읽어온 후 가공하고, 이를 토대로 결과물을 얻거나 다시 SQL에 가공한 데이터를 DB에 저장하는 것이 가능합니다.\n먼저 SQL에서 아래의 쿼리를 실행하여 MySQL의 사용자 password를 갱신합니다. (본 예제에서는 1234로 설정하였습니다.)"
  },
  {
    "objectID": "r_sql.html#r에서-sql-db에-접속하기",
    "href": "r_sql.html#r에서-sql-db에-접속하기",
    "title": "R과 SQL 연결하기",
    "section": "R에서 SQL DB에 접속하기",
    "text": "R에서 SQL DB에 접속하기\nDBI 패키지를 이용하면 R 내에서 SQL DB에 접속 및 작업이 가능합니다. 먼저 DB 인스턴스에 연결을 합니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'shop' # 사용하고자 하는 스키마\n)\n\n\ndrv: MySQL을 사용하므로 MySQL()을 입력합니다.\nuser: 관리자 계정에 해당하는 root를 입력합니다.\npassword: 위에서 설정한 root 관리자 계정의 비밀번호를 입력합니다.\nhost: 로컬 주소를 입력합니다. (일반적으로 127.0.0.1로 셋팅되어 있습니다.)\ndbname: 사용하고자 하는 데이터베이스(스키마) 이름을 입력합니다.\n\n이제 R과 SQL DB가 연결 되었습니다. dbListTables() 함수를 통해 데이터베이스 내의 테이블의 리스트를 확인할 수 있습니다.\n\ndbListTables(con)\n\n이제 R 내에서 SQL DB의 데이터를 불러와보겠습니다. dbGetQuery() 함수는 DB에 쿼리를 전송한 후 결과를 받아오는 함수이며, goods 테이블을 조회하는 쿼리를 전송해보겠습니다.\n\ngoods = dbGetQuery(con, 'select * from goods;')\n\n이처럼 SQL DB의 데이터를 R로 가져올 수 있으며, 얼마든지 복잡한 형태의 쿼리 전송도 가능합니다.\n\ndbGetQuery(con, 'select goods_classify, count(*) as cnt\n           from goods\n           group by goods_classify\n           order by cnt desc;')"
  },
  {
    "objectID": "r_sql.html#테이블-생성하기",
    "href": "r_sql.html#테이블-생성하기",
    "title": "R과 SQL 연결하기",
    "section": "테이블 생성하기",
    "text": "테이블 생성하기\n예제로 내장 데이터셋인 economics를 저장할 테이블을 만들어 보겠습니다. SQL에서는 CREATE TABLE 쿼리를 이용해 테이블을 만들수 있습니다. 그러나 R에서 SQL로 쿼리를 전송하여 테이블을 만들수도 있습니다.\n\ndbSendQuery(con,\n \"CREATE TABLE economics(\n  date Date PRIMARY KEY,\n  pce double,\n  pop double,\n  psavert double,\n  uempmed double,\n  unemploy double\n)\"\n)\n\n같은 날짜가 중복에서 입력되면 안되는 유일한 값이므로 date는 PRIMARY KEY로 설정해 줍니다. dbSendQuery() 함수는 dbGetQuery() 함수와는 다르게 단순히 쿼리를 전송하는 역할만 합니다. Workbench를 열어 해당 테이블이 제대로 만들어 졌는지 확인해보도록 하겟습니다.\n\n\n\n\n\n스키마 부분에서 새로고침을 눌러보면, **economics***** 테이블이 제대로 만들어졌으며, date 컬럼은 Primary Key를 나타내는 PK가 표시됩니다."
  },
  {
    "objectID": "r_sql.html#데이터-저장하기",
    "href": "r_sql.html#데이터-저장하기",
    "title": "R과 SQL 연결하기",
    "section": "데이터 저장하기",
    "text": "데이터 저장하기\nR의 데이터를 SQL DB에 저장하기 위해서는 추가적인 다음과 같은 설정이 필요합니다.\n\ndbSendQuery(con,\n  \"SET GLOBAL local_infile = TRUE;\"\n)\n\n위 쿼리를 통해 local_infile를 TRUE로 설정하면, R의 데이터를 SQL DB에 직접 저장이 가능합니다. 이제 economics 데이터셋을 불러오도록 합니다.\n먼저 economics 데이터셋을 불러오도록 합니다.\n\neconomics = ggplot2::economics\neconomics = data.frame(economics)\n\neconomics 데이터는 ggplot2 패키지에 존재하며, spec_tbl_df 형태이므로 data.frame() 함수를 통해 데이터프레임 형태로 변경합니다. 해당 데이터를 SQL DB에 저장해보도록 하겠으며, 해당 작업에는 dbWriteTable() 함수가 이용됩니다.\n\ndbWriteTable(con, \"economics\", economics[1:300, ],\n             overwrite = TRUE, row.names = FALSE)\n\ndbWriteTable() 함수를 이용해 economics 데이터의 1행부터 300행 까지의 데이터를 저장합니다. overwrite 인자를 TRUE로 설정하면 이미 존재하는 테이블에 새로운 데이터를 덮어쓰게 됩니다. row.names는 행 이름을 새로운 열로 추가할지 여부이므로 FALSE로 설정합니다.\nWorkbench에서 확인을 해보면 economics 테이블에 해당 데이터가 저장되어 있습니다.\n\n\n\n\n\n나머지에 해당하는 301행부터 574행 까지의 데이터도 저장해보도록 하겠습니다.\n\ndbWriteTable(con, \"economics\", economics[301:574, ],\n             append = TRUE, row.names = FALSE)\n\n이번에는 overwrite 인자 대신 append 인자를 TRUE로 설정합니다. 만약 overwrite = TRUE를 입력한다면 기존의 데이터가 모두 지워지고 새로운 데이터가 저장되는 반면, append = TRUE를 입력하면 기존의 데이터가 유지된 상태에서 새로운 데이터가 추가적으로 저장됩니다.\n이처럼 R 내에서 작업한 결과물을 SQL DB에 손쉽게 저장할 수 있습니다."
  },
  {
    "objectID": "r_sql.html#데이터-추가하기",
    "href": "r_sql.html#데이터-추가하기",
    "title": "R과 SQL 연결하기",
    "section": "데이터 추가하기",
    "text": "데이터 추가하기\n기본 데이터에는 2015년 4월 1일까지의 데이터만 존재합니다. 만일 새로운 데이터를 구해 기존 DB에 추가하고자 할 경우 SQL에서는 INSERT INTO 쿼리가 사용됩니다.\n\nINSERT INTO [테이블] (열1, 열2, ...)\nVALUE (값1, 값2 , ….);\n\n위 쿼리를 이용해 가상의 2015년 5월 1일 데이터를 추가해주도록 합니다.\n\ndbSendQuery(con,\n  \"INSERT INTO economics (date, pce, pop, psavert, uempmed, unemploy)\n  VALUES ('2015-05-01', '12300', '321000', '8', '12', '8600');\"\n)\n\nWorkbench에서 확인을 해보면 economics 테이블의 가장 하단에 2015-05-01 데이터가 추가되었습니다."
  },
  {
    "objectID": "r_sql.html#데이터-수정하기",
    "href": "r_sql.html#데이터-수정하기",
    "title": "R과 SQL 연결하기",
    "section": "데이터 수정하기",
    "text": "데이터 수정하기\n만일 DB의 데이터를 수정해야 할 경우 SQL에서는 UPDATE 쿼리가 사용됩니다.\n\nUPDATE [테이블] SET [열] = '변경할값' WHERE [조건]\n\n2015년 5월 1일 데이터 중 psavert는 7.9로, uempmed를 14로 수정해보도록 하겠습니다.\n\ndbSendQuery(con,\n  \"UPDATE economics\n  SET psavert = '7.9', uempmed = '14'\n  WHERE DATE = '2015-05-01';\"\n)\n\n데이터를 확인을 해보면 2015-05-01의 데이터가 수정되었습니다."
  },
  {
    "objectID": "r_sql.html#데이터-삭제하기",
    "href": "r_sql.html#데이터-삭제하기",
    "title": "R과 SQL 연결하기",
    "section": "데이터 삭제하기",
    "text": "데이터 삭제하기\n만일 특정 데이터를 삭제해야 할 경우 SQL에서는 DELETE FROM 쿼리가 사용됩니다.\n\nDELETE FROM [테이블]\nWHERE [조건]\n\n이번에는 2015년 5월 1일 데이터를 삭제해보도록 하겠습니다.\n\ndbSendQuery(con,\n  \"DELETE FROM economics\n  WHERE DATE = '2015-05-01';\"\n)\n\n데이터를 확인을 해보면 2015-05-01의 데이터가 삭제되었습니다."
  },
  {
    "objectID": "r_sql.html#테이블-삭제하기",
    "href": "r_sql.html#테이블-삭제하기",
    "title": "R과 SQL 연결하기",
    "section": "테이블 삭제하기",
    "text": "테이블 삭제하기\n만일 테이블 전체를 삭제해야 할 경우 SQL에서는 DROP TABLE 쿼리가 사용됩니다.\n\nDROP TABLE [테이블]\n\n우리가 작업했던 economics 테이블을 삭제해보겠습니다.\n\ndbSendQuery(con,\n  \"DROP TABLE economics;\"\n)\n\nWorkbench의 스키마 부분에서 새로고침을 눌러보면, data 스키마 내에서 economics 테이블이 삭제되었습니다."
  },
  {
    "objectID": "r_sql.html#스키마-생성하기-및-삭제",
    "href": "r_sql.html#스키마-생성하기-및-삭제",
    "title": "R과 SQL 연결하기",
    "section": "스키마 생성하기 및 삭제",
    "text": "스키마 생성하기 및 삭제\n처음에 dbConnect() 함수 내에 dbname을 통해 data 스키마를 사용하겠다고 선언했습니다. 만일 새로운 스키마를 생성하고자 할 경우의 쿼리는 CREATE DATABASE [스키마] 이며, R에서도 쿼리 전송을 통해 명령을 수행할 수 있습니다.\n\ndbSendQuery(con, \"CREATE DATABASE new_db;\")\n\nWorkbench의 스키마 부분에서 새로고침을 눌러보면, new_db 스키마가 새롭게 생성됩니다.\n\n\n\n\n\n반대로 이를 삭제하는 쿼리는 DROP DATABASE [스키마] 입니다.\n\ndbSendQuery(con, \"DROP DATABASE new_db;\")"
  },
  {
    "objectID": "r_sql.html#연결-해제하기",
    "href": "r_sql.html#연결-해제하기",
    "title": "R과 SQL 연결하기",
    "section": "연결 해제하기",
    "text": "연결 해제하기\nR에서 SQL을 이용한 모든 작업이 완료되면 반드시 R의 DB 접속을 종료해주어야 합니다. 만일 접속을 종료하지 않고 R을 닫을 경우, 향후 접속문제가 발생할 수도 있습니다.\n\ndbDisconnect(con)\n\ndbDisconnect() 함수를 통해 R의 DB 연결을 해제할 수 있습니다. 다시 DB를 사용하려면 dbConnect() 함수를 이용해 재접속을 하면 됩니다."
  },
  {
    "objectID": "sql.html",
    "href": "sql.html",
    "title": "SQL 기초",
    "section": "",
    "text": "만일 수많은 데이터를 텍스트나 엑셀 파일로 관리할 경우 어떠한 단점이 있을까? 먼저 다수의 사람이 데이터를 공유하기 어려우며, 원하는 데이터가 있으면 매번 파일을 전송해주어야 하는 번거로움이 있다. 둘째로는 대량의 데이터를 다루기가 힘들다. 마지막으로 파일 삭제, 하드 디스크 고장, 보안 문제 등 사고에 대응하기가 어렵다. 이러한 이유로 실무에서는 대부분 데이터베이스를 이용해 데이터를 효율적으로 관리한다.\n데이터베이스(database, DB)란 여러 사람이 공유하여 사용할 목적으로 체계화하여 통합, 관리하는 데이터의 집합이다. 예를 들어 티커, 주가, 재무제표, 목표주가 등 투자와 관련된 모든 데이터를 데이터베이스에 저장한 후 이를 관리하거나 사용할 수 있다. 데이터베이스 관리 시스템(database management system, DBMS)이란 다수의 사용자들이 데이터베이스 내의 데이터를 접근할 수 있도록 해주는 소프트웨어 도구의 집합이다. DBMS는 대량의 데이터를 다수의 사람이 안전하고 간단히 다룰 수 있게 해주는 장점이 있다.\nDBMS 중 가장 일반적으로 사용되는 것이 관계형 데이터베이스(Relational Database)다. 이는 엑셀 시트처럼 열과 행으로 이루어진 2차원 표 형식으로써 데이터를 관리하거나 이해하기 쉽다. 또한 SQL이라는 전용 언어를 사용해서 데이터를 처리할 수 있다. 이러한 관계형 데이터베이스 관리 시스템 중 대표적으로 사용되는 것으로는 오라클 RDBMS, MS SQL Server, Postgre SQL, MySQL 등이 있으며 본 강의에서는 무료로 사용 가능한 MySQL을 살펴보도록 하겠다."
  },
  {
    "objectID": "sql.html#데이터베이스의-구성-요소",
    "href": "sql.html#데이터베이스의-구성-요소",
    "title": "SQL 기초",
    "section": "데이터베이스의 구성 요소",
    "text": "데이터베이스의 구성 요소\n데이터베이스는 각각의 테이블로 이루어져 있으며, 테이블의 구성요소는 크게 다음과 같다.\n\n열(컬럼): 테이블에 보관하는 데이터 항목이다.\n행(레코드): 데이터 한 건에 해당하며, RDBMS는 반드시 행 단위로 데이터를 읽고 쓴다.\n셀(값): 행과 열이 교차하는 하나의 값이며, 하나의 셀 안에는 하나의 데이터만 넣을 수 있다."
  },
  {
    "objectID": "sql.html#데이터베이스와-테이블-만들기",
    "href": "sql.html#데이터베이스와-테이블-만들기",
    "title": "SQL 기초",
    "section": "데이터베이스와 테이블 만들기",
    "text": "데이터베이스와 테이블 만들기\n먼저 각각의 테이블이 저장될 데이터베이스(스키마)를 만들어 보도록 하자. MySQL Workbench를 열어 아래의 쿼리를 입력한다.\n\ncreate database shop;\n\n\n\n\n\n\ncreate database [데이터베이스명]은 데이터베이스를 만드는 SQL 쿼리다. 쿼리를 실행하는 방법은 원하는 부분을 선택한 후 Ctrl + Shift + Enter(맥 사용자의 경우 Modifier + Shift + Return) 키를 누른다. SQL 쿼리문의 끝에는 세미콜론(;)을 붙이며, 대문자나 소문자는 구분하지 않는다. 단 테이블에 등록된 데이터는 대/소문자가 구분된다.\n쿼리가 실행되면 하단의 [Action Output] 부분에 create database shop 이라는 문구가 뜨며, shop이라는 데이터베이스가 만들어졌음을 알 수 있다. 이를 확인할 수 있는 방법은 아래 그림과 같이 [Navigator]부분 하단에서 [Schemas]를 선택한 후 우측 상단의 새로고침 마크를 클릭하면 shop 데이터베이스가 생겼음이 확인된다.\n\n\n\n\n\n데이터베이스를 만들고 난 후에는 사용하고자 하는 데이터베이스를 지정해야하며, 이는 MySQL을 새로 열때마다 실행해야 한다.\n\nuse shop;\n\nuse [데이터베이스명]; 쿼리를 통해 shop 데이터베이스를 사용할 것을 지정하였다.\n이제 데이터베이스 하부에 테이블을 만들어보도록 하자. 테이블을 만드는 쿼리 형식은 다음과 같다.\n\ncreate table <테이블명>\n(\n<열 이름 1> <데이터 형태> <이 열의 제약>,\n<열 이름 2> <데이터 형태> <이 열의 제약>,\n<열 이름 3> <데이터 형태> <이 열의 제약>,\n….\n<테이블의 제약 1>, <테이블의 제약 2>, …. \n);\n\n위 형식에 맞춰 goods 테이블을 만들어주도록 한다.\n\ncreate table goods\n(\ngoods_id char(4) not null,\ngoods_name varchar(100) not null,\ngoods_classify varchar(32) not null,\nsell_price integer,\nbuy_price integer,\nregister_date date,\nprimary key (goods_id)\n);\n\n모든 열에 integer나 char 등의 데이터 형식을 지정해 주어야 한다. MySQL에서 사용할 수 있는 데이터 타입의 종류는 크게 CHAR, BINARY, TEXT, VARCHAR, BLOB, 숫자형 데이터 타입이 있으며, 입력되는 데이터에 맞는 타입을 설정한다. 또한 각종 제약을 설정해줄 수 있다. null이란 데이터가 없음을 의미하며, not null은 반드시 데이터가 존재해야 한다는 의미이다. 마지막으로 goods_id 열을 기본 키(primary key)로 지정해준다.\n위 쿼리를 실행한 후 좌측의 SCHEMAS 부분에서 새로고침을 해보면, shop 데이터베이스의 Tables에 [goods]가 생성되며, Columns 부분에서 우리가 입력한 열들을 확인할 수 있다. 또한 열 이름을 클릭하면 하단의 Information 부분에서 해당 열의 데이터 타입 또한 확인할 수 있다.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n데이터베이스나 테이블, 열 이름으로 사용할 수 있는 문자는 다음과 같다.\n\n영문자(간혹 한글이 되기는 하나 추천하지 않음)\n숫자\n언더바(_)\n\n\n\n\n테이블 정의 변경하기\n테이블에 열을 추가로 만들거나 삭제를 해야하는 등 테이블의 정의를 변경해야 하는 경우 ALTER TABLE 문을 사용하면 된다. 먼저 열을 추가하는 쿼리는 다음과 같다.\n\nalter table <테이블명> add column <열 이름> <열 정의>;\n\nshop 테이블에 goods_name이라는 열을 추가하며, 데이터 타입은 varchar(100)으로 설정하는 쿼리는 다음과 같다.\n\nalter table goods add column goods_name_eng varchar(100);\n\n쿼리를 실행하고 SCHEMAS 부분에서 새로고침을 누르면 shop 데이터베이스 내 goods 테이블에 goods_name_eng 열이 추가된 것이 확인된다.\n\n\n\n\n\n반대로 열을 삭제하는 쿼리는 다음과 같다.\n\nalter table <테이블명> drop column <열명>;\n\n이를 이용해 위에서 만든 goods_name_eng 열을 삭제하도록 한다.\n\nalter table goods drop column goods_name_eng;\n\n쿼리 실행후 SCHEMAS 부분에서 새로고침을 누르면 goods 테이블에서 해당 열이 삭제된 것을 확인할 수 있다.\n\n\n테이블에 데이터 등록하기\n현재 goods 테이블은 아무런 데이터가 없는 빈 테이블 상태이므로, 데이터를 등록해주어야 한다. SQL에서 데이터를 등록하는 쿼리는 다음과 같다.\n\ninsert into <테이블명> values (값);\n\n아래 쿼리를 입력하여 goods 테이블에 데이터를 등록해주도록 한다.\n\ninsert into goods values ('0001', '티셔츠', '의류', 1000, 500, '2020-09-20');\ninsert into goods values ('0002', '펀칭기', '사무용품', 500, 320, '2020-09-11');\ninsert into goods values ('0003', '와이셔츠', '의류', 4000, 2800, NULL);\ninsert into goods values ('0004', '식칼', '주방용품', 3000, 2800, '2020-09-20');\ninsert into goods values ('0005', '압력솥', '주방용품', 6800, 5000, '2020-01-15');\ninsert into goods values ('0006', '포크', '주방용품', 500, NULL, '2020-09-20');\ninsert into goods values ('0007', '도마', '주방용품', 880, 790, '2020-04-28');\ninsert into goods values ('0008', '볼펜', '사무용품', 100, NULL, '2020-11-11');\n\n\n\n\n\n\n쿼리가 제대로 실행되었으면 하단의 Output 부분이 위 그림과 같이 나타난다. 이 부분에서 SQL 초보자들에게 발생하는 대부분의 오류는 다음과 같다.\n\n한 번 입력한 데이터를 다시 입력(Error Code: 1062. Duplicate entry ‘000x’ for key ‘goods.PRIMARY’ 오류 메세지 발생)\n테이블 내 열의 갯수와 입력하는 데이터의 열 갯수가 같지 않음(Error Code: 1136. Column count doesn’t match value count at row 1 오류 메세지 발생)\n\n이 외에도 발생하는 오류들은 하단의 Output 부분에 그 원인이 있으므로, 당황하지 말고 해당 메세지를 살펴보고 수정하면 된다."
  },
  {
    "objectID": "sql.html#sql-기초구문-익히기",
    "href": "sql.html#sql-기초구문-익히기",
    "title": "SQL 기초",
    "section": "SQL 기초구문 익히기",
    "text": "SQL 기초구문 익히기\n위에서 만든 테이블을 바탕으로 SQL에서 자주 사용되는 기초 구문들을 실습해보겠다.\n\nselect: 열 선택하기\n테이블에서 원하는 열을 선택할 때는 select 문을 사용하며, 쿼리는 다음과 같다.\n\nselect <열 이름 1> , <열 이름 2>, … <열 이름 n>\nfrom <테이블명>;\n\ngoods 테이블 중 goods_id, goods_name, buy_price 열만 선택해보도록 하자.\n\nselect goods_id, goods_name, buy_price\nfrom goods;\n\n\n\n\n\n\n쿼리를 실행하면 하단의 [Result Grid]에 결과가 표시되며, 우리가 선택한 열만 표시된다. 만일 모든 데이터를 한번에 보고 싶다면 select * from <테이블명>; 형태로 입력하면 된다.\n\nselect * from goods;\n\n\n\n\n\n\nas 키워드를 사용하면 열에 별명을 부여할 수도 있다. 만일 저장된 테이블의 열 이름이 길 경우 이를 모두 출력하면 직관적으로 내용을 이해하기 힘드므로 이름을 간결하게 변경하는 것이 나을 때도 있다. as 키워드를 사용하는 방법은 다음과 같다.\n\nselect <열 이름 1> as <별명>\nfrom <테이블명>;\n\n이를 이용해 goods_id, goods_name, buy_price의 이름을 바꾼 후 출력해보도록 하자.\n\nselect goods_id as id,\n    goods_name as name,\n    buy_price as price\nfrom goods;\n\n\n\n\n\n\nselect 구를 통해 단순히 현재 있는 열을 선택할 뿐만 아니라 상수 및 계산식도 작성이 가능하다. 아래 쿼리를 실행해보도록 하자.\n\nselect '상품' as category,\n    38 as num,\n    '2022-01-01' as date,\n    goods_id,\n    goods_name,\n    sell_price, buy_price, sell_price - buy_price as profit\nfrom goods;\n\n\n\n\n\n\ncategory, num, date 열에는 각각 상품, 38, 2022-01-01이라는 상수가 입력된다. 또한 sell_price - buy_price를 통해 두 열의 차이를 계산할 수 있으며, as 키워드를 통해 해당 열을 profit 으로 출력한다. 만일 별명을 부여하지 않을 경우 해당 열 이름은 계산식인 [sell_price - buy_price]가 그대로 출력된다.\n\n\ndistinct: 중복 제거하기\n중복된 데이터가 있는 경우 중복되는 값을 제거하고 고유한 값만 확인하고 싶을 때는 distinct 키워드를 사용하며, 사용법은 다음과 같다.\n\nselect distinct <열 이름>\nfrom <테이블명>;\n\n상품 분류에 해당하는 goods_classify 열에는 중복된 값들이 존재한다. 만일 상품 분류가 어떤 것이 있는지 고유한 값만을 확인하고 싶을 경우 아래 쿼리를 실행하면 된다.\n\nselect distinct goods_classify\nfrom goods;\n\n\n\n\n\n\n상품 분류 중 고유한 값인 의류, 사무용품, 주방용품만이 출력된다.\n\n\nwhere: 원하는 행 선택하기\n여러 데이터 중 조건에 부합하는 행만 선택할 때는 where 구를 사용하면 된다. 이는 엑셀에서 필터 기능과도 비슷하다. where 구는 from 구 바로 뒤에 사용해야 작동한다.\n\nselect <열 이름>, …\nfrom <테이블명>\nwhere <조건식>;\n\n테이블에서 상품 분류(goods_classify)가 의류인 데이터만 선택해보도록 하자.\n\nselect goods_name, goods_classify\nfrom goods\nwhere goods_classify = '의류';\n\n\n\n\n\n\n여러 데이터 중 goods_classify가 의류인 데이터 2개(티셔츠, 와이셔츠)만 선택되었다."
  },
  {
    "objectID": "sql.html#연산자",
    "href": "sql.html#연산자",
    "title": "SQL 기초",
    "section": "연산자",
    "text": "연산자\n연산자는 SQL 문에서 연산을 수행하기 위해 사용되는 사전에 예약된 단어 또는 문자로써 일반적으로 where 구 안에서 사용된다. 흔히 사용되는 연산자는 다음과 같다.\n\n산술 연산자\n비교 연산자\n논리 연산자\n\n\n산술 연산자\n산술 연산자는 더하기, 빼기, 곱하기, 나누기 등 계산을 할 때 사용되는 연산자이다. 만일 판매가에서 구매가를 뺀 이익이 500 이상인 데이터만 선택하려면 다음과 같은 쿼리를 실행한다.\n\nselect *, sell_price - buy_price as profit\nfrom goods\nwhere sell_price - buy_price >= 500;\n\n\n\n\n\n\nwhere 구문 내애 [sell_price - buy_price]를 계산하여 이익이 500 이상인 조건에 만족하는 데이터만을 선택하였다.\n\n\n비교 연산자\n비교 연산자는 데이터의 크기를 비교할 때 사용되는 연산자이며, 종류는 다음과 같다.\n\n\n\n연산자\n의미\n\n\n\n\n=\n~와 같다\n\n\n<>\n~와 같지 않다\n\n\n>=\n~ 이상\n\n\n>\n~ 보다 크다\n\n\n<=\n~ 이하\n\n\n<\n~ 보다 작다\n\n\n\nsell_price가 1000 이상인 데이터만 선택하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere sell_price >= 1000;\n\n\n\n\n\n\n숫자 뿐 아니라 날짜에도 비교 연산자를 사용할 수 있다. 등록일(register_date)이 2020년 9월 27일 이전인 데이터만 선택하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, register_date\nfrom goods\nwhere register_date < '2020-09-27';\n\n\n\n\n\n\n\n\n논리 연산자\nwhere 구 내에 and 연산자와 or 연산자와 같은 논리 연산자를 사용하면 복수의 검색 조건을 조합할 수 있다. 예를 들어 상품 분류가 주방용품이고 판매가가 3000 이상인 데이터를 조회하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere goods_classify = '주방용품'\nand sell_price >= 3000;\n\n\n\n\n\n\n두 조건을 모두 만족하는 데이터가 선택되었다. 만약 상품 분류가 주방용품이거나 판매가가 3000 이상인 경우처럼 여러 조건 중 하나만 만족해도 되는 경우를 검색하고 싶을 경우에는 or 연산자를 사용하면 된다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere goods_classify = '주방용품'\nor sell_price >= 3000;"
  },
  {
    "objectID": "sql.html#집약-함수",
    "href": "sql.html#집약-함수",
    "title": "SQL 기초",
    "section": "집약 함수",
    "text": "집약 함수\n집약 함수란 여러 개의 레코드를 하나로 집약시키는 기능으로써, 대표적으로 사용되는 집약 함수는 다음과 같다.\n\n\n\n함수명\n의미\n\n\n\n\ncount\n행 숫자를 계산\n\n\nsum\n합계를 계산\n\n\navg\n평균을 구함\n\n\nmax\n최댓값을 구함\n\n\nmin\n최솟값을 구함\n\n\n\n\ncount: 행 숫자를 계산\ncount 함수는 행의 숫자를 계산한다. goods 테이블에 몇 개의 행이 있는 확인하는 쿼리는 다음과 같다.\n\nselect count(*)\nfrom goods;\n\n\n\n\n\n\n별표(*)는 모든 열을 의미하며 총 8개의 행이 있다는 것이 확인되었다. 그러나 이는 null이 포함된 행의 수이다. 만일 null을 제외한 행의 수를 계산하고자 할 때는 인수에 특정 열을 지정한다.\n\nselect count(buy_price)\nfrom goods;\n\n\n\n\n\n\n‘buy_price’ 열의 8개 데이터 중에는 총 2개의 null값이 있다. 따라서 count 함수를 실행하면 null을 제외한 6개의 행이 있음이 확인된다. 즉 count(*)는 null을 포함한 행의 갯수를, count(열 이름)은 null을 제외한 행 수를 계산한다.\n\n\nsum: 합계를 계산\nsum 함수는 특정 열의 합계를 계산하며, null 값은 무시하고 계산이 된다. sell_price와 buy_price 열의 합계를 구하는 쿼리는 다음과 같다.\n\nselect sum(sell_price), sum(buy_price)\nfrom goods;\n\n\n\n\n\n\n\n\navg: 산술평균을 계산\navg 함수는 산술평균을 구하며, 사용법은 sum과 동일하다. sell_price 열의 평균을 구하는 쿼리는 다음과 같다.\n\nselect avg(sell_price)\nfrom goods;\n\n\n\n\n\n\n\n\n중복값 제외 후 집약함수 사용하기\n만일 상품 분류가 몇 개가 있는지 확인하고 싶을 때는 어떻게 하면 될까? count 함수의 인자에 distict 키워드를 사용해 중복되지 않은 데이터의 갯수를 계산할 수 있다.\n\nselect count(distinct goods_classify) \nfrom goods;\n\n\n\n\n\n\ngoods_classify 에는 의류, 사무용품, 주방용품 3개가 있으므로 이에 해당하는 값이 계산되었다. 이는 count 뿐만 아니라 sum(distinct 열 이름)과 같이 다른 집약함수에도 동일하게 적용이 가능하다."
  },
  {
    "objectID": "sql.html#그룹화와-정렬",
    "href": "sql.html#그룹화와-정렬",
    "title": "SQL 기초",
    "section": "그룹화와 정렬",
    "text": "그룹화와 정렬\n데이터를 특정 기준으로 그룹을 나누어 값을 계산해야 하는 경우가 많다. 예를 들어 상품 분류 별 혹은 등록일 별 그룹을 나누어 손익을 계산한다고 생각해 보자. 이러한 경우 SQL에서는 group by 구를 사용하여 데이터를 그룹화할 수 있다. 또한 검색 결과를 특정 기준으로 정렬할 필요가 있을 경우 order by 구를 사용하면 된다.\n\n그룹 나누기\n\n\n\n\n\n위 그림의 경우 category 별로 그룹을 나누어 평균을 계산하기 위해서는 데이터를 Blue, Green, Red 별로 그룹을 나누어 평균을 계산해야 한다. 이러한 그룹화 작업을 수행하는 구가 group by이며, 사용법은 아래와 같이 그룹을 나누고자 하는 열을 입력하면 된다.\n\nselect <열 이름 1>, <열 이름 2>, …..\nfrom <테이블명>\ngroup by <열 이름 1>, <열 이름 2>, ….\n\n상품 분류 별 데이터의 수를 계산하기 위한 쿼리는 다음과 같다.\n\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\n\n\n\n\n\ngoods_classify 별로 그룹을 나눈 후 count(*)를 통해 각 그룹 별 행 갯수를 구할 수 있다. group by 구는 반드시 from 구 뒤에 두어야 한다. 이번에는 buy_price 별 행 갯수를 구해보도록 하자.\n\nselect buy_price, count(*)\nfrom goods\ngroup by buy_price;\n\n\n\n\n\n\nbuy_price 열에는 null 데이터도 포함되어 있으며, 이 역시 별도의 그룹으로 분류됨을 알 수 있다. 만일 where 구를 통해 조건에 맞는 데이터를 선택한 후 group by 구를 통해 그룹을 나눌때는 어떻게 해야 할까? 이 경우 where 구 뒤에 group by 구를 작성해야 한다. 상품 분류가 의류인 것 중 buy_price 별 데이터의 수를 구하는 쿼리는 다음과 같다.\n\nselect buy_price, count(*)\nfrom goods\nwhere goods_classify = '의류'\ngroup by buy_price;\n\n만일 group by를 통해 나온 결과에 조건을 지정하려면 어떻게 해야 할까? 이 경우 where이 아닌 having 구를 사용해야 한다.\n\nselect <열 이름 1>, <열 이름 2>, …\nfrom <테이블 명>\ngroup by <열 이름 1>, <열 이름 2>, …\nhaving <그룹값에 대한 조건>\n\n예를 들어 상품 분류별로 판매가의 평균을 구한 후, 이 값이 2500 이상인 데이터를 구하는 쿼리는 다음과 같다.\n\nselect goods_classify, avg(sell_price)\nfrom goods\ngroup by goods_classify\nhaving avg(sell_price) >= 2500;\n\n\n\n\n\n\n요약하자면 where는 group by 계산 이전, having은 group by 계산 이후 적용된다.\n\n\n검색 결과 정렬하기\nSQL에서는 결과가 무작위로 정렬되므로 쿼리를 실행할 때 마다 결과가 변한다. 오름차순이나 내림차순으로 결과를 정렬하고자 할 경우에는 order by 구를 사용한다.\n\nselect <열 이름 1>, <열 이름 2>, …\nfrom <테이블명>\norder by <재정렬 기준 열 1>, <재정렬 기준 열 2>, ...\n\n예를 들어 sell_price가 싼 순서, 즉 오름차순으로 정렬할 경우 쿼리는 다음과 같다.\n\nselect *\nfrom goods\norder by sell_price;\n\n\n\n\n\n\norder by 구는 기본적으로 오름차순으로 데이터를 정렬한다. 만일 내림차순으로 정렬하고자 할 경우 재정렬 기준 뒤에 desc 키워드를 사용한다.\n\nselect *\nfrom goods\norder by sell_price desc;"
  },
  {
    "objectID": "sql.html#뷰와-서브쿼리",
    "href": "sql.html#뷰와-서브쿼리",
    "title": "SQL 기초",
    "section": "뷰와 서브쿼리",
    "text": "뷰와 서브쿼리\n기초구문 만으로는 복잡한 형태의 데이터분석을 하는게 한계가 있으며, 뷰와 서브쿼리를 이용하면 이러한 작업을 쉽게 할 수 있다.\n\n뷰 만들기\n뷰는 기본적으로 테이블과 거의 동일하다. 그러나 테이블과의 차이는 실제 데이터를 저장하고 있지 않다는 점이다. 뷰는 데이터를 저장하지 않고 있으며, 뷰에서 데이터를 꺼내려고 할 때 내부적으로 쿼리를 실행하여 일시적인 가상 테이블을 만든다. 즉, 데이터가 아닌 쿼리를 저장하고 있다고 보면 된다. 이러한 뷰가 가진 장점은 다음과 같다.\n\n데이터를 저장하지 않기 때문에 기억 장치 용량을 절약할 수 있다.\n자주 사용하는 쿼리를 매번 작성하지 않고 뷰로 저장하면 반복해서 사용이 가능한다. 뷰는 원래의 테이블과 연동되므로, 데이터가 최신 상태로 갱신되면 뷰의 결과 역시 자동으로 최신 상태를 보여준다.\n\n뷰는 create view 문을 사용해 만들 수 있다.\n\ncreate view 뷰 이름 (<뷰의 열 이름 1>, <뷰의 열 이름 2>, ...)\nas\n<쿼리>;\n\n만일 상품 분류 별 행 갯수를 매일 조회해야 한다면, 매번 쿼리를 실행하는 것 보다 뷰를 만들어 이를 확인하는 것이 훨씬 효율적이다. 아래의 쿼리를 통해 해당 뷰를 만들 수 있다.\n\ncreate view GoodSum (goods_classify, cnt_goods)\nas\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\n\n\n\n\n\n위 쿼리를 실행한 후 SCHEMAS 부분에서 새로고침을 눌러보면 Views 하부에 goodsum 이라는 뷰가 생긴것이 확인된다. 뷰의 데이터를 확인하는 방법은 테이블의 데이터를 확인하는 방법과 동일하다.\n\nselect *\nfrom GoodSum;\n\n\n\n\n\n\n\n\n뷰 삭제하기\n뷰를 삭제하려면 drop view 뷰명 문을 사용한다.\n\ndrop view GoodSum;\n\n혹은 SCHEMAS 영역에서 삭제하고자 하는 뷰를 선택한 후 마우스 우클릭을 눌러 [Drop View]를 클릭해도 해당 뷰가 삭제된다.\n\n\n\n\n\n\n\n서브쿼리\n서브쿼리란 쿼리 내의 쿼리이며, 일회용 뷰를 의미한다. 즉, 뷰를 정의하는 구문을 그대로 다른 구 안에 삽입하는 것이다. 먼저 뷰를 만든 후 이를 확인하는 쿼리는 다음과 같다.\n\ncreate view GoodSum (goods_classify, cnt_goods)\nas\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\nselect * from GoodSum;\n\n이와 동일한 결과가 나오게 하는 서브쿼리는 다음과 같다.\n\nselect goods_classify, cnt_goods\nfrom (\n select goods_classify, count(*) as cnt_goods\n from goods\n group by goods_classify\n) as GoodsSum;\n\nfrom 구 뒤의 괄호안에 해당하는 부분은 뷰를 만들 때 사용하던 코드와 동일하다. 즉, ① from 구 안의 select 문(서브쿼리)가 실행되고, ② 이 결과를 바탕으로 바깥쪽 select 문이 실행된다.\n\n\n스칼라 서브쿼리\n스칼라 서브쿼리란 단이 값이 반환되는 서브쿼리다. 이를 통해 =, <, > 등 비교 연산자의 입력값으로 사용할 수 있다. 예를 들어 판매단가가 전체 평균 판매단가보다 높은 상품만을 검색하려면 어떻게 해야할까? 먼저 평균 단가를 계산해야 한다.\n\nselect avg(sell_price)\nfrom goods;\n\n\n\n\n\n\n해당 쿼리를 서브쿼리에 넣어 원하는 값을 찾을 수 있다.\n\nselect *\nfrom goods\nwhere sell_price > (select avg(sell_price) from goods);\n\n\n\n\n\n\n스칼라 서브쿼리는 where 구 뿐만 아니라 select, group by, having, order by 구 등 거의 모든 곳에 쓸 수 있다. 평균 판매가격을 새로운 열로 만드는 쿼리는 다음과 같다.\n\nselect goods_id, goods_name, sell_price,\n    (select avg(sell_price) from goods) as avg_price\nfrom goods;\n\n\n\n\n\n\nselect 구문 내에 select avg(sell_price) from goods 쿼리를 입력하여 평균 판매가격을 계산한 후 이를 avg_price 라는 열 이름으로 출력한다.\n이번에는 좀 더 복잡한 조건에 해당하는 데이터를 찾아보도록 하자. 상품 분류 별 평균 판매가격이 전체 데이터의 평균 판매가격 이상인 데이터만 출력하는 쿼리는 다음과 같다.\n\nselect goods_classify, avg(sell_price)\nfrom goods\ngroup by goods_classify\nhaving avg(sell_price) > (select avg(sell_price) from goods);\n\n\n\n\n\n\n먼저 group by 구문을 이용해 상품 분류 별 평균 판매가격을 계산한다. 그 후 having 구문 내에 전체 평균 판매가격을 계산하는 서브쿼리인 select avg(sell_price) from goods 를 입력하여 2097.5 라는 값을 계산하고, 그룹별 평균 판매가격이 이 값보다 큰 데이터만을 선택하게 된다."
  },
  {
    "objectID": "sql.html#함수-술어와-case-식",
    "href": "sql.html#함수-술어와-case-식",
    "title": "SQL 기초",
    "section": "함수, 술어와 case 식",
    "text": "함수, 술어와 case 식\nSQL에서도 함수를 이용해 다양한 연산을 할 수 있으며, 다음과 같은 함수가 존재한다. 본 책에서는 수치 계산을 위한 ‘산술 함수’, 문자열 처리를 위한 ‘문자열 함수’, 날짜 처리를 위한 ’날짜 함수’에 대해 대해 알아보겠다. 또한 함수의 변형 형태인 술어는 반환 값이 진리값(TRUE/FALSE/UNKNOWN)인 함수라 볼 수 있다. 마지막으로 case 식 역시 함수의 일종으로써, SQL 내에서의 if문 이라고도 볼 수 있다. case는 조건에 해당하는 목록을 평가하고 가능한 여러 결과 식 중 하나를 반환한다.\n\n산술 함수\n산술 함수는 숫자형 데이터의 절대값, 올림, 내림, 반올림 등을 계산할 수 있게 해준다. 먼저 m, n, p 3개 열로 구성된 테이블(SampleMath)을 만들어 주도록 한다.\n\ncreate table SampleMath\n(m  numeric (10,3),\n n  integer,\n p  integer);\n\ninsert into SampleMath(m, n, p) values (500, 0, NULL);\ninsert into SampleMath(m, n, p) values (-180, 0, NULL);\ninsert into SampleMath(m, n, p) values (NULL, NULL, NULL);\ninsert into SampleMath(m, n, p) values (NULL, 7, 3);\ninsert into SampleMath(m, n, p) values (NULL, 5, 2);\ninsert into SampleMath(m, n, p) values (NULL, 4, NULL);\ninsert into SampleMath(m, n, p) values (8, NULL, 3);\ninsert into SampleMath(m, n, p) values (2.27, 1, NULL);\ninsert into SampleMath(m, n, p) values (5.555,2, NULL);\ninsert into SampleMath(m, n, p) values (NULL, 1, NULL);\ninsert into SampleMath(m, n, p) values (8.76, NULL, NULL);\n\n\n\n\n\n\n\nabs: 절대값 계산하기\nabs 함수는 해당 열에 있는 값들의 절대값을 구해준다.\n\nselect m, abs(m) as abs_m\nfrom SampleMath;\n\n\n\n\n\n\nabs_m은 m열의 절대값을 계산한 것이며, 두번째 행을 보면 -180의 절대값에 해당하는 180이 계산되었다.\n\n\nmod: 나눗셈의 나머지 구하기\n7 나누기 3의 몫은 2이며 나머지는 1이다. mod 함수는 이 나머지에 해당하는 값을 구해준다.\n\nselect n, p, mod(n, p) as mod_col\nfrom SampleMath;\n\n\n\n\n\n\nmod(n, p)를 통해 n/p의 나머지를 구한다. 즉 7/3의 나머지인 1, 5/2의 나머지인 1이 계산되며, null은 계산이 불가한 데이터이므로 결과 역시 null로 나온다.\n\n\n\nround: 반올림 하기\nround 함수를 통해 반올림을 할 수 있으며, 몇 째자리에서 반올림을 할지 정할 수 있다. round(m, 2)의 경우 할 경우 m열의 데이터를 소수 둘째자리까지 반올림한다.\n\nselect m, n, round(m, n) as round_col\nfrom SampleMath;\n\n\n\n\n\n\n위의 쿼리는 m 열을 n 자리까지 반올림한다. n이 0인 경우 소수 0번째 자리, 즉 정수부분까지 반올림을 한다. n이 1인 경우에는 소수 첫째자리까지 반올림을 하기 위해 소수 둘째자리에서 반올림을 한다. round와 비슷한 함수로 올림에는 ceil, 내림에는 floor 함수가 있으므로 상황에 맞게 사용하면 된다\n\n\n문자열 함수\n문자열 함수는 문자 데이터를 처리할 때 사용되는 함수들이다. 먼저 아래의 샘플 테이블(SampleStr)을 만들도록 하자.\n\ncreate table SampleStr\n(str1  varchar(40),\n str2  varchar(40),\n str3  varchar(40));\n\ninsert into SampleStr (str1, str2, str3) values ('가나다', '라마', NULL);\ninsert into SampleStr (str1, str2, str3) values ('abc', 'def', NULL);\ninsert into SampleStr (str1, str2, str3) values ('김', '철수', '입니다');\ninsert into SampleStr (str1, str2, str3) values ('aaa', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values (NULL, '가가가', NULL);\ninsert into SampleStr (str1, str2, str3) values ('@!#$%', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('ABC', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('aBC', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('abc철수', 'abc', 'ABC');\ninsert into SampleStr (str1, str2, str3) values ('abcdefabc','abc', 'ABC');\ninsert into SampleStr (str1, str2, str3) values ('아이우', '이','우');\n\n\n\n\n\n\n\nconcat: 문자열 연결\nconcat 함수는 여러 열의 문자열을 연결하는데 사용됩니다. (타 RDMS에서는 ||로 문자를 합치기도 한다.) 먼저 str1과 str2 열의 문자를 합쳐보도록 하자.\n\nselect str1, str2, concat(str1, str2) as str_concat\nfrom SampleStr;\n\n\n\n\n\n\n두 열의 문자가 하나로 합쳐지며, null이 포함된 경우는 결과 역시 null이 반환된다.\n\n\nlower: 소문자로 변환\nlower 함수는 모든 알파벳을 소문자로 변환한다.\n\nselect str1, lower(str1) as low_str\nfrom SampleStr;\n\n\n\n\n\n\nABC가 abc로 변환되는 등 모든 알파벳이 소문자로 변환되었다. 반대로 모든 알파벳을 대문자로 변환하고자 할 경우 upper 함수를 사용하면 된다.\n\n\nreplace: 문자를 변경\nreplace 함수는 문자열 안에 있는 일부 문자를 다른 문자열로 변경하며, replace(대상 문자열, 치환 전 문자열, 치환 후 문자열) 형태로 입력한다.\n\nselect str1, str2, str3,\n    replace(str1, str2, str3) as rep_str\nfrom SampleStr;\n\n str1열 중 str2열에 해당하는 문자가 있을 경우 str3열의 문자로 변경된다.\n\n\n\n날짜 함수\nSQL에는 날짜를 다루는 많은 함수가 있으며, DBMS 종류마다 그 형태가 약간씩 다르다.\n\n현재 날짜, 시간, 일시\n현재 날짜(current_date)와 시간(current_time), 일시(current_timestamp)를 다루는 함수의 경우 from 구문이 없이 사용이 가능하다.\n\nselect current_date, current_time, current_timestamp;\n\n\n\n\n\n\n\n\n날짜 요소 추출하기\nextract(날짜 요소 from 날짜) 함수를 통해 년, 월, 시, 초 등을 추출할 수 있다.\n\nselect\n    current_timestamp,\n    extract(year from current_timestamp) as year,\n    extract(month from current_timestamp) as month,\n    extract(day from current_timestamp) as day,\n    extract(hour from current_timestamp) as hour,\n    extract(minute from current_timestamp) as minute,\n    extract(second from current_timestamp) as second;\n\n\n\n\n\n\n\n\n\n술어\n술어란 반환 값이 진리값(TRUE, FALSE, UNKNOWN)인 함수를 가리킨다. 대표적인 예로는 like, between, is null, in 등이 있다.\n\nlike: 문자열 부분 일치\n앞에서 문자열을 검색할 때는 등호(=)를 사용했지만, 이는 완전히 일치하는 경우에만 참이 된다. 반면 like 술어는 문자열 중 부분 일치를 검색할 때 사용한다. 먼저 아래의 테이블을 만들도록 한다.\n\ncreate table SampleLike\n(strcol varchar(6) not null,\nprimary key (strcol));\n\ninsert into SampleLike (strcol) values ('abcddd');\ninsert into SampleLike (strcol) values ('dddabc');\ninsert into SampleLike (strcol) values ('abdddc');\ninsert into SampleLike (strcol) values ('abcdd');\ninsert into SampleLike (strcol) values ('ddabc');\ninsert into SampleLike (strcol) values ('abddc');\n\n\n\n\n\n\n일치에는 크게 3가지 종류가 있다.\n\n전방 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 가장 앞에 위치하고 있는 레코드를 선택한다.\n중간 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 어딘가에 포함되어 있으면 레코드를 검색하며 위치는 어디든 상관없다.\n후방 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 가장 뒤에 위치하고 있는 레코드를 검색한다.\n\n먼저 전방 일치 검색은 다음과 같다.\n\nselect *\nfrom samplelike\nwhere strcol like 'ddd%';\n\n\n\n\n\n\n%는 ‘0문자 이상의 임의 문자열’ 을 의미하는 특수 기호이며, 위의 예에서 ’ddd%’는 ’ddd로 시작하는 모든 문자열’을 의미한다.\n다음으로 중간 일치 검색은 다음과 같다.\n\nselect *\nfrom SampleLike\nwhere strcol like '%ddd%';\n\n\n\n\n\n\n위의 예에서 ‘%ddd%’ 처럼 문자열 처음과 끝을 %로 감쌀 경우 ’문자열 안에 ddd를 포함하고 있는 모든 문자열’을 나타낸다. 결과를 살펴보면 ddd로 시작하거나 끝나는, 혹은 문자열 가운데에 ddd가 있는 문자열이 검색된다.\n마지막으로 후방 일치 검색을 해보도록 하겠다.\n\nselect *\nfrom SampleLike\nwhere strcol like '%ddd';\n\n ’%ddd’의 경우 전방 일치와 반대로 ddd로 끝나는 문자열을 검색한다.\n\n\nbetween: 범위 검색\nbetween은 범위 검색을 수행한다. goods 테이블에서 sell_price가 100원부터 1000원까지인 상품을 선택할 때 between 술어를 사용하면 다음과 같이 나타낼 수 있다.\n\nselect *\nfrom goods\nwhere sell_price between 100 and 1000;\n\n\n\n\n\n\nbetween을 사용할 경우 범위에 해당하는 100과 1000 데이터도 포함한다.\n\n\nis null, is not null: null 데이터 선택\n만일 null이 포함된 행을 선택하려면 어떻게 해야 할까? where 구를 where buy_price = null 형식으로 작성하면 될 듯 하지만 해당 쿼리를 실행하면 오류가 발생한다. 이는 null이 비교가 불가능한 특별한 표시어이기 때문이며, 이때는 is null 술어를 사용해야 한다. 먼저 buy_price가 null인 데이터를 선택하는 쿼리는 다음과 같다.\n\nselect *\nfrom goods\nwhere buy_price is null;\n\n\n\n\n\n\nbuy_price가 null인 데이터만 선택된다. 반대로 null이 포함되지 않은 데이터만 선택하고 싶을 때는 is not null 술어를 사용한다.\n\nselect *\nfrom goods\nwhere buy_price is not null;\n\n\n\n\n\n\n\n\nin: 복수의 값을 지정\n만일 buy_price가 320, 500, 5000인 상품을 선택할 경우, or을 쓰면 다음과 같이 쿼리를 작성해야 한다.\n\nselect *\nfrom goods\nwhere buy_price = 320 \n    or buy_price = 500\n    or buy_price = 5000;\n\n그러나 이러한 나열식의 쿼리는 조건이 많아질수록 길어지고 효율성이 떨어진다. 이 때 사용할 수 있는 것이 in 술어로써 in(값 1, 값 2, …) 형태를 통해 간단하게 표현할 수 있다.\n\nselect *\nfrom goods\nwhere buy_price in (320, 500, 5000);\n\n\n\n\n\n\n반대로 buy_price가 320, 500, 5000이 아닌 데이터만 선택하고 싶을 때는 not in 술어를 사용한다.\n\nselect *\nfrom goods\nwhere buy_price not in (320, 500, 5000);\n\n\n\n\n\n\n\n\n\ncase 식\ncase 식은 경우에 따라 값을 구분하며, 쿼리 형식은 다음과 같다.\n\ncase when <평가식 1> then <식 1>\n    when <평가식 2> then <식 2>\n    when <평가식 3> then <식 3>\n        ⋮\n    else <식 n>\nend\n\nsell_price 열의 가격에 따라 고가/중가/저가로 나눠보도록 하겠다.\n\nselect goods_name, sell_price,\n    case when sell_price >=  6000 then '고가'    \n         when sell_price >= 3000 and sell_price < 6000 then '중가'\n         when sell_price < 3000 then '저가'\n         else null\nend as price_classify\nfrom goods;\n\n\n\n\n\n\nelse 구문은 위에서 만족하는 조건이 없을 때의 반환값으로써 생략할 수도 있지만 명시적으로 기술하는 것이 좋으며, end는 생략이 불가능하다. 조건에 따른 결과가 end as 뒤에 입력한 ‘price_classify’ 열에 표시된다."
  },
  {
    "objectID": "sql.html#테이블의-집합과-결합",
    "href": "sql.html#테이블의-집합과-결합",
    "title": "SQL 기초",
    "section": "테이블의 집합과 결합",
    "text": "테이블의 집합과 결합\nSQL을 사용할 경우 하나의 테이블만 이용해 데이터를 다루는 일은 거의 없으며, 한번에 여러개의 테이블을 더하거나 결합하여 원하는 데이터를 얻을 수 있다. 이번에는 테이블의 각종 결합 방법에 대해 알아보도록 하겠다.\n\n테이블 결합\n앞서 살펴 본 union 은 행으로 테이블을 합치는 것이었다. 이번에 살펴 볼 결합(join)은 다른 테이블에서 열을 가지고 와 열을 늘리는 작업을 한다. 실무에서는 원하는 데이터가 여러 테이블에 분산되어 있는 경우가 많으므로, 테이블을 결합하여 사용해야 한다. join을 시각화하면 다음과 같다.\n\n\n\n\n\n먼저 아래의 테이블(StoreGoods)을 만든다.\n\nCREATE TABLE StoreGoods\n(store_id CHAR(4) NOT NULL,\n store_name VARCHAR(200) NOT NULL,\n goods_id CHAR(4) NOT NULL,\n num INTEGER NOT NULL,\n PRIMARY KEY (store_id, goods_id));\n\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0001', 30);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0002', 50);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0003', 15);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0002', 30);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B',' 대전',  '0003', 120);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0004', 20);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0006', 10);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0007', 40);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0003', 20);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0004', 50);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0006', 90);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0007', 70);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000D', '대구',  '0001', 100);\n\n\n\n\n\n\nGoods와 StoreGoods 테이블에 있는 열들을 정리하면 다음과 같다.\n\n\n\n\nGoods\nStoreGoods\n\n\n\n\ngoods_id (상품ID)\nO\nO\n\n\ngoods_name (상품명)\nO\n\n\n\ngoods_classify (상품분류)\nO\n\n\n\nsell_price (판매단가)\nO\n\n\n\nbuy_price (매입단가)\nO\n\n\n\nregister_date (등록일)\nO\n\n\n\nstore_id (점포ID)\n\nO\n\n\nstore_name (점포명)\n\nO\n\n\nnum (수량)\n\nO\n\n\n\n\ninner join: 내부 결합\n내부 결합(inner join)은 가장 많이 사용되는 결합 방법이다. 위의 테이블을 살펴보면 goods_id는 두 테이블에 모두 존재하며, 다른 열들은 한쪽 테이블에만 존재한다. 따라서 goods_id를 기준으로 StoreGoods 테이블에 Goods 테이블을 결합하는 방법은 다음과 같으며, 이는 마치 엑셀의 vlookup과도 비슷하다.\n\nselect store.store_id, store.store_name, store.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \ninner join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\n\n지금까지는 from에 하나의 테이블만 지정했지만, join 시에는 두 테이블(StoreGoods, Goods)에서 내용을 가지고 온다. 따라서 두 테이블에 store와 goods라는 별명을 붙였다. (원래 테이블명을 그대로 사용해도 되나 테이블명이 길면 가독성이 떨어지므로 일반적으로 별명을 붙인다.)\non 뒤에 결합 조건을 붙인다. 이는 * join 구문 바로 뒤에 붙이며, store의 goods_id 열과 goods 열의 goods_id 열을 이용해 두 테이블을 연결한다는 의미다.\nselect 구에서는 <테이블 별명>.<열 이름> 형식으로 기술한다. 이는 테이블이 여러개가 있으므로, 어느 테이블에서 데이터를 가지고 오는지 혼동하는 것을 방지하기 위해서이다.\n\n\n\nouter join 외부 결합\ninner join은 두 테이블에 모두 존재하는 데이터를 합쳤지만, outer join은 한쪽 테이블에만 존재하는 데이터도 출력한다. 먼저 StoreGoods와 Goods에 존재하는 상품ID를 검색한다.\n\nselect distinct(goods_id) from StoreGoods;\nselect distinct(goods_id) from Goods;\n\n\nStoreGoods: 0001, 0002, 0003, 0004, 0006, 0007\nGoods: 0001, 0002, 0003, 0004, 0005, 0006, 0007, 0008\n\nStoreGoods 1~4, 6~7번이, Goods 1번부터 8번까지 상품이 있다. 즉, StoreGoods 5번(압력솥)과 8번(볼펜) ID에 해당하는 물건이 없다. 이제 outer join을 해보도록 한다.\n\nselect store.store_id, store.store_name, goods.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \nright outer join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\ngoods_id가 5(압력솥)와 8(볼펜)의 경우 StoreGoods 테이블에 데이터가 존재하지 않는다. 즉, 현재 어떤 점포에서도 취급하지 않는 상품이다. inner join은 양쪽 테이블에 모두 존재하는 정보만을 선택하기 때문에 Goods 테이블에만 존재하는 두 상품은 결과로 출력되지 않았다. 반면 outer join은 한쪽 테이블에만 존재해도 누락 없이 모두 출력하며, 정보가 없는 부분은 NULL로 표시한다.\n또한 outer join은 어느 쪽 테이블을 마스터로 할 것인지 정해야 한다. 즉 left 혹은 right를 지정해주어야 한다. left를 사용하면 from 구에서 왼쪽에 지정한 테이블을 마스터로 설정하며, right를 사용하면 오른쪽 테이블을 마스터로 한다. 위의 쿼리는 마스터 테이블을 right로 지정하였기에 오른쪽에 해당하는 Goods 테이블의 내용이 모두 출력되고, goods_id를 기준으로 왼쪽에 해당하는 StoreGoods 테이블의 내용이 결합되었다. 위 쿼리를 left outer join 으로 바꿔보도록 하자.\n\nselect store.store_id, store.store_name, goods.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \nleft outer join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\n마스터 테이블인 StoreGoods에 존재하는 goods_id(1~4, 6~7)는 결합되는 테이블인 Goods에도 모두 존재하므로 이번에는 NULL이 생성되지 않는다. 어떤 테이블을 기준으로 삼아야 하는가를 미리 생각하여 left outer join을 할지 right outer join을 할지 결정해야 한다."
  },
  {
    "objectID": "sql.html#sql-고급-처리",
    "href": "sql.html#sql-고급-처리",
    "title": "SQL 기초",
    "section": "SQL 고급 처리",
    "text": "SQL 고급 처리\n이번에는 마지막으로 순위 계산, 누적합 계산, 소계를 구하는 등 고급 집계 처리를 하는 방법인 윈도우 함수에 대해 배워보겠다.\n\n윈도우 함수\n윈도우 함수를 이용하면 랭킹, 순번 생성 등 일반적인 집약 함수로는 불가능한 고급처리를 할 수 있다. 윈도우 함수의 사용법은 크게 다음과 같다.\n\n<윈도우 함수> over ([partition by <열 리스트>] order by <정렬용 열 리스트>)\n\n이 중 partition by는 생략이 가능하다.\n윈도우 함수로 사용할 수 있는 함수는 크게 다음과 같다.\n\n윈도우 전용 함수: rank, dense_rank, row_number 등\n집약함수: sum, avg, count, max, min 등\n\n\n\n\n\n\n\nNote\n\n\n\n윈도우 전용 함수는 원칙적으로 select 구에만 사용할 수 있다.\n\n\n\nrank: 순위를 계산\nrank 함수는 순위를 구하는 함수다. 예를 들어 Goods 테이블의 상품 중 상품분류(goods_classify) 별로 판매단가(sell_price)가 낮은 순서대로 순위를 구하는 방법은 다음과 같다.\n\nselect goods_name, goods_classify, sell_price,\n    rank() over (partition by goods_classify order by sell_price) as ranking\nfrom Goods;\n\n\n\n\n\n\n\npartition by는 순위를 정할 대상 범위를 설정하며, 어떤 조건으로 그룹을 나눈다고 생각하면 이해가 쉽다. 상품 분류마다 순위를 구하고자 하므로 goods_classify를 입력한다.\norder by는 윈도우 함수를 어떤 열에 어떤 순서로 적용할지 정한다. 판매단가를 오름차순으로 순위를 구하고자 하므로 sell_price를 입력하였다. 만일 내림차순으로 순위를 구하고자 할 경우 desc 를 입력하면 된다. (기본적으로 asc 즉 오름차순이 적용된다.)\n순위를 구하는 윈도우 전용 함수인 rank()를 입력한다.\n\n이 중 partition by를 통해 구분된 레코드 집합을 ’윈도우’라고 하며, 이는 ’범위’를 나타낸다. 만일 partition by를 지정하지 않으면 전체 테이블이 윈도우가 되므로, 아래와 같이 sell_price 열 자체를 기준으로 순위가 구해진다.\n\nselect goods_name, goods_classify, sell_price,\n    rank () over (order by sell_price) as ranking\nfrom Goods; \n\n\n\n\n\n\n순위를 구하는 함수는 rank 외에도 다양하게 존재하며, 그 결과가 약간씩 다르다.\n\nrank: 같은 순위인 행이 복수개 있으면 후순위를 건너뛴다. 예) 1위가 3개인 경우: 1위, 1위, 1위, 4위, …\ndense_rank: 같은 순위인 행이 복수가 있어도 후순위를 건너뛰지 않는다. 예) 1위가 3개인 경우: 1위, 1위, 1위, 2위, …\nrow_number: 순위와 상관없이 연속 번호를 부여한다. 예: 1위가 3개인 레코드인 경우: 1위, 2위, 3위, 4위, …\n\n각 함수 별 차이를 살펴보도록 하자.\n\nselect goods_name, goods_classify, sell_price,\n    rank() over (order by sell_price) as ranking,\n    dense_rank() over (order by sell_price) as ranking,\n    row_number() over (order by sell_price) as ranking\nfrom Goods;\n\n\n\n\n\n\n\n\n윈도우 함수에서 집약 함수의 사용\nsum이나 avg와 같은 집약 함수도 윈도우 함수로 사용할 수 있다.\n\nselect goods_id, goods_name, sell_price,\n    sum(sell_price) over() as current_sum\nfrom Goods;\n\n\n\n\n\n\nover()를 빈 칸으로 둘 경우 current_sum 열에는 모든 sell_price의 합계가 나타난다. 이번에는 누적합계를 구해보도록 하자.\n\nselect goods_id, goods_name, sell_price,\n    sum(sell_price) over(order by goods_id) as current_sum\nfrom Goods;\n\n\n\n\n\n\norder by에 열을 지정할 경우 goods_id를 기준으로 오름차순으로 정렬한 후 누적합계를 구한다. 즉 첫번째 행은 1000, 두번째 행은 1000+500=1500, 세번째 행은 1000+500+4000=5500 과 같이 누적해서 합계가 계산되며, 이는 다른 집계함수도 마찬가지이다. 이번에는 누적평균을 계산해보도록 하자.\n\nselect goods_id, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id) as current_avg\nfrom Goods;\n\n\n\n\n\n\n누적합계와 동일하게 첫번째 행은 (1000)/1=1000, 두번째 행은 (1000+500)/2=750, 세번째 행은 (1000+500+4000)/3=1833.33과 같이 누적해가며 평균을 계산한다.\npartition by를 추가하면 윈도우 별로 집계도 가능하다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    sum(sell_price) over(partition by goods_classify order by goods_id) as current_sum\nfrom Goods;\n\n partition by에 해당하는 goods_classify 별로(사무용품, 의류, 주방용품) 누적합계가 계산된다.\n\n\n이동평균 계산하기\n윈도우 함수에서는 그 범위를 정해 ’프레임’을 만들 수도 있다. 이는 over 내의 order by 구문 뒤에 범위 지정 키워드를 사용하면 된다. 예를 들어 모든 열에 대한 누적평균이 아닌 최근 3개 데이터만 이용해 평균을 구하는 이동평균을 계산하는 쿼리는 다음과 같다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id rows 2 preceding) as moving_avg\nfrom Goods;\n\n\n\n\n\n\nrows n proceding을 입력할 경우 앞의 n 행까지만 프레임을 만들어 계산한다. 위 예제에서는 n=2를 입력했으므로 현재 행과 앞의 두개 행, 즉 3개 행으로만 이동평균을 계산한다. 결과를 살펴보면 1행과 2행은 앞의 두개 행에 해당하는 데이터가 없으므로 존재하는 데이터들로 평균이 계산된다. 3행은 1~3행을 이용해 평균이 계산되며 4행은 2~4행, 5행은 3~5행 등 프레임이 움직이며 이동평균이 계산된다.\n앞의 행이 아닌 뒤의 행을 이용해 계산하고 싶을 경우 preceding 대신 following을 입력한다. 현재 행과 뒤의 두개 행으로 이동평균을 계산하는 법은 다음과 같다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id rows between current row and 2 following) as moving_avg\nfrom Goods;\n\n current row and 2 following는 현재 행과 뒤의 두개 행을 의미하며, 앞서 살펴 본 preceding과 반대로 뒤에서 부터 이동평균의 계산된다. preceding과 following을 동시에 사용하는 것도 가능하다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id\n    rows between 1 preceding and 1 following)\n    as moving_avg\nfrom goods;\n\n\n\n\n\n\nrows between n preceding and m following을 입력하면 앞의 n행과 뒤의 m행 까지를 프레임으로 지정한다. 위의 예에서는 앞의 1개 행과 뒤의 1개 행, 총 3개 행을 이용해 이동평균이 계산된다."
  }
]