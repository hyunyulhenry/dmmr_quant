[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "퀀트 투자 전문가 과정",
    "section": "",
    "text": "Welcome\n본 강의는 R을 이용해 금융 데이터 분석 및 퀀트 투자 프로세스에 대해 살펴봅니다. 수업 목차는 다음과 같습니다.\n\n데이터 분석 프로세스\nSQL 기초\nR 기초 및 데이터분석 실습\nR와 SQL 연결해 사용하기\nAPI를 이용한 데이터 수집\n크롤링 기초\n퀀트 전략을 이용한 포트폴리오 구성하기\n백테스트 실습\n성과 및 위험 평가하기"
  },
  {
    "objectID": "crawl.html",
    "href": "crawl.html",
    "title": "6  크롤링 기초",
    "section": "",
    "text": "7 크롤링 이해하기\n일반적으로 크롤링은 다음의 과정을 따릅니다. 먼저, httr 패키지의 GET() 혹은 POST() 함수를 이용해 데이터를 다운로드한 후 rvest 패키지의 함수들을 이용해 원하는 데이터를 찾는 과정으로 이루어집니다.\n일반적인 크롤링으로는 정적인 데이터, 즉 변하지 않는 데이터만을 수집할 수 있습니다. 한 페이지 안에서 원하는 정보가 모두 드러나는 것을 정적 데이터라 합니다. 반면 입력, 클릭, 로그인 등을 통해 데이터가 바뀌는 것을 동적 데이터라 합니다. 예를 들어 네이버 지도에서 매장을 검색을 한 후 좌측에서 원하는 선택할 때 마다 이에 해당하는 내용이 뜹니다.\n이는 웹페이지에서 사용자가 클릭 등과 같은 조작을 하면 AJAX 호출이 발생하여 그 결과가 페이지의 일부분에만 반영되어 변경되기 때문입니다. 즉 매장을 클릭하면 웹브라우저가 연결된 자바스크립트 코드를 실행하여 해당 매장의 상세 정보가 동일한 페이지에 동적으로 표시됩니다. 정적 페이지와 동적 페이지의 작동 방식 차이는 다음과 같습니다.\n셀레니움을 이용한 경우 정적 페이지와 동적 페이지를 모두 크롤링 할 수 있다는 강력함이 있지만, 상대적으로 속도가 느립니다. 따라서 정적 페이지는 기존의 방법을 이용한 크롤링을, 동적 페이지는 셀레니움을 이용한 크롤링을 하는 것이 일반적입니다."
  },
  {
    "objectID": "crawl.html#인코딩의-이해와-r에서-utf-8-설정하기",
    "href": "crawl.html#인코딩의-이해와-r에서-utf-8-설정하기",
    "title": "6  크롤링 기초",
    "section": "6.1 인코딩의 이해와 R에서 UTF-8 설정하기",
    "text": "6.1 인코딩의 이해와 R에서 UTF-8 설정하기\nR에서 스크립트를 한글로 작성해 저장한 후 이를 다시 불러올 때, 혹은 한글로 된 데이터를 크롤링하면 오류가 뜨거나 읽을 수 없는 문자로 나타나는 경우가 종종 있습니다. 이는 한글 인코딩 때문에 발생하는 문제이며, 이러한 현상을 흔히 ’인코딩이 깨졌다’라고 표현합니다. 인코딩이란 사람이 사용하는 언어를 컴퓨터가 사용하는 0과 1로 변환하는 과정을 말하며, 이와 반대의 과정을 디코딩이라고 합니다.\n이렇듯 사람과 컴퓨터 간의 언어를 번역하기 위해 최초로 사용된 방식이 아스키(ASCII: American Standard Code for Information Interchange)입니다. 0부터 127까지 총 128개 바이트에 알파벳과 숫자, 자주 사용되는 특수문자 값을 부여하고, 문자가 입력되면 이에 대응되는 바이트가 저장됩니다. 그러나 아스키의 ’American’이라는 이름에서 알 수 있듯이 이는 영어의 알파벳이 아닌 다른 문자를 표현하는 데 한계가 있으며, 이를 보완하기 위한 여러 방법이 나오게 되었습니다."
  },
  {
    "objectID": "crawl.html#한글-인코딩-방식의-종류",
    "href": "crawl.html#한글-인코딩-방식의-종류",
    "title": "6  크롤링 기초",
    "section": "6.2 한글 인코딩 방식의 종류",
    "text": "6.2 한글 인코딩 방식의 종류\n인코딩에 대한 전문적인 내용은 이 책의 범위를 넘어가며, 크롤링을 위해서는 한글을 인코딩하는 데 쓰이는 EUC-KR과 CP949, UTF-8 정도만 이해해도 충분합니다. 만일 ’알’이라는 단어를 인코딩한다면 어떤 방법이 있을까요? 먼저 ’알’이라는 문자 자체에 해당하는 코드를 부여해 나타내는 방법이 있습니다. 아니면 이를 구성하는 모음과 자음을 나누어 ㅇ, ㅏ, ㄹ 각각에 해당하는 코드를 부여하고 이를 조합할 수도 있습니다. 전자와 같이 완성된 문자 자체로 나타내는 방법을 완성형, 후자와 같이 각 자모로 나타내는 방법을 조합형이라고 합니다.\n한글 인코딩 중 완성형으로 가장 대표적인 방법은 EUC-KR입니다. EUC-KR은 현대 한글에서 많이 쓰이는 문자 2,350개에 번호를 붙인 방법입니다. 그러나 2,350개 문자로 모든 한글 자모의 조합을 표현하기 부족해, 이를 보완하고자 마이크로소프트가 도입한 방법이 CP949입니다. CP949는 11,720개 한글 문자에 번호를 붙인 방법으로 기존 EUC-KR보다 나타낼 수 있는 한글의 개수가 훨씬 많아졌습니다. 윈도우의 경우 기본 인코딩이 CP949로 되어 있습니다.\n조합형의 대표적 방법인 UTF-8은 모음과 자음 각각에 코드를 부여한 후 조합해 한글을 나타냅니다. 조합형은 한글뿐만 아니라 다양한 언어에 적용할 수 있다는 장점이 있어 전 세계 웹페이지의 대부분이 UTF-8로 만들어지고 있습니다."
  },
  {
    "objectID": "crawl.html#웹의-동작-방식",
    "href": "crawl.html#웹의-동작-방식",
    "title": "6  크롤링 기초",
    "section": "6.3 웹의 동작 방식",
    "text": "6.3 웹의 동작 방식\n크롤링은 웹사이트의 정보를 수집하는 과정입니다. 따라서 웹이 어떻게 동작하는지 이해할 필요가 있습니다.\n\n\n\n\n\n먼저 클라이언트란 여러분의 데스크톱이나 휴대폰과 같은 장치와 크롬이나 파이어폭스와 같은 소프트웨어를 의미합니다. 서버는 웹사이트와 앱을 저장하는 컴퓨터를 의미합니다. 클라이언트가 특정 정보를 요구하는 과정을 ’요청’이라고 하며, 서버가 해당 정보를 제공하는 과정을 ’응답’이라고 합니다. 그러나 클라이언트와 서버가 연결되어 있지 않다면 둘 사이에 정보를 주고받을 수 없으며, 이를 연결하는 공간이 바로 인터넷입니다. 또한 건물에도 고유의 주소가 있는 것처럼, 각 서버에도 고유의 주소가 있는데 이것이 인터넷 주소 혹은 URL입니다.\n여러분이 네이버에서 경제 기사를 클릭하는 경우를 생각해봅시다. 클라이언트는 사용자인 여러분이고, 서버는 네이버이며, URL은 www.naver.com 이 됩니다. 경제 기사를 클릭하는 과정이 요청이며, 클릭 후 해당 페이지를 보여주는 과정이 응답입니다.\n\n6.3.1 HTTP\n클라이언트가 각기 다른 방법으로 데이터를 요청한다면, 서버는 해당 요청을 알아듣지 못할 것입니다. 이를 방지하기 위해 규정된 약속이나 표준에 맞추어 데이터를 요청해야 합니다. 이러한 약속을 HTTP(HyperText Transfer Protocol)라고 합니다.\n클라이언트가 서버에게 요청의 목적이나 종류를 알리는 방법을 HTTP 요청 방식(HTTP Request Method)이라고 합니다. HTTP 요청 방식은 크게 GET, POST, PUT, DELETE라는 네 가지로 나눌 수 있지만 크롤링에는 GET과 POST 방식이 대부분 사용되므로 이 두 가지만 알아도 충분합니다.\n인터넷을 사용하다 보면 한 번쯤 ‘이 페이지를 볼 수 있는 권한이 없음(HTTP 오류 403 - 사용할 수 없음)’ 혹은 ’페이지를 찾을 수 없음(HTTP 오류 404 - 파일을 찾을 수 없음)’이라는 오류를 본 적이 있을 겁니다. 여기서 403과 404라는 숫자는 클라이언트의 요청에 대한 서버의 응답 상태를 나타내는 HTTP 상태 코드입니다.\nHTTP 상태 코드는 100번대부터 500번대까지 있으며, 성공적으로 응답을 받을 시 200번 코드를 받게 됩니다. 각 코드에 대한 내용은 HTTP 상태 코드를 검색하면 확인할 수 있으며, 크롤링 과정에서 오류가 발생할 시 해당 코드를 통해 어떤 부분에서 오류가 발생했는지 확인이 가능합니다.\n\n\n\n\n\n\n\n\n코드\n내용\n설명\n\n\n\n\n1xx\nInformational (조건부 응답)\n리퀘스트를 받고, 처리 중에 있음\n\n\n2xx\nSuccess (성공)\n리퀘스트를 정상적으로 처리함\n\n\n3xx\nRedirection (리디렉션)\n리퀘스트 완료를 위해 추가 동작이 필요함\n\n\n4xx\nClient Error (클라이언트 오류)\n클라이언트 요청을 처리할 수 없어 오류 발생\n\n\n5xx\nServer Error (서버 오류)\n서버에서 처리를 하지 못하여 오류 발생"
  },
  {
    "objectID": "crawl.html#html과-css",
    "href": "crawl.html#html과-css",
    "title": "6  크롤링 기초",
    "section": "6.4 HTML과 CSS",
    "text": "6.4 HTML과 CSS\n클라이언트와 서버가 데이터를 주고받을 때는 디자인이라는 개념이 필요하지 않습니다. 그러나 응답받은 정보를 사람이 확인하려면 보기 편한 방식으로 바꾸어줄 필요가 있는데 웹페이지가 그러한 역할을 합니다. 웹페이지의 제목, 단락, 목록 등 레이아웃을 잡아주는 데 쓰이는 대표적인 마크업 언어가 HTML(HyperText Markup Language)입니다. HTML을 통해 잡혀진 뼈대에 글자의 색상이나 폰트, 배경색, 배치 등 화면을 꾸며주는 역할을 하는 것이 CSS(Cascading Style Sheets)입니다.\n우리의 목적은 웹페이지를 만드는 것이 아니므로 HTML과 CSS에 대해 자세히 알 필요는 없습니다. 그러나 크롤링하고자 하는 데이터가 웹페이지의 어떤 태그 내에 위치하고 있는지, 어떻게 크롤링하면 될지 파악하기 위해서는 HTML과 CSS에 대한 기본적인 지식은 알아야 합니다.\nHTML과 CSS의 실습은 아래 페이지에서 해볼 수 있습니다.\nhttps://www.w3schools.com/html/tryit.asp?filename=tryhtml_intro\n\n6.4.1 HTML 기본 구조\nHTML은 크게 메타 데이터를 나타내는 head와 본문을 나타내는 body로 나누어집니다. head에서 title은 웹페이지에서 나타나는 제목을 나타내며 body 내에는 본문에 들어갈 각종 내용들이 포함되어 있습니다.\n\n<html>\n<head>\n<title>Page Title</title>\n</head>\n\n<body>\n<h2> This is page heading </h2>\n<p> THis is first paragraph text </p>\n</body>\n</html>\n\n\n\n\n\n\n<head> 부분에 입력한 내역은 실습 페이지 구조 상 확인되지 않지만, <body> 부분에 입력한 글자들은 우측 결과물 페이지에서 확인이 가능합니다. <h2>와 <p> 등의 태그가 하는 역할들에 대해서 더욱 자세히 알아보도록 하겠습니다.\n\n\n6.4.2 태그와 속성\nHTML 코드는 태그와 속성, 내용으로 이루어져 있습니다. 크롤링한 데이터에서 특정 태그의 데이터만을 찾는 방법, 특정 속성의 데이터만을 찾는 방법, 뽑은 자료에서 내용만을 찾는 방법 등 내용을 찾는 방법이 모두 다르기 때문에 태그와 속성에 대해 좀 더 자세히 살펴보겠습니다.\n\n\n\n\n\n꺾쇠(<>)로 감싸져 있는 부분을 태그라고 하며, 여는 태그 <>가 있으면 반드시 이를 닫는 태그인 </>가 쌍으로 있어야 합니다. 속성은 해당 태그에 대한 추가적인 정보를 제공해주는 것으로, 뒤에 속성값이 따라와야 합니다. 내용은 우리가 눈으로 보는 텍스트 부분을 의미합니다. 앞의 HTML 코드는 문단을 나타내는\n\n, 정렬을 나타내는 align 속성과 center를 통해 가운데 정렬을 지정하며, 내용에는 ’퀀트 투자 Cookbook’을 나타내고,\n\n태그를 통해 태그를 마쳤습니다.\n\n\n6.4.3 h 태그와 p 태그\nh 태그는 폰트의 크기를 나타내는 태그이며, p 태그는 문단을 나타내는 태그입니다. 이를 사용한 간단한 예제는 다음과 같습니다. h 태그의 숫자가 작을수록 텍스트 크기는 커지는 것이 확인되며, 숫자는 1에서 6까지 지원됩니다. p 태그를 사용하면 각각의 문단이 만들어지는 것이 확인됩니다.\n\n<html>\n<body>\n\n<h1>Page heading: size 1</h1>\n<h2>Page heading: size 2</h2>\n<h3>Page heading: size 3</h3>\n\n<p>Quant Cookbook</p>\n<p>By Henry</p>\n\n</body>\n</html>\n\n\n\n\n\n\nh 태그의 숫자가 작을수록 텍스트 크기는 커지며, 숫자는 1에서 6까지 지원됩니다. 또한 p 태그를 사용하면 각각의 문단이 만들어집니다.\n\n\n6.4.4 리스트를 나타내는 ul 태그와 ol 태그\nul과 ol 태그는 리스트(글머리 기호)를 만들 때 사용됩니다. ul은 순서가 없는 리스트(unordered list), ol은 순서가 있는 리스트(ordered list)를 만듭니다.\n\n<html>\n<body>\n\n<h2> Unordered List</h2>\n<ul>\n  <li>List 1</li>\n  <li>List 2</li>\n  <li>List 3</li>\n</ul>  \n\n<h2> Ordered List</h2>\n<ol>\n  <li>List A</li>\n  <li>List B</li>\n  <li>List C</li>\n  <li>List D</li>\n </ol> \n\n</body>\n</html>\n\n\n\n\n\n\nul 태그로 감싼 부분은 글머리 기호가 순서가 없는 •으로 표현되며, ol 태그로 감싼 부분은 숫자가 순서대로 표현됩니다. 각각의 리스트는 li를 통해 생성됩니다.\n\n\n6.4.5 table 태그\ntable 태그는 표를 만드는 태그입니다.\n\n<html>\n<body>\n\n<h2>Sample Table</h2>\n\n<table>\n  <tr>\n    <th>Column 1</th>\n    <th>Column 2</th>\n    <th>Column 3</th>    \n  </tr>\n  <tr>\n    <td>1</td>\n    <td>2</td>\n    <td>3</td>\n  </tr>\n  <tr>\n    <td>A</td>\n    <td>B</td>\n    <td>C</td>\n  </tr>\n  <tr>\n    <td>a</td>\n    <td>b</td>\n    <td>c</td>\n  </tr>\n</table>\n\n</body>\n</html>\n\n\n\n\n\n\ntable 태그 내의 tr 태그는 각 행을 의미하며, 각 셀의 구분은 th 혹은 td 태그를 통해 구분할 수 있습니다. th 태그는 진하게 표현되므로 주로 테이블의 제목에 사용되고, td 태그는 테이블의 내용에 사용됩니다.\n\n\n6.4.6 a 태그와 img 태그 및 속성\na 태그와 img 태그는 다른 태그와는 다르게, 혼자 쓰이기보다는 속성과 결합해 사용됩니다. a 태그는 href 속성과 결합해 다른 페이지의 링크를 걸 수 있습니다. img 태그는 src 속성과 결합해 이미지를 불러옵니다.\n\n<html>\n<body>\n\n<h2>a tag & href attribute</h2>\n<p>HTML links are defined with the a tag.\nThe link address is specified in the href attribute:</p>\n\n<a href=\"https://blog.naver.com/leebisu\">Henry's Quantopia</a>\n\n<h2>img tag & src attribute</h2>\n<p>HTML images are defined with the img tag,\nand the filename of the image source is\nspecified in the src attribute:</p>\n\n<img src=\"https://www.python.org/static/img/python-logo.png\",\nwidth=\"200\",height=\"100\">\n\n</body>\n</html>\n\n\n\n\n\n\na 태그 뒤 href 속성에 연결하려는 웹페이지 주소를 속성값(https://blog.naver.com/leebisu)으로으로){.uri} 입력한 후 내용(Henry’s Quantopia)을 입력하면, 내용 텍스트에 웹페이지의 링크가 추가됩니다. img 태그 뒤 src 속성의 속성값에는 불러오려는 이미지 주소를 입력하며, width 속성과 height 속성을 통해 이미지의 가로 세로 길이를 조절할 수도 있습니다. 페이지 내에서 링크된 주소를 모두 찾거나, 모든 이미지를 저장하려고 할 때 속성값을 찾으면 손쉽게 원하는 작업을 할 수 있습니다.\n\n\n6.4.7 div 태그\ndiv 태그는 화면의 전체적인 틀(레이아웃)을 만들 때 주로 사용하는 태그입니다. 단독으로도 사용될 수 있으며, 꾸밈을 담당하는 style 속성과 결합되어 사용되기도 합니다.\n\n<html>\n<body>\n\n<div style=\"background-color:black;color:white\">\n  <h5>First Div</h5>\n  <p>Black backgrond, White Color</p>\n</div> \n\n<div style=\"background-color:yellow;color:red\">\n  <h5>Second Div</h5>\n  <p>Yellow backgrond, Red Color</p>\n</div> \n\n<div style=\"background-color:blue;color:grey\">\n  <h5>Second Div</h5>\n  <p>Blue backgrond, Grey Color</p>\n</div> \n\n</body>\n</html>\n\n\n\n\n\n\ndiv 태그를 통해 총 세 개의 레이아웃으로 나누어진 것을 알 수 있습니다. style 속성 중 background-color는 배경 색상을, color는 글자 색상을 의미하며, 각 레이아웃마다 다른 스타일이 적용되었습니다.\n\n\n6.4.8 CSS\nCSS는 앞서 설명했듯이 웹페이지를 꾸며주는 역할을 합니다. head에서 각 태그에 CSS 효과를 입력하면 본문의 모든 해당 태그에 CSS 효과가 적용됩니다. 이처럼 웹페이지를 꾸미기 위해 특정 요소에 접근하는 것을 셀렉터(Selector)라고 합니다.\n\n<html>\n<head>\n<style>\nbody {background-color: powderblue;}\nh4   {color: blue;}\n</style>\n</head>\n<body>\n\n<h4>This is a heading</h4>\n<p>This is a first paragraph.</p>\n<p>This is a second paragraph.</p>\n\n</body>\n</html>\n\n\n\n\n\n\nhead의 style 태그에서 여러 CSS 효과가 정의되었습니다. 먼저 body의 전체 배경 색상을 powderblue로 설정했으며, h4 태그의 글자 색상은 파란색(blue)으로 설정했습니다. body 태그 내에서 style에 태그를 주지 않더라도, head에서 정의한 CSS 효과가 모두 적용됩니다.\n\n\n6.4.9 클래스와 id\n위의 예제에서 클래스 속성을 이용하면 특정 이름을 가진 클래스에 동일한 효과를 적용할 수 있습니다.\n\n<html>\n<style>\n.language {\n  background-color: tomato;\n  color: white;\n  padding: 10px;\n} \n.desc {\n  background-color: moccasin;\n  color: black;\n  padding: 10px;\n} \n</style>\n\n<div>\n<h2 class=\"language\">Python</h2>\n<p class=\"desc\"> Python is a high-level, general-purpose programming language.</p>\n</div>\n\n<div>\n<h2>SQL</h2>\n<p>SQL is a domain-specific language used in programming and designed for managing data held in a RDBMS, or for stream processing in a RDBMS. </p>\n</div>\n\n<div>\n<h2 class=\"language\">R</h2>\n<p class=\"desc\">R is a free software environment for statistical computing and graphics.</p>\n<div>\n</html>\n\n\n\n\n\n\n셀렉터를 클래스에 적용할 때는 클래스명 앞에 마침표(.)를 붙여 표현합니다다. 위 예제에서 language 클래스는 배경 색상이 tomato, 글자 색상은 흰색, 여백은 10px로 정의됩니다. desc 클래스는 배경 색상이 moccasin, 글자 색상은 검은색, 여백은 10px로 정의되었습니다. 본문의 첫 번째(Python)와 세 번째(R) 레이아웃의 h2 태그 뒤에는 language 클래스를, p 태그 뒤에는 desc 클래스를 속성으로 입력했습니다. 따라서 해당 레이아웃에만 CSS 효과가 적용되며, 클래스 값이 없는 두 번째 레이아웃에는 효과가 적용되지 않습니다.\nid 또한 이와 비슷한 역할을 합니다. HTML 내에서 클래스는 여러 개가 정의될 수 있는 반면, id는 단 하나만 사용하기를 권장합니다.\n\n<html>\n<head>\n<style>\n\n#myHeader {\n  background-color: lightblue;\n  color: black;\n  padding: 15px;\n  text-align: center;\n}\n\n</style>\n</head>\n<body>\n\n<h1 id=\"myHeader\">My Header</h1>\n\n</body>\n</html>\n\n\n\n\n\n\n셀렉터를 id에 적용할 때는 id명 앞에 샵(#)를 붙여 표현하며, 페이지에서 한 번만 사용된다는 점을 제외하면 클래스와 사용 방법이 거의 동일합니다. 클래스나 id 값을 통해 원하는 내용을 크롤링하는 경우도 많으므로, 각각의 이름 앞에 마침표(.)와 샵(#) 을 붙여야 한다는 점을 꼭 기억해야 합니다."
  },
  {
    "objectID": "crawl.html#get과-post-방식-이해하기",
    "href": "crawl.html#get과-post-방식-이해하기",
    "title": "6  크롤링 기초",
    "section": "7.1 GET과 POST 방식 이해하기",
    "text": "7.1 GET과 POST 방식 이해하기\n우리가 인터넷에 접속해 서버에 파일을 요청하면, 서버는 이에 해당하는 파일을 우리에게 보내줍니다. 크롬과 같은 웹 브라우저는 이러한 과정을 사람이 수행하기 편하고 시각적으로 보기 편하도록 만들어진 것이며, 인터넷 주소는 서버의 주소를 기억하기 쉽게 만든 것입니다. 우리가 서버에 데이터를 요청하는 형태는 다양하지만 크롤링에서는 주로 GET과 POST 방식을 사용합니다.\n\n\n\n\n\n\n7.1.1 GET 방식\nGET 방식은 인터넷 주소를 기준으로 이에 해당하는 데이터나 파일을 요청하는 것입니다. 주로 클라이언트가 요청하는 쿼리를 앰퍼샌드(&) 혹은 물음표(?) 형식으로 결합해 서버에 전달합니다.\n네이버 홈페이지에 접속한 후 [퀀트]를 검색하면, 주소 끝부분에 [&query=퀀트]가 추가되며 이에 해당하는 페이지의 내용을 보여줍니다. 즉, 해당 페이지는 GET 방식을 사용하고 있으며 입력 종류는 query, 입력값은 [퀀트]임을 알 수 있습니다.\n\n\n\n\n\n[헤지펀드]를 다시 검색하면, 주소 끝부분이 [&query=헤지펀드&oquery=퀀트…]로 변경됩니다. 현재 입력값은 헤지펀드, 기존 입력값은 퀀트이며 이러한 과정을 통해 연관검색어가 생성됨도 유추해볼 수 있습니다.\n\n\n\n\n\n\n\n7.1.2 POST 방식\nPOST 방식은 사용자가 필요한 값을 추가해서 요청하는 방법입니다. GET 방식과 달리 클라이언트가 요청하는 쿼리를 body에 넣어서 전송하므로 요청 내역을 직접 볼 수 없습니다. 동행복권 홈페이지에 접속해 [당첨결과] 메뉴를 확인해봅시다.\n\nhttps://www.dhlottery.co.kr/gameResult.do?method=byWin\n\n\n\n\n\n\n이번엔 회차 바로가기를 변경한 후 [조회]를 클릭합니다. 페이지의 내용은 선택일 기준으로 변경되었지만, 주소는 변경되지 않고 그대로 남아 있습니다. GET 방식에서는 입력 항목에 따라 웹페이지 주소가 변경되었지만, POST 방식을 사용해 서버에 데이터를 요청하는 해당 웹사이트는 그렇지 않은 것을 알 수 있습니다.\nPOST 방식의 데이터 요청 과정을 살펴보려면 개발자도구를 이용해야 하며, 크롬에서는 [F12]키를 눌러 개발자도구 화면을 열 수 있습니다. 개발자도구 화면을 연 상태에서 다시 한번 [조회]를 클릭해봅시다. [Network] 탭을 클릭하면, [조회]을 클릭함과 동시에 브라우저와 서버 간의 통신 과정을 살펴볼 수 있습니다. 이 중 상단의 gameResult.do?method=byWin 이라는 항목이 POST 형태임을 알 수 있습니다.\n\n\n\n\n\n해당 메뉴를 클릭하면 통신 과정을 좀 더 자세히 알 수 있습니다. [Payload] 탭의 [Form Data]에는 서버에 데이터를 요청하는 내역이 있습니다. drwNo와 dwrNoList에는 선택한 회차의 숫자가 들어가 있습니다.\n\n\n\n\n\n이처럼 POST 방식은 요청하는 데이터에 대한 쿼리가 GET 방식처럼 URL을 통해 전송되는 것이 아닌 body를 통해 전송되므로, 이에 대한 정보는 웹 브라우저를 통해 확인할 수 없으며, 개발자도구 화면을 통해 확인해야 합니다."
  },
  {
    "objectID": "crawl.html#명언-크롤링하기",
    "href": "crawl.html#명언-크롤링하기",
    "title": "6  크롤링 기초",
    "section": "8.1 명언 크롤링하기",
    "text": "8.1 명언 크롤링하기\n크롤링의 간단한 예제로 ‘Quotes to Scrape’ 사이트에 있는 명언을 수집힙니다.\n\nhttps://quotes.toscrape.com/\n\n먼저 해당사이트에 접속한 후, 명언에 해당하는 부분에 마우스 커서를 올려둔 후 마우스 오른쪽 버튼을 클릭하고 [검사]를 선택하면 개발자 도구 화면이 나타납니다. 여기서 해당 글자가 HTML 내에서 어떤 부분에 위치하는지 확인할 수 있습니다. 각 네모에 해당하는 부분은 [div 태그의 quote 클래스]에 위치하고 있으며, 명언은 [div 태그 → span 태그의 text 클래스]에, 명언가는 [div 태그 → span 태그 → small 태그의 author 클래스]에 위치하고 있습니다.\n\n\n\n\n\n먼저 해당 페이지의 내용을 불러옵니다.\n\nlibrary(httr)\nlibrary(rvest)\n\nurl = 'https://quotes.toscrape.com/'\nquote = GET(url)\n\nprint(quote)\n\nResponse [https://quotes.toscrape.com/]\n  Date: 2023-01-19 02:15\n  Status: 200\n  Content-Type: text/html; charset=utf-8\n  Size: 11.1 kB\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Quotes to Scrape</title>\n    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n    <link rel=\"stylesheet\" href=\"/static/main.css\">\n</head>\n<body>\n    <div class=\"container\">\n...\n\n\nurl에 해당 주소를 입력한 후 GET() 함수를 이용해 해당 페이지의 내용을 받아온다. Response 부분을 확인해보면 Status가 200, 즉 데이터가 이상 없이 받아졌음이 확인됩니다.\n이제 rvest 패키지를 이용해 html 정보를 불러오도록 합니다.\n\nquote_html = read_html(quote)\n\nprint(quote_html)\n\n{html_document}\n<html lang=\"en\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body>\\n    <div class=\"container\">\\n        <div class=\"row header-box\"> ...\n\n\nread_html() 함수는 받아온 페이지 내용을 html 정보로 변환합니다. 이를 확인해보면 head 부분과 body 부분이 존재합니다.\n우리는 개발자 도구 화면에서 명언에 해당하는 부분이 [div 태그의 quote 클래스 → span 태그의 text 클래스]에 위치하고 있음을 살펴보았습니다. 이를 활용해 명언만을 추출하는 방법은 다음과 같습니다.\n\nquote_div = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span.text')\n\nprint(quote_div)\n\n{xml_nodeset (10)}\n [1] <span class=\"text\" itemprop=\"text\">“The world as we have created it is a ...\n [2] <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show  ...\n [3] <span class=\"text\" itemprop=\"text\">“There are only two ways to live your ...\n [4] <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, ...\n [5] <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is g ...\n [6] <span class=\"text\" itemprop=\"text\">“Try not to become a man of success.  ...\n [7] <span class=\"text\" itemprop=\"text\">“It is better to be hated for what yo ...\n [8] <span class=\"text\" itemprop=\"text\">“I have not failed. I've just found 1 ...\n [9] <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never ...\n[10] <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you  ...\n\n\n\nhtml_nodes() 함수는 태그, id, 클래스, xpath 등의 정보를 이용해 해당하는 데이터를 추출합니다. div 태그에서 클래스에 해당하는 quote 클래스에 해당하는 데이터를 찾으며, 클래스의 경우 앞에 콤마(.)를 붙입니다(id의 경우 앞에 샵(#)을 붙입니다). html_node() 함수는 해당하는 정보 중 가장 첫번째 데이터만을 추출하며, html_nodes() 함수는 모든 데이터를 추출하는 차이가 있습니다.\nspan 태그 중 text 클래스를 찾습니다.\n\n결과를 확인하면 개발자 도구 화면과 거의 일치합니다. 이제 텍스트에 해당하는 부분만 추출합니다.\n\nquote_text = quote_div %>%\n  html_text()\n\nprint(quote_text)\n\n [1] \"“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\"                \n [2] \"“It is our choices, Harry, that show what we truly are, far more than our abilities.”\"                                              \n [3] \"“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\"\n [4] \"“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\"                           \n [5] \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\"                    \n [6] \"“Try not to become a man of success. Rather become a man of value.”\"                                                                \n [7] \"“It is better to be hated for what you are than to be loved for what you are not.”\"                                                 \n [8] \"“I have not failed. I've just found 10,000 ways that won't work.”\"                                                                  \n [9] \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\"                                              \n[10] \"“A day without sunshine is like, you know, night.”\"                                                                                 \n\n\nhtml_text() 함수를 이용하면 html 에서 텍스트 정보만을 추출할 수 있습니다.\n이번에는 명언을 말한 사람에 해당하는 정보만 수집합니다.\n\nquote_who = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span') %>%\n  html_nodes('small.author') %>%\n  html_text()\n\nprint(quote_who)\n\n [1] \"Albert Einstein\"   \"J.K. Rowling\"      \"Albert Einstein\"  \n [4] \"Jane Austen\"       \"Marilyn Monroe\"    \"Albert Einstein\"  \n [7] \"André Gide\"        \"Thomas A. Edison\"  \"Eleanor Roosevelt\"\n[10] \"Steve Martin\"     \n\n\n파이프 오퍼레이터(%>%)를 통해 html에서 원하는 부분만 추출하는 작업을 단계별로 진행할 수 있습니다.\n마지막으로 명언가 정보에 해당하는 링크(about)를 불러오도록 합니다. 이는 [quote 클래스 → span 태그 → a 태그 내에서 href 속성]에 위치하고 있습니다.\n\nquote_link = quote_html %>%\n  html_nodes('div.quote') %>%\n  html_nodes('span') %>%\n  html_nodes('a') %>%\n  html_attr('href')\n\nprint(quote_link)\n\n [1] \"/author/Albert-Einstein\"   \"/author/J-K-Rowling\"      \n [3] \"/author/Albert-Einstein\"   \"/author/Jane-Austen\"      \n [5] \"/author/Marilyn-Monroe\"    \"/author/Albert-Einstein\"  \n [7] \"/author/Andre-Gide\"        \"/author/Thomas-A-Edison\"  \n [9] \"/author/Eleanor-Roosevelt\" \"/author/Steve-Martin\"     \n\n\nhtml_attr() 함수는 속성값을 찾아주는 함수이며, href 속성에 해당하는 값을 찾아줍니다.\n기본 url(https://quotes.toscrape.com)에에){.uri} 해당하는 정보가 없으므로 이를 추가적으로 붙여줍니다.\n\nquote_link = paste0('https://quotes.toscrape.com', quote_link)\n\nquote_link\n\n [1] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [2] \"https://quotes.toscrape.com/author/J-K-Rowling\"      \n [3] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [4] \"https://quotes.toscrape.com/author/Jane-Austen\"      \n [5] \"https://quotes.toscrape.com/author/Marilyn-Monroe\"   \n [6] \"https://quotes.toscrape.com/author/Albert-Einstein\"  \n [7] \"https://quotes.toscrape.com/author/Andre-Gide\"       \n [8] \"https://quotes.toscrape.com/author/Thomas-A-Edison\"  \n [9] \"https://quotes.toscrape.com/author/Eleanor-Roosevelt\"\n[10] \"https://quotes.toscrape.com/author/Steve-Martin\"     \n\n\n세 개의 데이터를 하나의 데이터프레임으로 묶어 정리합니다.\n\nquote_df = data.frame(\n  'quote' = quote_text,\n  'author' = quote_who,\n  'link' = quote_link\n)\n\nquote_df\n\n                                                                                                                                   quote\n1                  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n2                                                “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n3  “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n4                             “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n5                      “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n6                                                                  “Try not to become a man of success. Rather become a man of value.”\n7                                                   “It is better to be hated for what you are than to be loved for what you are not.”\n8                                                                    “I have not failed. I've just found 10,000 ways that won't work.”\n9                                                “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n10                                                                                  “A day without sunshine is like, you know, night.”\n              author                                                 link\n1    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n2       J.K. Rowling       https://quotes.toscrape.com/author/J-K-Rowling\n3    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n4        Jane Austen       https://quotes.toscrape.com/author/Jane-Austen\n5     Marilyn Monroe    https://quotes.toscrape.com/author/Marilyn-Monroe\n6    Albert Einstein   https://quotes.toscrape.com/author/Albert-Einstein\n7         André Gide        https://quotes.toscrape.com/author/Andre-Gide\n8   Thomas A. Edison   https://quotes.toscrape.com/author/Thomas-A-Edison\n9  Eleanor Roosevelt https://quotes.toscrape.com/author/Eleanor-Roosevelt\n10      Steve Martin      https://quotes.toscrape.com/author/Steve-Martin"
  },
  {
    "objectID": "crawl.html#xpath를-이용해-원하는-지점만-찾기",
    "href": "crawl.html#xpath를-이용해-원하는-지점만-찾기",
    "title": "6  크롤링 기초",
    "section": "8.2 xpath를 이용해 원하는 지점만 찾기",
    "text": "8.2 xpath를 이용해 원하는 지점만 찾기\nxpath란 HTML의 위치를 나타내는 형태입니다. 만일 웹페이지에서 한 지점의 데이터만 추출해야 할 경우, 번거롭게 html의 구조를 모두 발라내기 보다는 xpath를 이용하는 것이 훨씬 효율적입니다.\n예제로 yes24의 판매지수를 크롤링 하도록 하겠습니다. 해당 지수는 책의 출간일 그리고 판매량에 따라 매일 바뀝니다.\nhttp://www.yes24.com/Product/Goods/108408162\n이 중 개발자도구 화면에서 판매지수에 해당하는 부분을 찾은 후, 우클릭 해 [Copy → Copy xpath]를 선택하면 해당 내역이 복사됩니다. 이는 다음과 같습니다.\n//*[@id=\"yDetailTopWrap\"]/div[2]/div[1]/span[3]/span[3]\n이를 이용해 크롤링 하는 법은 다음과 같습니다.\n\nlibrary(rvest)\nlibrary(httr)\n\nurl = 'http://www.yes24.com/Product/Goods/108408162'\n\ndata = GET(url)\n\ndata_sales = data %>%\n  read_html() %>%\n  html_nodes(xpath = '//*[@id=\"yDetailTopWrap\"]/div[2]/div[1]/span[3]/span[3]')\n\nprint(data_sales)\n\n{xml_nodeset (1)}\n[1] <span class=\"gd_sellNum\">\\r\\n                <em class=\"divi\">|</em>\\r\\n  ...\n\n\nxpath를 통해 해당 부분만 손쉽게 추출할 수 있습니다. 이제 판매지수에 해당하는 숫자만 선택하도록 하면 됩니다.\n\nlibrary(stringr)\n\ndata_sales %>%\n  html_text() %>%\n  str_extract_all('(\\\\d)+') %>%\n  .[[1]] %>%\n  str_c(., collapse = '') %>%\n  as.numeric()\n\n[1] 4155\n\n\n먼저 정규표현식을 이용해 숫자부분만 추출할 수 있습니다.\n\nhtml_text() 함수를 통해 텍스트 데이터만 불러옵니다.\nstr_extract_all() 함수 내에 정규표현식을 이용해 숫자에 해당하는 데이터만 추출합니다.\n첫번째 원소를 선택한다.\nstr_c() 함수를 통해 모든 텍스트를 붙입니다.\nas.numeric() 함수를 이용해 숫자 형태로 변경합니다.\n\n그러나 정규표현식은 꽤나 복잡합니다. 다행히 패키지 내 함수를 사용하면 위 과정을 매우 간단하게 수행할 수 있습니다.\n\ndata_sales %>%\n  html_text() %>%\n  readr::parse_number()\n\n[1] 4155\n\n\nreadr 패키지의 parse_number() 함수는 여러 텍스트 중 숫자 형태만 추출해주는 매우 유용한 함수입니다."
  },
  {
    "objectID": "crawl.html#표-크롤링",
    "href": "crawl.html#표-크롤링",
    "title": "6  크롤링 기초",
    "section": "8.3 표 크롤링",
    "text": "8.3 표 크롤링\n표는 html 중 td와 th 태그로 구성되어 있으며, 이를 일일이 추출하며 다시 표 형태로 만드는 것은 사실상 불가능에 가깝습니다. 다행히 R의 크롤링 패키지에는 표 형태만 간단하게 추출할 수 있는 함수 역시 존재합니다.\n예제로써 UFC의 역대 챔피언 리스트를 크롤링 해보도록 합시다.\nhttps://en.wikipedia.org/wiki/List_of_UFC_champions\n위 페이지에는 각 체급별 챔피언의 역사가 표 형태로 정리되어 있습니다. 이 중 표만 가져오는 법은 다음과 같습니다.\n\nlibrary(rvest)\nlibrary(httr)\n\nurl = 'https://en.wikipedia.org/wiki/List_of_UFC_champions'\ndata_ufc = GET(url)\n\n\ndata_ufc %>%\n  read_html() %>%\n  html_table()\n\nhtml_table() 함수는 테이블 형태의 데이터만 추출하는 함수입니다. 그러나 윈도우의 경우 다음과 같은 오류가 뜹니다.\n\nError in type.convert.default(x, as.is = TRUE, dec = dec, na.strings = na.strings) : \n  invalid multibyte string at '<e2><94>'\n\n이는 웹페이지와 컴퓨터의 인코딩이 달라 발생하는 오류이며, 잠시 로케일 언어를 영어로 변경하여 크롤링 하면 오류가 발생하지 않습니다.\n\nSys.setlocale(\"LC_ALL\", \"English\")\n\nWarning in Sys.setlocale(\"LC_ALL\", \"English\"): using locale code page other than\n65001 (\"UTF-8\") may cause problems\n\n\n[1] \"LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252\"\n\nchampion_list = data_ufc %>%\n  read_html() %>%\n  html_table()\n\nSys.setlocale(\"LC_ALL\", \"Korean\")\n\nWarning in Sys.setlocale(\"LC_ALL\", \"Korean\"): using locale code page other than\n65001 (\"UTF-8\") may cause problems\n\n\n[1] \"LC_COLLATE=Korean_Korea.949;LC_CTYPE=Korean_Korea.949;LC_MONETARY=Korean_Korea.949;LC_NUMERIC=C;LC_TIME=Korean_Korea.949\"\n\n\nchampion_list는 44개 원소로 이루어진 리스트이며, 각 원소에는 웹페이지의 테이블 정보가 들어가 있습니다. 이 중 원하는 표만 선택하면 됩니다.\n\nchampion_list[[1]]\n\n# A tibble: 9 x 4\n  Division          Champion                 Since        Defenses\n  <chr>             <chr>                    <chr>        <chr>   \n1 Heavyweight       Vacant                   Jan 14, 2023 <U+2014>       \n2 Light Heavyweight Vacant                   Nov 23, 2022 <U+2014>       \n3 Middleweight      Alex Pereira             Nov 12, 2022 0       \n4 Welterweight      Leon Edwards             Aug 20, 2022 0       \n5 Lightweight       Islam Makhachev          Oct 22, 2022 0       \n6 Featherweight     Alexander Volkanovski    Dec 14, 2019 4       \n7 Bantamweight      Aljamain Sterling        Mar 6, 2021  2       \n8 Flyweight         Deiveson Figueiredo      Jan 22, 2022 0       \n9 Flyweight         Brandon Moreno (interim) Jul 30, 2022 0"
  },
  {
    "objectID": "crawl.html#post-방식-크롤링",
    "href": "crawl.html#post-방식-크롤링",
    "title": "6  크롤링 기초",
    "section": "8.4 POST 방식 크롤링",
    "text": "8.4 POST 방식 크롤링\nGET 방식은 요청 쿼리가 url에 포함되어 있으므로 매우 손쉽게 페이지 내역을 받을 수 있었습니다. 그러나 POST 방식은 요청 쿼리가 숨겨져 있으므로 이를 직접 입력해야 합니다. 앞서 살펴본 로또 당첨번호를 크롤링 해보도록 하겠습니다.\nhttps://www.dhlottery.co.kr/gameResult.do?method=byWin\n개발자도구 화면을 연 상태에서 조회를 누른 후 [gameResult.do?…] 부분을 클릭합니다. [Headers] 탭의 General 에서 Request URL은 데이터를 요청하는 서버 주소를 의미합니다.\n\n\n\n\n\nPayload 탭의 [Form Data] 에는 요청하는 쿼리가 나타나 있습니다.\n\n\n\n\n\n또한 당첨번호에 해당하는 부분의 html 위치를 확인해보면, num win 클래스에 위치하고 있음을 알 수 있습니다.\n\n\n\n\n\n위의 정보를 이용해 POST 형태로 데이터를 받아보도록 하겠습니다.\n\nlibrary(httr)\nlibrary(rvest)\n\nurl = 'https://www.dhlottery.co.kr/gameResult.do?method=byWin'\n\ndata_lotto = POST(\n  url, \n  body = list(\n    drwNo = \"1009\",\n    dwrNoList = \"1009\"\n  )\n)\n\ndata_lotto_html = data_lotto %>% read_html() \n\n\nurl에는 서버 주소를 입력하며, 쿼리값은 body 내에 리스트 형태로 입력한다. 요청한 쿼리, 즉 1009회 당첨결과에 해당하는 데이터가 받아집니다. 만일 다른 회차의 값이 궁금하면 1009 숫자를 다른 숫자로 입력하면 됩니다.\nread_html() 함수를 통해 html 내용을 추출합니다.\n\n이제 당첨번호에 해당하는 데이터만을 뽑아내도록 합니다.\n\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text()\n\n결과를 확인해보면 당첨번호와 함께 , 같은 문자들이 보입니다. 이는 띄어쓰기, 줄바꿈 등에 해당하는 태그입니다. 우리에게 남은 일은 숫자에 해당하는 부분만 뽑아내는 것이며, 클렌징 방법은 매우 많습니다.\n\nlibrary(stringr)\n\n# 1\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text() %>%\n  str_extract_all('(\\\\d)+') %>%\n  unlist()\n\n# 2\ndata_lotto_html %>%\n  html_nodes('.num.win') %>%\n  html_text() %>%\n  str_replace_all(\"[\\r\\n\\t]\", \" \") %>%\n  str_split(\" \") %>%\n  unlist() %>%\n  unique() %>%\n  .[3:8]"
  },
  {
    "objectID": "crawl.html#셀레니움-실습하기",
    "href": "crawl.html#셀레니움-실습하기",
    "title": "6  크롤링 기초",
    "section": "9.1 셀레니움 실습하기",
    "text": "9.1 셀레니움 실습하기\n셀레니움의 경우 R에서 세팅하기는 지나치게 번거로우므로, 파이썬에서 하는 것을 권장합니다.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nimport time\nfrom bs4 import BeautifulSoup\n\n\n\n\n\n\nwebdriver.Chrome(service=Service(ChromeDriverManager().install())) 코드를 실행하면 크롬 브라우저의 버전을 탐색한 다음, 버전에 맞는 웹드라이버를 다운로드하여 해당 경로를 셀레니움에 전달해준다. 또한 크롬 창이 열리며, 좌측 상단에 'Chrome이 자동화된 테스트 소프트웨어에 의해 제어되고 있습니다.'라는 문구가 뜬다. 이제 파이썬 코드를 이용해 해당 페이지를 조작할 수 있다.\n\nurl = 'https://www.naver.com/'\ndriver.get(url)\ndriver.page_source[1:1000]\n\n\n\n\n\n\ndriver.get() 내에 URL 주소를 입력하면 해당 주소로 이동한다. 또한 driver.page_source를 통해 열려있는 창의 HTML 코드를 확인할 수도 있다. 이제 네이버 메인에서 [뉴스]버튼을 누르는 동작을 실행해보자. 개발자도구 화면을 통해 확인해보면 [뉴스] 탭은 아래 HTML에 위치하고 있다.\n\n<a href=\"https://news.naver.com/\" class=\"nav\" data-clk=\"svc.news\">뉴스</a>\n\n\n\n\n\n\n\ndriver.find_element(By.LINK_TEXT , value = '뉴스').click()\n\n\n\n\n\n\n브라우저 상에서 보이는 버튼, 검색창, 사진, 테이블, 동영상 등을 엘레먼트(element, 요소)라고 한다. find_element()는 다양한 방법으로 엘레먼트에 접근하게 해주며, By.* 를 통해 어떠한 방법으로 엘레먼트에 접근할지 선언한다. LINK_TEXT의 경우 링크가 달려 있는 텍스트로 접근하며, value = '뉴스', 즉 뉴스라는 단어가 있는 엘레먼트로 접근한다. click() 함수는 마우스 클릭을 실행하며 결과 적으로 뉴스 탭을 클릭한 후 페이지가 이동되는 것을 확인할 수 있다. find_element() 내 접근방법 및 셀레니움의 각종 동작 제어 방법에 대해서는 나중에 다시 정리하도록 한다.\n이제 뒤로가기를 실행해보도록 하자.\n\ndriver.back()\n\nback()은 뒤로가기를 의미하며, 기존 페이지인 네이버 메인으로 이동한다.\n이제 특정 검색어를 검색하는 방법에 대해 알아보자. 먼저 검색창의 위치가 어디에 있는지 확인해보면 query라는 id와 input_text라는 class에 위치하고 있다.\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'input_text').send_keys('퀀트 투자 포트폴리오 만들기')\n\n\n\n\n\n\nfind_element() 내에 By.CLASS_NAME을 입력하면 클래스 명에 해당하는 엘레먼트에 접근하며, 여기서는 검색창에 접근한다. 그 후 send_keys() 내에 텍스트를 입력하면 해당 내용이 웹페이지에 입력된다. 이제 웹페이지에서 검색 버튼 해당하는 돋보기 모양을 클릭하거나 엔터키를 누르면 검색이 실행된다. 먼저 돋보기 모양의 위치를 확인해보면 search_btn id와 btn_submit 클래스에 위치하고 있다.\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'btn_submit').send_keys(Keys.ENTER)\n\n\n\n\n\n\nfind_element(By.CLASS_NAME, value = 'btn_submit')를 통해 검색 버튼에 접근한다. 그 후 send_keys(Keys.ENTER)를 입력하면 엔터키를 누르는 동작이 실행된다. 페이지를 확인해보면 검색이 실행된 후 결과를 확인할 수 있다.\n이번에는 다른 단어를 검색해보도록 하자. 웹에서 기존 검색어 내용을 지운 후, 검색어를 입력하고, 버튼을 클릭해야 한다. 이를 위해 검색어 박스와 검색 버튼의 위치를 찾아보면 다음과 같다.\n\n검색어 박스: box_window 클래스\n검색 버튼: bt_search 클래스\n\n\n\n\n\n\n\ndriver.find_element(By.CLASS_NAME, value = 'box_window').clear()\ndriver.find_element(By.CLASS_NAME, value = 'box_window').send_keys('이현열 퀀트')\ndriver.find_element(By.CLASS_NAME, value = 'bt_search').click()\n\n\n검색어 박스(box_window)에 접근한 후, clear()를 실행하면 모든 텍스트가 지워진다.\nsend_keys('이현열 퀀트')를 실행하여 새로운 검색어를 입력한다.\n검색 버튼(bt_search)에 접근한 후, click()을 실행하여 해당 버튼을 클릭한다.\n\n이번에는 [VIEW] 버튼을 클릭하는 동작을 실행해보도록 한다. 기존처럼 링크나 클래스명을 통해 엘레먼트에 접근할 수도 있지만, 이번에는 XPATH를 이용해 접근해보도록 하자. XPATH란 XML 중 특정 값의 태그나 속성을 찾기 쉽게 만든 주소다. 예를 들어 윈도우 탐색기에서는 특정 폴더의 위치가 'C:\\Program Files'과 같이 주소처럼 보이며 이는 윈도우의 PATH 문법이다. XML 역시 이와 동일한 개념의 XPATH가 있다. 웹페이지에서 XPATH를 찾는 법은 다음과 같다.\n\n개발자도구 화면에서 위치를 찾고 싶은 부분에서 마우스 우클릭을 한다.\n[Copy → Copy Xpath]를 선택한다.\n\n\n\n\n\n\n위 과정을 통해 XPATH가 복사된다. 메모장을 확인해보면 VEW 부분의 XPATH는 다음과 같다.\n//*[@id=\"lnb\"]/div[1]/div/ul/li[2]/a\n이를 이용해 해당 부분을 클릭하는 동작을 실행해보자.\n\ndriver.find_element(By.XPATH, value = '//*[@id=\"lnb\"]/div[1]/div/ul/li[2]/a').click()\n\n\n\n\n\n\n탭이 [통합] 검색이 아닌 [VIEW]로 변경되었다. 이번에는 [옵션]을 클릭한 후 정렬을 [최신순]으로 하는 동작을 실행해보자. 둘의 위치는 다음과 같다.\n\n옵션 버튼: option_filter (클래스)\n최신순 버튼: //*[@id=\"snb\"]/div[2]/ul/li[2]/div/div/a[2] (Xpath)\n\n\n\n\n\n\n코드 실행에 앞서 옵션 창이 열려있다면 [X] 버튼을 눌러 닫아주도록 한다.\n\n\n\n\n\n옵션 창을 닫은 후 아래의 코드를 실행하도록 한다.\n\ndriver.find_element(By.CLASS_NAME, value = 'option_filter').click()\ndriver.find_element(By.XPATH, value = '//*[@id=\"snb\"]/div[2]/ul/li[2]/div/div/a[2]').click()\n\n\n\n\n\n\n옵션 클릭 후 최신순 버튼을 클릭하는 동작을 수행하여 검색어가 최신순으로 정렬되었다. 이제 page down 기능을 수행해보도록 하자.\n\ndriver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n# driver.find_element(By.TAG_NAME, value = 'body').send_keys(Keys.PAGE_DOWN)\n\n먼저 document.body.scrollHeight는 웹페이지의 높이를 나타내는 것으로써, window.scrollTo(0, document.body.scrollHeight);는 웹페이지의 가장 하단까지 스크롤을 내리라는 자바스크립트 명령어다. driver.execute_script()를 통해 해당 명령어를 실행하면 웹페이지가 아래로 스크롤이 이동된다. send_keys(Keys.PAGE_DOWN) 는 키보드의 페이지다운(PgDn) 버튼을 누르는 동작이며 이 역시 페이지가 아래로 이동시킨다.\n그러나 결과를 살펴보면 스크롤이 끝까지 내려간 후 얼마간의 로딩이 있은 후에 새로운 데이터가 생성된다. 이처럼 유튜브나 인스타그램, 페이스북 등 많은 검색결과를 보여줘야 하는 경우 웹페이지 상에서 한 번에 모든 데이터를 보여주기 보다는 스크롤을 가장 아래로 위치하면 로딩을 거쳐 추가적인 결과를 보여준다. 따라서 스크롤을 한 번만 내리는 것이 아닌 모든 결과가 나올 때까지 내리는 동작을 실행해야 한다.\n\nprev_height = driver.execute_script('return document.body.scrollHeight')\n\nwhile True:\n    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n    time.sleep(2)\n    \n    curr_height = driver.execute_script('return document.body.scrollHeight')\n    if curr_height == prev_height:\n        break\n    prev_height = curr_height\n\n\nreturn document.body.scrollHeight은 현재의 창 높이는 반환하는 자바스크립트 명령어이며, 이를 prev_height에 저장한다.\nwhile문을 통해 반복문을 실행한다.\n셀레니움을 통해 페이지의 최하단으로 스크롤을 내린다.\n페이지가 로딩되는 시간을 기다리기 위해 2초간 슬립을 준다.\ncurr_height에 현재 창 높이를 저장한다.\ncurr_height와 prev_height가 동일하다는 의미는 페이지가 끝까지 내려왔다는 의미이다. 따라서 이 경우 break를 통해 while문을 멈추며, 그렇지 않을 경우 다시 스크롤을 내리는 동작을 반복한다.\nprev_height에 새로운 창 높이를 입력한다.\n\n이제 모든 검색 결과가 나타났으면 이전 장에서 살펴보았던 정적 크롤링을 통해 데이터 수집이 가능하다. 제목 부분을 확인해보면 api_txt_lines total_tit _cross_trigger 클래스에 위치하고 있으며, 이를 통해 모든 제목을 크롤링해보자.\n\nhtml = BeautifulSoup(driver.page_source, 'lxml')\ntxt = html.find_all(class_ = 'api_txt_lines total_tit _cross_trigger')\ntxt_list = [i.get_text() for i in txt]\n\ntxt_list[0:10]\n\n\ndriver.page_source를 통해 현재 웹페이지의 HTML 정보를 가져올 수 있으며, 이를 BeautifulSoup 객체로 만들어준다.\nfind_all() 함수를 통해 제목 부분에 위치하는 데이터를 모두 불러온다.\nfor문을 통해 텍스트만 추출한다.\n\n이처럼 동적 페이지의 경우도 셀레니움을 통해 웹페이지를 제어한 후 BeautifulSoup 패키지를 사용해 원하는 부분을 추출하면 얼마든지 크롤링이 가능하다.\n\ndriver.quit()"
  },
  {
    "objectID": "portfolio.html#팩터-이해하기",
    "href": "portfolio.html#팩터-이해하기",
    "title": "7  포트폴리오 구성하기",
    "section": "7.1 팩터 이해하기",
    "text": "7.1 팩터 이해하기\n하나 혹은 소수의 주식만을 연구해서 주식이 오르거나 내리는 공통적인 이유를 찾는 것은 불가능에 가깝지만, 그룹으로 살펴보면 어느 정도 파악이 가능합니다. 어떠한 특성, 예를 들어 기업의 크기 별로 주식들을 묶은 후 수익률을 살펴보면, 크기가 큰 기업의 수익률이 좋았는지 아니면 작은 기업의 수익률이 좋았는지 알 수 있습니다. 즉, 오르는 주식과 내리는 주식은 애초에 가지고 있는 특성이 다르며 그로 인해 수익률에도 차이가 있습니다. 이처럼 주식의 수익률에 영향을 미치는 특성들을 ’팩터(Factor)’라고 하며, 주식의 수익률은 이러한 팩터들로 대부분 설명됩니다. 주식이 가지고 있는 특성만 제대로 알아도 오를만한 주식을 선별하거나, 혹은 내릴만한 주식을 걸러낼 수 있습니다.\n그러나 단순히 특성을 기준으로 수익률이 높거나 낮다고 해서 팩터로 인정되는 것은 아닙니다. 팩터로 인정되고 전략으로 사용되기 위해서는 아래의 조건을 충족해야 합니다.\n\n지속성: 오랜 기간, 그리고 여러 경제 상황에서도 꾸준히 작동해야 합니다. 몇 달 혹은 몇 년 동안의 기간에서만 작동한다면 우연의 결과일 가능성이 매우 큽니다.\n범용성: 특정 국가에서만 작동하는 것이 아닌 다양한 국가, 지역, 섹터, 자산군에서도 작동해야 합니다. 전세계 중 한국에서만 작동하는 전략이라면 이 역시 우연일 가능성이 큽니다.\n이해 가능성: 전략이 작동하는 이유 및 지속 가능한지에 대한 설명이 가능해야 합니다. 수익률이 높은 이유를 경제학이나 이론적으로 설명할 수 있어야 앞으로도 수익률이 높을 것이라 믿을 수 있습니다. 이유가 없는 효과는 우연 혹은 과최적화의 결과일 가능성이 매우 높습니다.\n강건성: 같은 팩터라면 비슷한 정의(예: 가치주를 정의하는 PBR, PER, PSR 등) 모두에서 작동해야 합니다. 전략이 작동하는 이유가 명확하다면 정의가 약간씩 달라도 당연히 작동해야 하며, 결과 역시 비슷해야 합니다.\n투자 가능성: 이론적으로만 작동하는 것이 아닌 실제로 투자가 가능해야 합니다. 아무리 좋은 전략도 수수료, 세금, 법률적인 문제 등으로 실제 투자가 불가능하다면 돈을 벌 수 없기 때문입니다.\n\n퀀트 운용 전략에서는 팩터의 강도가 양인 종목들로 구성한 포트폴리오는 향후 수익률이 높을 것으로 예상되어 매수를 하며, 팩터의 강도가 음인 종목들로 구성한 포트폴리오는 반대로 향후 수익률이 낮을 것으로 예상되어 매수를 하지 않거나 공매도를 합니다. 기본적인 팩터들에 대해 알아보고, 우리가 구한 데이터를 바탕으로 각 팩터별 투자 종목을 선택하는 방법을 알아보겠습니다."
  },
  {
    "objectID": "portfolio.html#데이터-불러오기",
    "href": "portfolio.html#데이터-불러오기",
    "title": "7  포트폴리오 구성하기",
    "section": "7.2 데이터 불러오기",
    "text": "7.2 데이터 불러오기\n먼저 샘플로 사용할 주가 및 재무제표 데이터를 다운로드 받습니다. 데이터는 아래 링크에 .sql 파일로 업로드 되어 있습니다.\nhttps://drive.google.com/file/d/13KLFlZTGJvyrlXQYQ_mR0RgAbfYtufti/view?usp=share_link\n[다운로드] 버튼을 눌러 파일을 다운로드 합니다. 그 후 SQL에서 해당 데이터베이스를 불러옵니다.\n\n\n\n\n\n\nNavigator에서 Administration 부분을 클릭한 후 Data Import를 선택합니다.\nImport from Self-Contained File를 선택한 후 […]을 눌러 다운로드 받은 파일을 선택합니다.\nDefault Target Schema 우측의 New를 누른 후 저장될 데이터베이스 이름을 입력합니다.\n하단의 Start Import를 클릭합니다.\n\n\n\n\n\n\n데이터베이스를 확인해보면 티커, 주가, 재무제표 데이터가 들어와 있습니다."
  },
  {
    "objectID": "portfolio.html#밸류-전략",
    "href": "portfolio.html#밸류-전략",
    "title": "7  포트폴리오 구성하기",
    "section": "7.3 밸류 전략",
    "text": "7.3 밸류 전략\n가치주 효과란 내재 가치 대비 낮은 가격의 주식(저PER, 저PBR 등)이, 내재 가치 대비 비싼 주식(고PER, 고PBR)보다 수익률이 높은 현상을 뜻합니다. 가치주 효과가 발생하는 원인은 바로 사람들이 가치주(저밸류에이션)를 기피하고, 성장주(고밸류에이션)를 선호하기 때문입니다. 달리 말하면 사람들이 기피한 주식이 가치주가 되었다고 할 수도 있습니다. 가치주는 일반적으로 차입비율이 높고, 수익의 변동성이 크며, 경기가 좋지 않을 때 더 위험한 경향이 있습니다. 사람들은 이처럼 위험한 주식에 필요 이상으로 과민 반응을 보입니다. 그로 인해 주가가 하락하고 가치주가 되는 것입니다. 반면 인간은 익숙한 것을 안전하다고 착각하는 경향이 있습니다. 최근 성과가 좋은 주식은 여러 매체를 통해 접하기 쉬운데, 이런 주식을 안전하다고 착각해 많은 사람이 매수에 나섭니다. 그로 인해 주가가 상승하고 고평가주가 됩니다. 보고 싶은 것만 보는 확증 편향으로 인해 투자자들은 위험하다고 생각되는 가치주가 망할 것 같은 이유만 찾아 더욱 기피하고, 안전하다고 생각되는 성장주는 영원히 상승할 것 같은 이유만 찾아 더욱 선호합니다. 그러나 가치주가 생각보다 위험하지 않다는 것을, 성장주가 너무 많이 상승해 안전하지 않다는 것을 깨닫는 순간 주가는 원래 수준으로 회귀하기 마련이고, 이로 인해 가치주 효과가 발생합니다.\n\n7.3.1 French Library 데이터 불러오기\n파마-프렌치 모형으로 유명한 프렌치 교수가 제공하는 라이브러리에서는 다양한 팩터 데이터를 다운로드 받을 수 있습니다.\nhttps://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n해당 데이터를 분석하기 위해 사이트에 접속하여 데이터를 내려받아 압축을 푼 후 csv 파일을 불러오는 방법 보다는, R 내에서 데이터를 다운로드 받은 후 불러오는 것이 훨씬 효율적입니다. 또한 이미 개발된 패키지를 사용할 경우 이러한 작업을 매우 쉽게 할수도 있습니다.\nhttps://nareal.github.io/frenchdata/articles/basic_usage.html\nR에서 해당 패키지를 사용해 팩터 데이터를 다운로드 받은 후 성과를 확인해보도록 하겠습니다.\n\nlibrary(frenchdata)\ndata_sets = get_french_data_list()\n\ndata_sets$files_list\n\n# A tibble: 297 × 3\n   name                                                file_url          detai…¹\n   <chr>                                               <chr>             <chr>  \n 1 Fama/French 3 Factors                               ftp/F-F_Research… Data_L…\n 2 Fama/French 3 Factors [Weekly]                      ftp/F-F_Research… Data_L…\n 3 Fama/French 3 Factors [Daily]                       ftp/F-F_Research… Data_L…\n 4 Fama/French 5 Factors (2x3)                         ftp/F-F_Research… Data_L…\n 5 Fama/French 5 Factors (2x3) [Daily]                 ftp/F-F_Research… Data_L…\n 6 Portfolios Formed on Size                           ftp/Portfolios_F… Data_L…\n 7 Portfolios Formed on Size [ex.Dividends]            ftp/Portfolios_F… Data_L…\n 8 Portfolios Formed on Size [Daily]                   ftp/Portfolios_F… Data_L…\n 9 Portfolios Formed on Book-to-Market                 ftp/Portfolios_F… Data_L…\n10 Portfolios Formed on Book-to-Market [ex. Dividends] ftp/Portfolios_F… Data_L…\n# … with 287 more rows, and abbreviated variable name ¹​details_url\n\n\n먼저 필요한 패키지들을 불러온 후, get_french_data_list() 함수를 사용해 다운로드 받을 수 있는 데이터를 조회합니다. data_sets의 files_list에는 다운로드 받을 수 있는데 데이터와 해당 url이 표시되어 있습니다. 이 중 우리는 name 컬럼의 데이터 이름을 알면 됩니다. 이 중 밸류에 해당하는 데이터의 이름은 [Portfolios Formed on Book-to-Market] 입니다. B/M에서 B는 장부가치(Book Value), M는 시장가치(Market Value)로써, 이는 PBR의 역수라고 생각해도 됩니다. 즉 해당값이 높을수록 저PBR 주식을 의미합니다. 해당 데이터를 다운로드 받도록 하겠습니다.\n\nff_value = download_french_data('Portfolios Formed on Book-to-Market')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_value$subsets\n\n# A tibble: 8 × 2\n  name                                                    data                \n  <chr>                                                   <list>              \n1 Value Weight Returns -- Monthly                         <spc_tbl_>          \n2 Equal Weight Returns -- Monthly                         <spc_tbl_>          \n3 Value Weight Returns -- Annual from January to December <spc_tbl_ [95 × 20]>\n4 Equal Weight Returns -- Annual from January to December <spc_tbl_ [95 × 20]>\n5 Number of Firms in Portfolios                           <spc_tbl_>          \n6 Average Firm Size                                       <spc_tbl_>          \n7 Sum of BE / Sum of ME                                   <spc_tbl_ [97 × 20]>\n8 Value Weight Average of BE / ME                         <spc_tbl_ [97 × 20]>\n\n\n리스트 중 subsets를 확인해보면 월간수익률(시가총액가중평균, 동일가중평균), 연간수익률(시가총액가중평균, 동일가중평균) 및 기타 데이터가 포함되어 있습니다. 이 중 일반적으로 많이 사용하는 시가총액가중포트폴리오의 월간 수익률 (Value Weighted Returns – Monthly)를 확인해보겠습니다.\n\nff_value_vw = ff_value$subsets$data[[1]]\nhead(ff_value_vw)\n\n# A tibble: 6 × 20\n    date `<= 0` `Lo 30` `Med 40` `Hi 30` `Lo 20` `Qnt 2` `Qnt 3` `Qnt 4` `Hi 20`\n   <dbl>  <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 192607  12.1     5.55     1.86    1.54    3.18    5.41    1.78    2.41    0.6 \n2 192608  -9.73    2.65     2.67    5.61    1       4.01    2.05    4.59    7.1 \n3 192609 -15.2     1.28     0.07   -0.71   -1.04    3.04   -0.29   -0.19   -1.46\n4 192610  -5.63   -3.6     -2.41   -3.55   -2.89   -2.96   -2.2    -4.2    -4.28\n5 192611   5.58    3.13     2.95    2.94    4.12    2.56    1.9     3.96    2.48\n6 192612  -6.13    2.96     2.59    2.52    1.68    3.33    1.82    5.2     2.06\n# … with 10 more variables: `Lo 10` <dbl>, `Dec 2` <dbl>, `Dec 3` <dbl>,\n#   `Dec 4` <dbl>, `Dec 5` <dbl>, `Dec 6` <dbl>, `Dec 7` <dbl>, `Dec 8` <dbl>,\n#   `Dec 9` <dbl>, `Hi 10` <dbl>\n\n\n\n<=0: PBR이 0 이하인 기업들의 포트폴리오\nLo 30, Med 40, Hi 30: PBR 기준 상위 30%, 30-70%, 하위 30%로 나눈 포트폴리오\nLo 20, Qnt 2, Qnt 3, Qnt 4, Hi 20: PBR 기준 상위 20%, 20-40%, 40-60%, 60-80%, 80-100%로 나눈 포트폴리오\nLo 10, Dec 2, Dec 3, …, Dec 9, Hi 19: PBR 기준 상위 10% 씩으로 나눈 포트폴리오\n\n이 중 20%씩 나눈 [Lo 20, Qnt 2, Qnt 3, Qnt 4, Hi 20] 열만 선택하여 누적 수익률을 확인보도록 하겠습니다.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\nLoading required package: timechange\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(zoo)\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\ndata_to_plot = function(data) {\n  \n  data %>%\n    mutate(date = as.character(date)) %>%\n    mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n    mutate(across(!date, ~.x / 100)) %>%\n    mutate(across(!date, ~log(1+.x))) %>%\n    mutate(across(!date, ~cumsum(.x))) %>%\n    pivot_longer(-date) %>%\n    mutate(name = factor(name, levels = .$name %>% unique)) %>%\n    ggplot(aes(x = date, y = value, color = name)) +\n    geom_line() +\n    xlab('') +\n    ylab('') +\n    theme_bw() +\n    theme(legend.title=element_blank())\n  \n}\n\n먼저 데이터를 클렌징한 후 그림으로 나타내는 함수를 만듭니다.\n\ndate열을 yyyy-mm-dd로 변경\n해당 데이터에서는 1이 1%를 의미하므로, 올바른 계산을 위해 100으로 나누어 줌\n로그수익률로 치환\ncumsum() 함수를 통해 누적합 계산\npivot_longer() 함수를 통해 형태 변경\nname 열의 순서 지정을 위해 팩터 levels 재설정\n그림으로 나타내기\n\n이제 PBR 기준 5분위 열만 선택한 후 해당 함수를 적용합니다.\n\nff_value_vw %>% select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\nHi 20, 즉 B/M이 높은(PBR이 낮은) 포트폴리오의 누적 수익률이 가장 높으며, B/M이 낮을수록(PBR이 높을수록) 누적 수익률이 낮아집니다.\n\nff_value_vw %>% select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  pivot_longer(-date) %>%\n  mutate(name = factor(name, levels = .$name %>% unique)) %>%\n  ggplot(aes(x = name, y = value)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n박스 플랏을 분석해 보면 PBR이 낮을수록 수익률의 변동성은 크지만, 큰 수익이 나는 경우가 더 많습니다.\n이번에는 고PBR 대비 저PBR 수익률인 HML 팩터의 수익률을 살펴보겠습니다. 흔히 롱숏 모델을 비교할때는 상하위 30% 수익률을 이용합니다.\n\nff_value_vw %>% select(date, `Lo 30`, `Hi 30`) %>%\n  mutate(HML = `Hi 30` - `Lo 30`) %>%\n  select(date, HML) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n1940년 이후 꾸준히 상향하며 저PBR이 고PBR 대비 뛰어난 성과를 기록하였습니다. 반면 2008년 이후 10여년 동안 하락하다가, 2020년을 기점으로 다시 반등하는 모습입니다.\nFrench 라이브러리에서는 PBR외에도 PER나 PCR 팩터의 수익률도 확인할 수 있으며, 미국이 아닌 글로벌 수익률도 확인할 수 있습니다.\n\n\n7.3.2 밸류 포트폴리오 구하기\n가치주에 투자하는 것이 훨씬 수익률이 높다는 점을 확인하였으니, 국내 종목들 중 가치주에는 어떠한 것이 있는 확인해보도록 합니다. 먼저 전통적인 가치지표인 PER와 PBR이 낮은 종목을 선정해보도록 합니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\n\n먼저 DB에서 티커 테이블과 가치지표 테이블을 불러옵니다. 티커는 최신일 기준 및 보통주에 해당하는 종목만 불러오며, 가치지표는 최신일 기준 데이터를 불러옵니다.\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일)\n\nvalue_bind = ticker %>% \n  left_join(value)\n\nJoining, by = \"종목코드\"\n\nvalue_bind %>% head()\n\n  종목코드     종목명 시장구분  종가    시가총액     기준일   EPS 선행EPS\n1   000020   동화약품    KOSPI  8650 2.41607e+11 2022-10-14   647      NA\n2   000040   KR모터스    KOSPI   599 5.75869e+10 2022-10-14    NA      NA\n3   000050       경방    KOSPI 10800 2.96085e+11 2022-10-14   872      NA\n4   000060 메리츠화재    KOSPI 29600 3.36798e+12 2022-10-14  5768    6808\n5   000070 삼양홀딩스    KOSPI 63800 5.46401e+11 2022-10-14 30711      NA\n6   000080 하이트진로    KOSPI 24650 1.72879e+12 2022-10-14  1031    1984\n     BPS 주당배당금 종목구분     DY    PBR    PCR     PER    PSR\n1  12534        180   보통주 0.0208 0.6718 5.7117 12.5185 0.7600\n2    385          0   보통주     NA 1.1705     NA      NA 0.4359\n3  30033        125   보통주 0.0116 0.3900 4.7602 15.1838 0.7365\n4  22086        620   보통주 0.0209 1.8143 2.7349  4.1457     NA\n5 226314       3000   보통주 0.0470 0.2223 3.3317  2.8518 0.1653\n6  15657        800   보통주 0.0325 1.5829 4.2258 18.0647 0.7408\n\n\n\n일부 종목은 가치지표가 0보다 작은 경우(예: 적자기업의 경우 PER가 음수, 혹은 배당수익률이 0%인 종목)가 있으며 이러한 데이터는 NA로 변경합니다.\n테이블을 가로로 긴 형태로 변경합니다.\n두 테이블을 합칩니다.\n\n이제 PER와 PBR이 낮은 종목을 찾아보도록 합니다.\n\nvalue_bind %>%\n  mutate(across(c(PBR, PER), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank = min_rank(rank_PBR + rank_PER)) %>%\n  filter(rank <= 20) \n\n   종목코드           종목명 시장구분   종가    시가총액     기준일   EPS\n1    000880             한화    KOSPI  24000 1.79901e+12 2022-10-14  9781\n2    001390         KG케미칼    KOSPI  21450 2.97428e+11 2022-10-14  5749\n3    001940      KISCO홀딩스    KOSPI  12150 1.96543e+11 2022-10-14  8106\n4    002030           아세아    KOSPI 110500 2.42108e+11 2022-10-14 56785\n5    003380         하림지주   KOSDAQ   6630 7.42597e+11 2022-10-14  4129\n6    006200   한국전자홀딩스    KOSPI   1155 5.40576e+10 2022-10-14   531\n7    007860             서연    KOSPI   5270 1.23739e+11 2022-10-14  1091\n8    008060             대덕    KOSPI   5990 2.03002e+11 2022-10-14    NA\n9    009970   영원무역홀딩스    KOSPI  51200 6.98142e+11 2022-10-14 19026\n10   023590         다우기술    KOSPI  17150 7.69463e+11 2022-10-14  8693\n11   032190       다우데이타   KOSDAQ  13850 5.30455e+11 2022-10-14  3838\n12   037400 우리엔터프라이즈   KOSDAQ   2220 5.82158e+10 2022-10-14   899\n13   052300     초록뱀컴퍼니   KOSDAQ    570 6.55956e+10 2022-10-14   942\n14   088350         한화생명    KOSPI   2020 1.75443e+12 2022-10-14  1455\n15   090740       연이비앤티   KOSDAQ     75 1.68446e+09 2022-10-14  1328\n16   101360         이엔드디   KOSDAQ  26000 2.75825e+11 2022-10-14   992\n17   106240     파인테크닉스   KOSDAQ   2190 3.48715e+10 2022-10-14   983\n18   139480           이마트    KOSPI  84900 2.36666e+12 2022-10-14 56152\n19   151860           KG ETS   KOSDAQ   8410 3.02760e+11 2022-10-14  1389\n20   296640         이노룰스   KOSDAQ  19850 1.02064e+11 2022-10-14   813\n   선행EPS    BPS 주당배당금 종목구분     DY    PBR    PCR    PER    PSR\n1     8821  52527        750   보통주 0.0312 0.0943 0.3589 0.9098 0.0323\n2       NA  34343        500   보통주 0.0233 0.1539 1.1798 0.5282 0.0531\n3       NA  68463        400   보통주 0.0329 0.1393 4.7589 1.2965 0.1053\n4       NA 491013       3000   보통주 0.0271 0.1407 1.2185 1.3473 0.1211\n5       NA  27945        100   보통주 0.0151 0.1684 0.6366 1.0822 0.0572\n6       NA   2900          0   보통주     NA 0.1777 1.2175 1.5314 0.1492\n7       NA  21587        100   보통주 0.0190 0.1320 0.4529 1.9579 0.0451\n8       NA  16976        300   보통주 0.0501 0.1455 0.6002 1.6945 0.1296\n9    22866 140307       2000   보통주 0.0391 0.2158 1.7153 1.0987 0.1846\n10      NA  45679        600   보통주 0.0350 0.1673     NA 1.1148 0.0962\n11      NA  24053        300   보통주 0.0217 0.1085     NA 0.7750 0.0619\n12      NA   4170          0   보통주     NA 0.2277 0.9153 1.0267 0.0375\n13      NA   2655          0   보통주     NA 0.1442 3.9515 1.1137 0.3827\n14     556  15004          0   보통주     NA 0.1488 0.4769 1.5061     NA\n15      NA   2489          0   보통주     NA 0.0363 0.3584 0.0952 0.0148\n16      NA   7068          0   보통주     NA 0.1615 0.1615 0.1615 0.1615\n17      NA   2512         25   보통주 0.0114 0.2265 0.7647 0.6086 0.0716\n18   14456 369202       2000   보통주 0.0236 0.1873 3.6898 1.3550 0.0866\n19      NA   8862        120   보통주 0.0143 0.2211 4.0584 0.6047 0.0734\n20      NA   3492         25   보통주 0.0013 0.2438     NA 0.2438 0.2438\n   rank_PBR rank_PER rank\n1         3       38    5\n2        20       12    3\n3        11       65    7\n4        12       68    9\n5        31       45    7\n6        36       79   17\n7         9      117   20\n8        17       93   15\n9        65       48   16\n10       30       50    9\n11        5       31    4\n12       76       43   19\n13       16       49    6\n14       19       76   14\n15        1        1    1\n16       26        2    2\n17       73       18   12\n18       47       70   18\n19       67       17   11\n20       89        3   13\n\n  # select(종목코드, 종목명, PBR, PER)\n\n\nmin_rank() 함수를 통해 PER와 PBR 열의 순위를 구하며, rank_열 이름으로 저장합니다.\n앞서 구한 두 열을 합한 후 다시 순위를 구합니다.\n순위가 낮은 20종목을 선택합니다. 이는 PER와 PBR이 낮은 종목이라고 볼 수 있습니다.\n\n\n\n7.3.3 여러 지표 결합하기\n이번에는 가치지표에 해당하는 모든 지표, 즉 PER, PBR, PCR, PSR, DY를 고려한 밸류 포트폴리오를 만들어보도록 하겠다. 먼저 각 지표 별 상관관계를 살펴보도록 합니다.\n\nvalue_bind_rank = value_bind %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\nvalue_bind_rank %>%\n  select(contains('rank')) %>%\n  cor(., use = 'complete.obs') %>%\n  round(., 2)\n\n         rank_PBR rank_PER rank_PCR rank_PSR rank_DY\nrank_PBR     1.00     0.49     0.42     0.74    0.41\nrank_PER     0.49     1.00     0.53     0.50    0.33\nrank_PCR     0.42     0.53     1.00     0.46    0.26\nrank_PSR     0.74     0.50     0.46     1.00    0.36\nrank_DY      0.41     0.33     0.26     0.36    1.00\n\n\nPER, PBR, PCR, PSR의 경우 값이 낮을수록 가치주에 해당하지만, DY의 경우 값이 높을수록 배당수익률이 높은 가치주에 해당한다. 따라서 DY는 desc() 함수를 통해 내림차순으로 순위를 매겨줍니다. 비슷한 가치지표임에도 불구하고 서로 간의 상관관계가 꽤 낮은 지표도 있습니다. 따라서 지표를 통합적으로 고려하면 분산효과를 기대할 수도 있습니다.\n\nvalue_bind_rank %>%\n  mutate(rank_sum = rowSums(across(contains('rank')))) %>%\n  mutate(rank_final = min_rank(rank_sum)) %>%\n  filter(rank_final <= 20) \n\n   종목코드           종목명 시장구분   종가    시가총액     기준일   EPS\n1    000140 하이트진로홀딩스    KOSPI  10050 2.33228e+11 2022-10-14  1529\n2    000880             한화    KOSPI  24000 1.79901e+12 2022-10-14  9781\n3    001040               CJ    KOSPI  71200 2.07740e+12 2022-10-14  8197\n4    001390         KG케미칼    KOSPI  21450 2.97428e+11 2022-10-14  5749\n5    002030           아세아    KOSPI 110500 2.42108e+11 2022-10-14 56785\n6    002990         금호건설    KOSPI   7300 2.69761e+11 2022-10-14  4130\n7    003300       한일홀딩스    KOSPI  10250 3.16037e+11 2022-10-14  1462\n8    005990       매일홀딩스   KOSDAQ   7130 9.78115e+10 2022-10-14  3575\n9    007860             서연    KOSPI   5270 1.23739e+11 2022-10-14  1091\n10   008060             대덕    KOSPI   5990 2.03002e+11 2022-10-14    NA\n11   009410         태영건설    KOSPI   4580 1.78158e+11 2022-10-14  1920\n12   009970   영원무역홀딩스    KOSPI  51200 6.98142e+11 2022-10-14 19026\n13   010100       한국프랜지    KOSPI   2220 6.75999e+10 2022-10-14   612\n14   013580         계룡건설    KOSPI  17600 1.57184e+11 2022-10-14 17601\n15   016450 한세예스24홀딩스    KOSPI   4190 1.67600e+11 2022-10-14  1026\n16   034730               SK    KOSPI 206000 1.52748e+13 2022-10-14 37408\n17   036530        SNT홀딩스    KOSPI  13900 2.26624e+11 2022-10-14  5329\n18   078930               GS    KOSPI  45950 4.26946e+12 2022-10-14 15304\n19   092230        KPX홀딩스    KOSPI  52700 2.22639e+11 2022-10-14 11573\n20   267290     경동도시가스    KOSPI  20050 1.18203e+11 2022-10-14  3756\n   선행EPS    BPS 주당배당금 종목구분     DY    PBR    PCR    PER    PSR\n1       NA  23538        450   보통주 0.0448 0.2128 0.5890 2.6030 0.1004\n2     8821  52527        750   보통주 0.0312 0.0943 0.3589 0.9098 0.0323\n3    12727 151085       2300   보통주 0.0323 0.1244 0.7088 2.4128 0.0553\n4       NA  34343        500   보통주 0.0233 0.1539 1.1798 0.5282 0.0531\n5       NA 491013       3000   보통주 0.0271 0.1407 1.2185 1.3473 0.1211\n6     2203  18202        800   보통주 0.1096 0.4132 2.0671 2.8100 0.1295\n7       NA  44782        550   보통주 0.0537 0.1627 3.6368 2.9509 0.1634\n8       NA  26268        150   보통주 0.0210 0.1473 0.8296 2.3741 0.0521\n9       NA  21587        100   보통주 0.0190 0.1320 0.4529 1.9579 0.0451\n10      NA  16976        300   보통주 0.0501 0.1455 0.6002 1.6945 0.1296\n11      NA  17753        350   보통주 0.0764 0.2518 0.6446 4.2419 0.0627\n12   22866 140307       2000   보통주 0.0391 0.2158 1.7153 1.0987 0.1846\n13      NA   8412         90   보통주 0.0405 0.2529 1.8270 3.1296 0.0589\n14   14985  78914        800   보통주 0.0455 0.2109 2.6687 1.3527 0.0564\n15      NA  12066        250   보통주 0.0597 0.1796 4.0581 2.9611 0.0522\n16   34166 375047       8000   보통주 0.0388 0.2290 1.7970 1.7034 0.1304\n17      NA  65710        700   보통주 0.0504 0.1274 2.6537 2.1604 0.1669\n18   19446 108672       2000   보통주 0.0435 0.2967 2.3272 1.7018 0.1657\n19      NA 208904       3000   보통주 0.0569 0.1607 3.7481 2.9179 0.1744\n20      NA  63687        875   보통주 0.0436 0.3095 1.0442 3.9533 0.0632\n   rank_PBR rank_PER rank_PCR rank_PSR rank_DY rank_sum rank_final\n1        60      170       20       83     179      512          3\n2         3       38        7        4     364      416          2\n3         7      144       31       21     348      551          6\n4        20       12       69       20     510      631          7\n5        12       68       74      117     423      694         12\n6       316      195      136      126      12      785         18\n7        28      216      283      184     115      826         19\n8        18      140       45       17     556      776         15\n9         9      117       12       10     611      759         14\n10       17       93       21      127     131      389          1\n11       99      347       25       33      44      548          5\n12       65       48      112      218     247      690         11\n13      100      240      120       28     231      719         13\n14       58       69      197       22     169      515          4\n15       39      217      320       18      78      672          9\n16       77       95      117      129     254      672          9\n17        8      125      196      191     130      650          8\n18      146       94      155      190     198      783         17\n19       25      213      291      205      92      826         19\n20      161      326       58       34     197      776         15"
  },
  {
    "objectID": "portfolio.html#모멘텀-전략",
    "href": "portfolio.html#모멘텀-전략",
    "title": "7  포트폴리오 구성하기",
    "section": "7.4 모멘텀 전략",
    "text": "7.4 모멘텀 전략\n투자에서 모멘텀이란 주가 혹은 이익의 추세로서, 상승 추세의 주식은 지속적으로 상승하며 하락 추세의 주식은 지속적으로 하락하는 현상을 말합니다. 모멘텀의 종류는 크게 기업의 이익에 대한 추세를 나타내는 이익 모멘텀과 주가의 모멘텀에 대한 가격 모멘텀이 있으며, 이 중에서 3개월에서 12개월 가격 모멘텀을 흔히 모멘텀이라고 합니다. 즉 과거 12개월 수익률이 높았던 종목이 계속해서 상승하는 현상을 모멘텀이라 합니다.\n모멘텀 효과가 발생하는 이유는 기업의 가치 변화에 대한 사람들의 반응 때문입니다. 기업의 이익이 증가하면 내재가치(펀더멘털 가치) 역시 증가하고, 이러한 가치는 즉각적으로 변합니다. 반면 주식의 가격은 늘 새로운 정보에 반응해 상승하기는 하지만, 초기에는 이익에 대한 과소 반응으로 인해 상승폭이 낮으며 그 이후 계속해서 상승합니다. 주식의 가격이 가치에 수렴하기 위해 상승하다 보면 투자자들의 주목을 끌기 마련이며, 양떼 효과로 인해 따라서 투자하는 이들이 많아집니다. 그 결과, 과잉 반응이 발생해 주가는 계속해서 상승하며 모멘텀 효과가 발생합니다. 그러나 투자자들이 기업의 가치에 비해 주가가 너무 비싸졌다고 판단하는 순간 주가는 하락하기 시작하며 반전이 이루어집니다.\n\n\n\n\n\n\n7.4.1 모멘텀별 포트폴리오의 수익률\n프렌치 라이브러리 데이터를 이용해 최근 12개월 수익률을 기준으로 구성된 포트폴리오의 수익률을 비교해보겠습니다.\n\nlibrary(frenchdata)\nff_mom = download_french_data('10 Portfolios Formed on Momentum')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_mom_vw = ff_mom$subsets$data[[1]]\nff_mom_vw %>% data_to_plot() + scale_colour_manual(values = rainbow(10))\n\n\n\n\n\n\n\n\n모멘텀별 포트폴리오의 누적수익률을 확인해보면, 최근 12개월 수익률이 높을수록(Hi PRIOR) 향후에도 지속적으로 수익률이 높으며, 최근 12월 수익률이 낮을수록(Lo PRIOR) 향후에도 수익률이 낮은 ’모멘텀 현상’이 존재합니다. 이번에는 저모멘텀 대비 고모멘텀 수익률인 UMD 팩터의 수익률을 살펴보겠습니다.\n\nff_umd = download_french_data('Momentum Factor (Mom)')\n\nNew names:\nNew names:\n• `` -> `...1`\n\nff_umd$subsets$data[[1]] %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n장기적으로 우상향 하는 모습을 보이지만 시장이 급락한 이후 반등할 때 모멘텀 팩터가 무너지는 현상이 발생하며, 이를 ’모멘텀 크래쉬’라 합니다.\n\n\n7.4.2 모멘텀 포트폴리오 구하기\n최근 12개월 수익률이 높은 주식에 투자하는 것이 훨씬 수익률이 높다는 점을 확인하였으니, 국내 종목들 중 모멘텀 주식에는 어떠한 것이 있는 확인해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\n\n먼저 티커 테이블과 가격 테이블을 불러옵니다. 가격 테이블은 최근 1년에 해당하는 데이터만 불러옵니다.\n가격 테이블에서 종목코드 별로 그룹을 묶습니다.\n최근 종가를 1년전 종가로 나누어 1년간의 수익률을 계산합니다.\n\n이제 12개월 수익률이 높은 종목을 찾아보도록 합니다.\n\nmomentum_bind = ret_1yr %>% mutate(rank = min_rank(desc(ret))) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker)\n\nJoining, by = \"종목코드\"\n\nmomentum_bind\n\n# A tibble: 20 × 13\n   종목…¹   ret  rank 종목명  시장…²   종가 시가총액 기준일   EPS 선행EPS    BPS\n   <chr>  <dbl> <int> <chr>   <chr>   <dbl>    <dbl> <chr>  <dbl>   <dbl>  <dbl>\n 1 001570  2.47     5 금양    KOSPI   18650  1.08e12 2022-…   295      NA   2530\n 2 003610  1.38    15 방림    KOSPI    5780  2.45e11 2022-…   191      NA   5145\n 3 004690  1.83     8 삼천리  KOSPI  272500  1.10e12 2022-… 17385      NA 392735\n 4 005860  1.95     7 한일사… KOSDAQ   6260  2.47e11 2022-…   183      NA   1751\n 5 016710  1.41    14 대성홀… KOSPI   93400  1.50e12 2022-…  1040      NA  29257\n 6 016790  5.17     2 카나리… KOSDAQ  21100  9.38e11 2022-…    NA      NA   1876\n 7 025770  1.01    20 한국정… KOSDAQ  13350  5.00e11 2022-…   295      NA   6019\n 8 030960  2.99     3 양지사  KOSDAQ  43100  6.89e11 2022-…    96      NA  13794\n 9 043090  1.13    17 한창바… KOSDAQ   4270  1.88e11 2022-…    NA      NA    881\n10 052020  2.02     6 에스티… KOSDAQ  24750  1.07e12 2022-…    NA      NA    460\n11 053690  1.41    13 한미글… KOSPI   31400  3.44e11 2022-…  1537    2266  14014\n12 079810  1.04    19 디이엔… KOSDAQ  10200  1.57e11 2022-…    62     886   1711\n13 090710  1.55    11 휴림로… KOSDAQ   2150  3.52e11 2022-…    NA      NA    443\n14 095500  2.82     4 미래나… KOSDAQ  14950  4.64e11 2022-…   940      NA   8392\n15 101670  6.87     1 코리아… KOSDAQ  15500  2.98e11 2022-…    NA      NA   1470\n16 179290  1.58    10 엠아이… KOSDAQ  13050  4.19e11 2022-…   392     968   2081\n17 249420  1.05    18 일동제… KOSPI   26800  7.18e11 2022-…    NA      NA   6429\n18 322000  1.49    12 현대에… KOSPI   56400  6.32e11 2022-…    NA    5743  28600\n19 366030  1.26    16 공구우… KOSDAQ   7140  1.57e11 2022-…   581      NA   1797\n20 373200  1.75     9 하인크… KOSDAQ   5410  1.02e11 2022-…    NA      NA   1872\n# … with 2 more variables: 주당배당금 <dbl>, 종목구분 <chr>, and abbreviated\n#   variable names ¹​종목코드, ²​시장구분\n\n\nmin_rank() 함수를 통해 수익률의 순위를 구하며, 모멘텀의 경우 지표가 높을수록 좋으므로 desc() 함수를 통해 내림차순으로 순위를 구합니다. 마지막으로 해당 종목들의 가격 그래프를 확인해보도록 하겠습니다.\n\nprice %>% filter(종목코드 %in% (momentum_bind %>% select(종목코드) %>% pull())) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  ggplot(aes(x = as.Date(날짜), y = 종가)) +\n  geom_line() +\n  facet_wrap(. ~종목코드, scales = 'free') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme(axis.text.x=element_blank())\n\n\n\n\n\n\n\n\n\n\n7.4.3 K-Ratio\n12개월 수익률 기준 모멘텀 종목들의 주가 그래프를 보면 단순히 수익률 만으로 종목을 선택할 경우 다음과 같은 종목 또한 포함됩니다.\n\n장기간 수익률이 횡보하다가 최근 주가가 급등하여 누적수익률 역시 높게 나타나는 종목\n이미 몇달전에 주가가 급등한 후 최근에는 하락세이지만, 누적수익률 자체는 높게 나타나는 종목\n\n반면 좋은 모멘텀 주식이란 단순히 많이 상승한 것이 아닌, 꾸준하게 상승하는 종목이다. 하나의 예를 살펴봅시다.\n\n\n\n\n\n동일한 누적수익률을 가진 두 종목이 있다고 가정해봅시다. A의 경우 상승폭이 작다가 최근 급등하여 누적수익률이 높아진 경우입니다. 반면 B의 경우 꾸준하게 상승하여 누적수익률이 높아진 경우입니다. 이 중 꾸준하게 상승한 B가 더 뛰어난 모멘텀 주식이라고 볼 수 있습니다. 이처럼 꾸준한 상승을 측정하기 위해 실무에서는 단순 12개월 수익률이 아닌 3~12개월 수익률을 같이 보거나, 변동성을 함께 고려하기도 합니다. 그 중 모멘텀의 꾸준함을 측정하는 지표 중 하나가 ’K-Ratio’입니다. 해당 지표는 다음과 같습니다.\n\\[K-Ratio = \\frac{누적수익률의\\ 기울기}{표준\\ 오차}\\] 누적수익률이 높을수록 기울기도 커져 분자는 커집니다. 또한 추세가 꾸준할수록 표준 오차가 작아 분모는 작아집니다. 따라서 추세가 꾸준하게 많이 상승할수록 K-Ratio는 증가합니다. 먼저 K-Ratio를 측정하는 법을 살펴봅시다.\n\nlibrary(tidyr)\nlibrary(broom)\n\ntbl = price %>% filter(종목코드 == '005930') %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number()) \n\nreg = lm(cumret ~ id, data = tbl)\nsummary(reg)\n\n\nCall:\nlm(formula = cumret ~ id, data = tbl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.11585 -0.02906  0.01277  0.03074  0.08558 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.200e-01  6.377e-03   18.82   <2e-16 ***\nid          -1.396e-03  4.458e-05  -31.31   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04996 on 245 degrees of freedom\nMultiple R-squared:  0.8001,    Adjusted R-squared:  0.7993 \nF-statistic: 980.5 on 1 and 245 DF,  p-value: < 2.2e-16\n\n\n\n먼저 삼성전자에 해당하는 데이터만 뽑아 수익률을 계산합니다.\n로그수익률로 변경한 후 로그 누적수익률을 계산합니다.\nrow_number() 함수를 통해 순서를 입력합니다.\nlm() 함수를 통해 \\(x\\) 축에는 기간, \\(y\\) 축에는 로그 누적수익률로 회귀분석을 실행합니한다.\n\n결과표의 ’Estimate’는 기울기를, ’std err’는 표준 오차를 나타냅니다.\n\ncat(coef(summary(reg))[2, 1],\n    coef(summary(reg))[2, 2],\n    coef(summary(reg))[2, 1] / coef(summary(reg))[2, 2]\n)\n\n-0.001395999 4.458329e-05 -31.31215\n\n\n기울기와 표준오차를 추출한 후, 이 두개를 나눈 값이 K-Ratio 입니다. 이를 이용해 모든 종목의 K-Ratio를 계산하도록 하겠습니다.\n\nlibrary(purrr)\nlibrary(broom)\n\nstep_1 = price %>%\n  group_by(종목코드) %>%\n  filter(n() >= 200) %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number()) \n\nstep_2 = step_1 %>% \n  ungroup() %>%\n  nest(data = -종목코드) %>%\n  mutate(model = map(data, ~lm(cumret~id, data = .)),\n         tidied = map(model, tidy))\n\nk_ratio = step_2 %>%\n  unnest(tidied) %>%\n  filter(term == 'id') %>%\n  mutate(k_ratio = estimate / `std.error`) \n\n# k_ratio = price %>%\n#   group_by(종목코드) %>%\n#   filter(n() == t) %>%\n#   mutate(ret = 종가 / lag(종가) - 1) %>%\n#   mutate(ret = log(1+ret)) %>%\n#   slice(-1) %>%\n#   mutate(cumret = cumsum(ret)) %>%\n#   mutate(id = row_number()) %>%\n#   do({model = lm(cumret ~ id, data = .);\n#        data.frame(slope =  coef(summary(model))[2, 1], std_err =coef(summary(model))[2, 2])}) %>%\n#   mutate(k_ratio = slope / std_err) %>%\n#   ungroup()\n\n\n상장한지 200일 이상 된 종목만 선택합니다.\n수익률을 계산합니다.\nK-Ratio를 구합니다.\n\n이를 토대로 K-Ratio 상위 종목을 구해보겠습니다.\n\nk_bind = k_ratio %>% mutate(rank = min_rank(desc(k_ratio))) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker)\n\nJoining, by = \"종목코드\"\n\nprice %>% filter(종목코드 %in% (k_bind %>% select(종목코드) %>% pull())) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  ggplot(aes(x = as.Date(날짜), y = 종가)) +\n  geom_line() +\n  facet_wrap(. ~종목코드, scales = 'free') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme(axis.text.x=element_blank())\n\n\n\n\n\n\n\n\n기존 단순 모멘텀이 비해 훨씬 더 꾸준하게 우상향하는 종목들이 선택되었습니다."
  },
  {
    "objectID": "portfolio.html#퀄리티-전략",
    "href": "portfolio.html#퀄리티-전략",
    "title": "7  포트폴리오 구성하기",
    "section": "7.5 퀄리티 전략",
    "text": "7.5 퀄리티 전략\n벤자민 그레이엄 이후 유지되고 있는 기본적 분석 혹은 가치 투자자들의 가장 중요한 투자 지표 중 하나는 기업의 우량성(퀄리티)입니다. 벤저민 그레이엄은 종목 선정에 있어 유동 자산이 풍부하여 재무적으로 건전하고, 꾸준하게 이익을 달성하는 기업을 강조했습니다. 최고의 투자자로 꼽히는 워런 버핏의 종목 선정 기준 역시 실적의 강력한 성장 추세와 높은 자기자본 이익률로 알려져 있습니다.\n그러나 어떠한 지표가 기업의 우량성을 나타내는지 한 마디로 정의하기에는 너무나 주관적이고 광범위해 쉽지 않습니다. 연구에 따르면 수익성, 성장성, 안정성이 높을 주식일수록 수익률이 높은 경향이 있습니다. 이 외에도 학계 혹은 업계에서 사용되는 우량성 관련 지표는 다음과 같이 요약할 수 있습니다.\n\n수익성: 기업이 돈을 얼마나 잘 버는가(ROE, ROA, 매출총이익률 등).\n수익의 안정성: 기업이 얼마나 안정적으로 돈을 버는가(ROE의 변동성 등).\n재무 구조: 기업의 재무 구조가 얼마나 안전한가(차입비율 등).\n이익의 성장: 기업의 이익 증가율이 얼마나 되는가(전년 대비 ROE 증가율 등).\n재무 신뢰도: 재무제표를 얼마나 신뢰할 수 있는가(회계 처리 방법 등).\n배당: 얼마나 주주 친화적인가(배당금, 신주발행, 자사주 매입 등.)\n투자: 얼마나 신사업에 투자를 하는가(총자산의 증가 등)\n\n이 중 사람들이 가장 중요하게 여기는 것은 바로 수익성입니다. 돈을 벌지 못하는 기업은 지속될 수 없기 때문입니다. 기업의 규모가 크면 당연히 돈을 더 많이 벌기 때문에 단순히 수익의 양이 아닌, 기업의 규모에 비해 얼마를 버는지 표준화를 통해 비교해야 합니다.\n\n\n\n지표\n설명\n분자\n분모\n\n\n\n\nROE\n자기자본이익률\n당기순이익\n자본\n\n\nROA\n총자산이익률\n당기순이익\n자산\n\n\nROIC\n투하자본이익률\n당기순이익\n투하자본\n\n\nGP\n매출총이익률\n매출총이익\n자산 혹은 자본\n\n\n\n우량주 효과가 발생하는 이유 역시 사람들의 반응과 관계가 있습니다. 기업의 수익성이 높을 경우, 투자자들은 이익이 다시 원래 수준으로 빠르게 돌아갈 것이라 생각하지만, 실제로는 수익성이 높은 기업은 계속해서 높은 수익성을 보이는 경향이 있습니다. 반대로 기업의 수익성이 낮은 경우, 투자자들은 이익이 반등할 것이라 생각하지만 나쁜 기업은 계속해서 나쁜 경향이 있습니다.\n\n7.5.1 수익성별 포트폴리오의 수익률\n프렌치 라이브러리 데이터를 이용해 영업수익성을 기준으로 구성된 포트폴리오의 수익률을 비교해보겠습니다.\n\nff_op = download_french_data('Portfolios Formed on Operating Profitability')\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -> `...1`\n\nff_op_vw = ff_op$subsets$data[[1]]\nff_op_vw %>%select(date, `Lo 20`, `Qnt 2`, `Qnt 3`, `Qnt 4`, `Hi 20`) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n누적수익률을 확인해보면 수익성이 높을수록(Hi 20) 향후에도 지속적으로 수익률이 높으며, 수익성이 낮을수록(Lo 20) 향후에도 수익률이 낮은 ’퀄리티 현상’이 존재합니다. 이번에는 저수익성 대비 고수익성 수익률인 QMJ 팩터의 수익률을 살펴보겠습니다.\n\nff_op_vw %>%\n  select(date, `Lo 30`, `Hi 30`) %>%\n  mutate(QMJ = `Hi 30` - `Lo 30`) %>%\n  select(date, QMJ) %>%\n  data_to_plot()\n\n\n\n\n\n\n\n\n역시나 장기간 우상향하는 모습입니다.\n\n\n7.5.2 우량성 포트폴리오 구하기\n이번에는 국내 종목들 중 우량성(수익성)이 높은 종믁은 어떠한 것이 있는지 확인해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\nlibrary(RcppRoll)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nfs = dbGetQuery(con ,\n\"select * from kor_fs\nwhere 계정 in ('당기순이익', '매출총이익', '영업활동으로인한현금흐름', '자산', '자본')\nand 공시구분 = 'q';\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nfs_roll = fs %>% arrange(종목코드, 계정, 기준일) %>%\n  group_by(종목코드, 계정) %>%\n  mutate(rollsum = roll_sum(값, n = 4, align = 'right', fill = NA)) %>%\n  slice(n()) %>%\n  mutate(rollsum = case_when(\n    계정 %in% c('자본', '자산') ~ rollsum / 4,\n    TRUE ~ rollsum\n  )) %>%\n  ungroup()\n\nfs_roll\n\n# A tibble: 11,384 × 6\n   계정                     기준일        값 종목코드 공시구분 rollsum\n   <chr>                    <chr>      <dbl> <chr>    <chr>      <dbl>\n 1 당기순이익               2022-06-30    65 000020   q           193 \n 2 매출총이익               2022-06-30   468 000020   q          1666 \n 3 영업활동으로인한현금흐름 2022-06-30    48 000020   q           423 \n 4 자본                     2022-06-30  3652 000020   q          3596.\n 5 자산                     2022-06-30  4639 000020   q          4549 \n 6 당기순이익               2022-06-30    12 000040   q          -104 \n 7 매출총이익               2022-06-30    42 000040   q           158 \n 8 영업활동으로인한현금흐름 2022-06-30    -2 000040   q          -130 \n 9 자본                     2022-06-30   479 000040   q           492 \n10 자산                     2022-06-30  1640 000040   q          1698.\n# … with 11,374 more rows\n\n\n\n티커와 재무제표 테이블을 가져오고, 수익성을 계산하는데 필요한 계정(당기순이익, 매출총이익, 영업활동으로인한현금흐름, 자산, 자본 / 분기 데이터)을 불러옵니다.\n종목코드와 계정별로 그룹을 묶은 후, roll_sum() 함수를 이용해 최근 4분기 데이터의 합을 구합니다.\nslice(n()) 함수를 통해 그룹에서 가장 최근 데이터만 선택합니다.\n자산과 자본의 경우 재무상태표 항목이므로 합이 아닌 평균을 구하며, 나머지 항목은 합을 그대로 사용합니다.\n\n이제 각종 수익성 지표를 계산하겠습니다.\n\nfs_roll_pivot = fs_roll %>% select(계정, 종목코드, rollsum) %>%\n  pivot_wider(names_from = 계정, values_from = rollsum) %>%\n  mutate(ROE = 당기순이익 / 자본,\n         GPA = 매출총이익 / 자산,\n         CFO = 영업활동으로인한현금흐름 / 자산)\n\n마지막으로 수익성 지표의 순위를 구한 후, 상위 20 종목을 선택합니다.\n\nfs_roll_pivot %>%\n  mutate(across(c(ROE, GPA, CFO), .fns = ~rank(desc(.)), .names = \"rank_{col}\")) %>%\n  mutate(rank = rank(rank_ROE + rank_GPA + rank_CFO)) %>%\n  filter(rank <= 20) %>%\n  left_join(ticker) %>%\n  select(종목명, 종목코드, ROE, GPA, CFO)\n\nJoining, by = \"종목코드\"\n\n\n# A tibble: 20 × 5\n   종목명           종목코드   ROE   GPA   CFO\n   <chr>            <chr>    <dbl> <dbl> <dbl>\n 1 DB하이텍         000990   0.447 0.495 0.339\n 2 HMM              011200   0.905 0.574 0.570\n 3 엠게임           058630   0.266 0.703 0.226\n 4 아프리카TV       067160   0.358 0.739 0.305\n 5 랩지노믹스       084650   0.520 0.649 0.386\n 6 이크레더블       092130   0.285 0.647 0.259\n 7 씨젠             096530   0.402 0.606 0.390\n 8 위메이드맥스     101730   0.349 0.776 0.260\n 9 LX세미콘         108320   0.435 0.642 0.281\n10 에스디바이오센서 137310   0.466 0.482 0.301\n11 파수             150900   0.330 0.699 0.387\n12 휴마시스         205470   1.32  1.17  0.932\n13 골프존           215000   0.343 0.674 0.295\n14 삼양옵틱스       225190   0.348 0.554 0.263\n15 수젠텍           253840   0.670 0.574 0.371\n16 제이시스메디칼   287410   0.555 0.882 0.258\n17 비올             335890   0.291 0.545 0.32 \n18 넥스틴           348210   0.439 0.640 0.239\n19 원티드랩         376980   0.259 0.903 0.269\n20 F&F              383220   0.654 1.01  0.315"
  },
  {
    "objectID": "portfolio.html#섹터-중립-포트폴리오",
    "href": "portfolio.html#섹터-중립-포트폴리오",
    "title": "7  포트폴리오 구성하기",
    "section": "7.6 섹터 중립 포트폴리오",
    "text": "7.6 섹터 중립 포트폴리오\n팩터 전략의 단점 중 하나는 선택된 종목들이 특정 섹터로 쏠리는 경우가 있다는 점입니다. 특히 과거 수익률을 토대로 종목을 선정하는 모멘텀 전략은 특정 섹터의 호황기에 동일한 섹터의 모든 종목이 함께 움직이는 경향이 있어 이러한 쏠림이 심할 수 있습니다.\n실제 연구 결과를 살펴보아도 섹터 중립 포트폴리오의 수익률이 일반적인 포트폴리오의 수익률 보다 높습니다.\n\n\n\n\n\n먼저 12개월 모멘텀을 이용한 포트폴리오 구성 방법을 다시 살펴봅시다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nsector = dbGetQuery(con,\n                    \"select * from kor_sector\nwhere 기준일 = (select max(기준일) from kor_sector);\"\n)\n                  \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\nret_1yr %>% mutate(rank = min_rank(desc(ret))) %>%\n  filter(rank <= 20) %>%\n  left_join(sector, by = (c(\"종목코드\" = \"CMP_CD\"))) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  arrange(n) %>%\n  mutate(SEC_NM_KOR = factor(SEC_NM_KOR, levels = .$SEC_NM_KOR %>% unique)) %>%\n  ggplot(aes(x = SEC_NM_KOR, y = n)) +\n  geom_col() +\n  geom_text(aes(label = n, hjust = -1)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n12개월 기준 모멘텀 상위 종목을 선택한 후, 섹터 테이블을 이용해 섹터별 갯수를 구합니다. 간혹 특정 섹터의 모멘텀이 매우 좋을 경우, 해당 섹터에 쏠림이 심한 경우가 있습니다. 이러한 섹터 쏠림 현상을 제거한 섹터 중립 포트폴리오를 구성해보도록 하겠습니다.\n\nret_1yr_neutral = ret_1yr %>%\n  left_join(sector, by = (c(\"종목코드\" = \"CMP_CD\"))) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(scale_per_sector = scale(ret),\n         scale_per_sector = ifelse(is.na(`SEC_NM_KOR`),\n                                   NA, scale_per_sector)) %>%\n  ungroup()\n         \nhead(ret_1yr_neutral)\n\n# A tibble: 6 × 7\n  종목코드     ret IDX_CD CMP_KOR    SEC_NM_KOR     기준일     scale_per_sector\n  <chr>      <dbl> <chr>  <chr>      <chr>          <chr>                 <dbl>\n1 000020   -0.493  G35    동화약품   건강관리       2022-10-14           -0.572\n2 000040   -0.399  G25    KR모터스   경기관련소비재 2022-10-14           -0.342\n3 000050   -0.159  G25    경방       경기관련소비재 2022-10-14            0.523\n4 000060    0.0549 G40    메리츠화재 금융           2022-10-14            1.82 \n5 000070   -0.412  G30    삼양홀딩스 필수소비재     2022-10-14           -0.422\n6 000080   -0.299  G30    하이트진로 필수소비재     2022-10-14           -0.238\n\n\n\ngroup_by() 함수를 통해 섹터별 그룹을 만들어줍니다.\nscale() 함수를 이용해 그룹별 정규화를 해줍니다. 정규화는 \\(\\frac{x-\\mu}{\\sigma}\\)로 계산됩니다.\n섹터 정보가 없을 경우 NA로 변경합니다.\n\n위의 정규화 과정을 살펴보면, 전체 종목에서 12개월 수익률을 비교하는 것이 아닌 각 섹터별로 수익률의 강도를 비교하게 됩니다. 따라서 특정 종목의 과거 수익률이 전체 종목과 비교해서 높았더라도 해당 섹터 내에서의 순위가 낮다면, 정규화된 값은 낮아집니다.\n따라서 섹터별 정규화 과정을 거친 값으로 비교 분석을 한다면, 섹터 효과가 제거된 포트폴리오를 구성할 수 있습니다.\n\nret_1yr_neutral %>%\n  mutate(rank = min_rank(desc(scale_per_sector))) %>%\n  filter(rank <= 20)\n\n# A tibble: 20 × 8\n   종목코드   ret IDX_CD CMP_KOR          SEC_NM_KOR        기준일 scale…¹  rank\n   <chr>    <dbl> <chr>  <chr>            <chr>             <chr>    <dbl> <int>\n 1 000230   0.833 G35    일동홀딩스       건강관리          2022-…    3.97    18\n 2 001570   2.47  G15    금양             소재              2022-…    8.74     3\n 3 003610   1.38  G25    방림             경기관련소비재    2022-…    6.06     9\n 4 016790   5.17  G30    카나리아바이오   필수소비재        2022-…    8.68     4\n 5 025770   1.01  G50    한국정보통신     커뮤니케이션서비… 2022-…    4.90    12\n 6 030960   2.99  G20    양지사           산업재            2022-…    6.08     8\n 7 043090   1.13  G25    한창바이오텍     경기관련소비재    2022-…    5.18    11\n 8 052020   2.02  G45    에스티큐브       IT                2022-…    7.08     5\n 9 056090   0.939 G35    이노시스         건강관리          2022-…    4.33    16\n10 079810   1.04  G45    디이엔티         IT                2022-…    4.02    17\n11 095500   2.82  G45    미래나노텍       IT                2022-…    9.60     2\n12 101670   6.87  G20    코리아에스이     산업재            2022-…   13.5      1\n13 179290   1.58  G35    엠아이텍         건강관리          2022-…    6.52     6\n14 205470   0.746 G35    휴마시스         건강관리          2022-…    3.67    19\n15 215100   0.707 G25    로보로보         경기관련소비재    2022-…    3.64    20\n16 249420   1.05  G35    일동제약         건강관리          2022-…    4.70    13\n17 322000   1.49  G10    현대에너지솔루션 에너지            2022-…    4.44    15\n18 366030   1.26  G25    공구우먼         경기관련소비재    2022-…    5.64    10\n19 373200   1.75  G45    하인크코리아     IT                2022-…    6.26     7\n20 376180   0.938 G25    피코그램         경기관련소비재    2022-…    4.48    14\n# … with abbreviated variable name ¹​scale_per_sector\n\n\n\nret_1yr_neutral %>%\n  mutate(rank = min_rank(desc(scale_per_sector))) %>%\n  filter(rank <= 20) %>%\n  group_by(SEC_NM_KOR) %>%\n  summarize(n = n()) %>%\n  arrange(n) %>%\n  mutate(SEC_NM_KOR = factor(SEC_NM_KOR, levels = .$SEC_NM_KOR %>% unique)) %>%\n  ggplot(aes(x = SEC_NM_KOR, y = n)) +\n  geom_col() +\n  geom_text(aes(label = n, hjust = -1)) +\n  coord_flip()\n\n\n\n\n\n\n\n\ngroup_by() 함수를 통해 손쉽게 그룹별 중립화를 할 수 있으며, 글로벌 투자를 하는 경우에는 지역, 국가, 섹터별로도 중립화된 포트폴리오를 구성하기도 합니다."
  },
  {
    "objectID": "portfolio.html#이상치-데이터-처리-및-팩터의-결합",
    "href": "portfolio.html#이상치-데이터-처리-및-팩터의-결합",
    "title": "7  포트폴리오 구성하기",
    "section": "7.7 이상치 데이터 처리 및 팩터의 결합",
    "text": "7.7 이상치 데이터 처리 및 팩터의 결합\n안정적인 퀀트 포트폴리오를 구성하기 위해서는 팩터 데이터를 어떻게 처리하여 결합할지에 대해서도 알고 있어야 하므로, 이러한 점에 대해 살펴보도록 하겠습니다.\n모든 데이터 분석에서 중요한 문제 중 하나가 이상치(극단치, Outlier) 데이터를 어떻게 처리할 것인가입니다. 과거 12개월 수익률이 10배인 주식이 과연 모멘텀 관점에서 좋기만 한 주식인지, ROE가 100%를 넘는 주식이 과연 퀄리티 관점에서 좋기만 한 주식인지 고민이 되기 마련입니다. 따라서 이러한 이상치를 제외하고 분석할지, 포함해서 분석할지를 판단해야 합니다. 만일 이상치를 포함한다면 그대로 사용할 것인지, 보정해 사용할 것인지도 판단해야 합니다.\n우리가 가지고 있는 PBR 데이터에서 이상치 데이터를 탐색해보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nPBR = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  filter(지표 == 'PBR') %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일)\n\nPBR %>% summarize(max_pbr = max(PBR, na.rm = T), min_pbr = min(PBR, na.rm = T))\n\n# A tibble: 1 × 2\n  max_pbr min_pbr\n    <dbl>   <dbl>\n1    40.4  0.0363\n\n\n먼저 밸류 테이블을 불러온 후 PBR 데이터만 선택합니다. PBR의 최대값과 최소값을 확인해보면 값이 매우 큰 것을 확인할 수 있습니다.\n\nPBR %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n국내 종목들의 PBR을 히스토그램으로 그려보면 오른쪽으로 꼬리가 매우 긴 분포를 보입니다. 이는 PBR이 극단적으로 큰 이상치 데이터가 있기 때문입니다. 이처럼 모든 팩터 데이터에는 극단치가 있기 마련이며, 이를 처리하는 방법을 알아보도록 하겠습니다.\n\n7.7.1 트림(Trim): 이상치 데이터 삭제\n트림은 이상치 데이터를 삭제하는 방법입니다. 위의 예제에서 이상치에 해당하는 상하위 1% 데이터를 삭제하겠습니다.\n\nPBR %>%\n  mutate(PBR = ifelse(percent_rank(PBR) > 0.99, NA, PBR),\n         PBR = ifelse(percent_rank(PBR) < 0.01, NA, PBR)) %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 50 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\npercent_rank() 함수를 통해 백분위를 구한 후 상하위 1%에 해당하는 데이터를 제외한 데이터만 선택합니다. 결과적으로 지나치게 PBR이 낮은 종목과 높은 종목은 제거되어 \\(x\\)축의 스케일이 많이 줄어든 모습입니다.\n평균이나 분산 같이 통계값을 구하는 과정에서는 이상치 데이터를 제거하는 것이 바람직할 수 있습니다. 그러나 팩터를 이용해 포트폴리오를 구하는 과정에서 해당 방법은 조심스럽게 사용되어야 합니다. 데이터의 손실이 발생하게 되며, 제거된 종목 중 정말로 좋은 종목이 있을 수도 있기 때문입니다.\n\n\n7.7.2 윈저라이징(Winsorizing): 이상치 데이터 대체\n이상치 데이터를 다른 데이터로 대체하는 윈저라이징 방법을 사용할 수도 있습니다. 예를 들어 상위 1%를 초과하는 데이터는 1% 값으로 대체하며, 하위 1% 미만의 데이터는 1% 데이터로 대체합니다. 즉, 좌우로 울타리를 쳐놓고 해당 범위를 넘어가는 값을 강제로 울타리에 맞춰줍니다.\n\nPBR %>%\n  mutate(PBR = ifelse(percent_rank(PBR) > 0.99,\n                      quantile(.$PBR, 0.99, na.rm = TRUE), PBR),\n         PBR = ifelse(percent_rank(PBR) < 0.01,\n                      quantile(.$PBR, 0.01, na.rm = TRUE), PBR)) %>%\n  ggplot(aes(x = PBR)) +\n  geom_histogram(bins = 100)\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n이번에는 값이 상하위 1%를 벗어나는 경우, 1%에 해당하는 값으로 대체하였습니다. 그림을 살펴보면 축 양 끝부분의 막대(붉은색)가 길어진 것을 확인할 수 있습니다.\n\n\n7.7.3 팩터의 결합방법\n앞서 밸류 지표의 결합, 퀄리티 지표의 결합, 마법공식 포트폴리오를 구성할 때는 단순히 순위를 더하는 방법을 사용했습니다. 물론 투자 종목수가 얼마 되지 않거나, 개인 투자자의 입장에서는 이러한 방법이 가장 단순하면서도 효과적일수 있습니다. 그러나 전문투자자가 포트폴리오를 구성하거나 팩터를 분석하는 업무를 할 경우 이처럼 단순히 순위를 더하는 방법은 여러 가지 문제를 안고 있습니다.\n각 밸류 지표의 순위를 구한 후 히스토그램으로 나타내보도록 하겠습니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'stock_db' # 사용하고자 하는 스키마\n)\n\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n                  \nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\ndbDisconnect(con)\n\n[1] TRUE\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\nvalue %>%\n  select(종목코드, contains('rank_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(name ~. , ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2729 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n그림에서 알 수 있듯이 순위를 구하는 것의 가장 큰 장점은 극단치로 인한 효과가 사라진다는 점과 균등한 분포를 가진다는 점입니다. 그러나 각 지표의 \\(x\\)축을 보면 최댓값이 서로 다릅니다. 이는 지표별 결측치로 인해 유효 데이터의 갯수가 달라 나타나는 현상입니다.\n\nvalue %>%\n  select(종목코드, contains('rank_')) %>%\n  pivot_longer(-종목코드) %>%\n  group_by(name) %>%\n  summarize(na_count = sum(is.na(value)))\n\n# A tibble: 5 × 2\n  name     na_count\n  <chr>       <int>\n1 rank_DY      1130\n2 rank_PBR        4\n3 rank_PCR      828\n4 rank_PER      681\n5 rank_PSR       86\n\n\n밸류 지표 별 NA 개수를 확인해보면 그 결과가 모두 다르며, 특히 배당 수익률의 경우 절반 정도가 NA 데이터입니다. 따라서 서로 다른 범위의 분포를 단순히 합치는 것은 좋은 방법이 아닙니다. 예를 들어 A, B, C, D 팩터에 각각 비중을 25%, 25%, 25%, 25% 부여해 포트폴리오를 구성한다고 가정해봅시다. 각 순위는 분포의 범위가 다르므로, 순위와 비중의 가중평균을 통해 포트폴리오를 구성하면 왜곡된 결과를 발생시킵니다.\n이러한 문제를 해결하는 가장 좋은 방법은 순위를 구한 후 이를 Z-Score로 정규화하는 것입니다.\n\nvalue_z_score = value %>%\n  select(1:6) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY))) %>%\n  mutate(across(c(rank_PBR, rank_PER, rank_PCR, rank_PSR, rank_DY), scale, .names = \"z_{col}\")) \n\nvalue_z_score %>%\n  select(종목코드, contains('z_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_wrap(name ~. , ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2729 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n앞서 구해진 순위에 scale 함수를 통해 정규화를 해줍니다. 기본적으로 순위의 분포가 가진 극단치 효과가 사라지는 점과 균등 분포의 장점을 유지하고 있으며, 분포의 범위 역시 거의 동일하게 바뀌었습니다. 이처럼 여러 팩터를 결합해 포트폴리오를 구성하고자 하는 경우, 먼저 각 팩터(지표)별 순위를 구한 후 이를 정규화한 뒤 더해야 왜곡 효과가 제거되어 안정적인 포트폴리오가 됩니다.\n\\[Z-Score(Rank(Factor\\ A)) + Z-Score(Rank(Factor\\ B)) + \\dots + Z-Score(Rank(Factor\\ N))\\]"
  },
  {
    "objectID": "portfolio.html#멀티팩터-포트폴리오",
    "href": "portfolio.html#멀티팩터-포트폴리오",
    "title": "7  포트폴리오 구성하기",
    "section": "7.8 멀티팩터 포트폴리오",
    "text": "7.8 멀티팩터 포트폴리오\n앞에서 배웠던 팩터 이론들과 결합 방법들을 응용해 멀티팩터 포트폴리오를 구성해봅시다. 각 팩터에 사용되는 지표는 다음과 같습니다.\n\n퀄리티: 자기자본이익률(ROE), 매출총이익(GPA), 영업활동현금흐름(CFO)\n밸류: PER, PBR, PSR, PCR, DY\n모멘텀: 12개월 수익률, K-Ratio\n\n\nlibrary(DBI)\nlibrary(RMySQL)\n\n# 연결\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\n# 티커\nticker = dbGetQuery(con,\n                    \"select * from kor_ticker\nwhere 기준일 = (select max(기준일) from kor_ticker)\n    and 종목구분 = '보통주';\")\n      \n# 주가            \nprice = dbGetQuery(con ,\n\"select 날짜, 종가, 종목코드\nfrom kor_price\nwhere 날짜 >= (select (select max(날짜) from kor_price) - interval 1 year);\n\")\n\n# 밸류\nvalue = dbGetQuery(con ,\n\"select * from kor_value\nwhere 기준일 = (select max(기준일) from kor_value);\n\")\n\n# 재무제표\nfs = dbGetQuery(con ,\n\"select * from kor_fs\nwhere 계정 in ('당기순이익', '매출총이익', '영업활동으로인한현금흐름', '자산', '자본')\nand 공시구분 = 'q';\n\")\n\n# 섹터\nsector = dbGetQuery(con,\n                    \"select * from kor_sector\nwhere 기준일 = (select max(기준일) from kor_sector);\"\n)\n\ndbDisconnect(con)\n\n[1] TRUE\n\n\n티커, 섹터, 주가, 재무제표, 가치지표 데이터를 불러옵니다.\n\nvalue = value %>%\n  mutate(값 = ifelse(값 <=0, NA, 값)) %>%\n  pivot_wider(names_from = '지표', values_from = '값') %>%\n  select(-기준일) %>%\n  mutate(across(c(PBR, PER, PCR, PSR), min_rank, .names = \"rank_{col}\")) %>%\n  mutate(rank_DY = min_rank(desc(DY)))\n\n가치지표를 핸들링합니다.\n\nlibrary(RcppRoll)\n\nfs_roll = fs %>% arrange(종목코드, 계정, 기준일) %>%\n  group_by(종목코드, 계정) %>%\n  mutate(rollsum = roll_sum(값, n = 4, align = 'right', fill = NA)) %>%\n  slice(n()) %>%\n  mutate(rollsum = case_when(\n    계정 %in% c('자본', '자산') ~ rollsum / 4,\n    TRUE ~ rollsum\n  )) %>%\n  ungroup()\n\nfs_roll_pivot = fs_roll %>% select(계정, 종목코드, rollsum) %>%\n  pivot_wider(names_from = 계정, values_from = rollsum) %>%\n  mutate(ROE = 당기순이익 / 자본,\n         GPA = 매출총이익 / 자산,\n         CFO = 영업활동으로인한현금흐름 / 자산)\n\n퀄리티 지표를 계산하기 위해 TTM 기준 ROE, GPA, CFO를 계산합니다.\n\nret_1yr =\n  price %>% select(날짜, 종목코드, 종가) %>%\n  group_by(종목코드) %>%\n  slice_tail(n = 255) %>%\n  summarise(ret = last(종가) / first(종가) - 1)\n\nk_ratio = price %>%\n  group_by(종목코드) %>%\n  filter(n() >= 200) %>%\n  mutate(ret = 종가 / lag(종가) - 1) %>%\n  mutate(ret = log(1+ret)) %>%\n  slice(-1) %>%\n  mutate(cumret = cumsum(ret)) %>%\n  mutate(id = row_number())  %>%\n  ungroup() %>%\n  nest(data = -종목코드) %>%\n  mutate(model = map(data, ~lm(cumret~id, data = .)),\n         tidied = map(model, tidy)) %>%\n  unnest(tidied) %>%\n  filter(term == 'id') %>%\n  mutate(k_ratio = estimate / `std.error`) \n\n최근 12개월 수익률과 K-Ratio를 계산합니다. 이제 모든 테이블을 하나로 합치도록 합니다.\n\nlibrary(tibble)\n\ndata_bind  = \n  ticker %>%\n  left_join(sector, by = c('종목코드' = 'CMP_CD')) %>%\n  left_join(fs_roll_pivot %>% select(종목코드, ROE, GPA, CFO)) %>%\n  left_join(value) %>%\n  left_join(ret_1yr) %>%\n  left_join(k_ratio %>% select(종목코드, k_ratio)) \n\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\nJoining, by = \"종목코드\"\n\ndata_bind = data_bind %>%\n  mutate(SEC_NM_KOR = replace_na(SEC_NM_KOR, '기타')) %>% as_tibble()\n\ndata_bind\n\n# A tibble: 2,294 × 30\n   종목코드 종목명    시장…¹  종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>     <chr>  <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000020   동화약품  KOSPI   8650  2.42e11 2022-1…   647      NA  12534    180\n 2 000040   KR모터스  KOSPI    599  5.76e10 2022-1…    NA      NA    385      0\n 3 000050   경방      KOSPI  10800  2.96e11 2022-1…   872      NA  30033    125\n 4 000060   메리츠화… KOSPI  29600  3.37e12 2022-1…  5768    6808  22086    620\n 5 000070   삼양홀딩… KOSPI  63800  5.46e11 2022-1… 30711      NA 226314   3000\n 6 000080   하이트진… KOSPI  24650  1.73e12 2022-1…  1031    1984  15657    800\n 7 000100   유한양행  KOSPI  55000  4.03e12 2022-1…  1496    1673  28297    400\n 8 000120   CJ대한통… KOSPI  81000  1.85e12 2022-1…  1841   10250 178766      0\n 9 000140   하이트진… KOSPI  10050  2.33e11 2022-1…  1529      NA  23538    450\n10 000150   두산      KOSPI  78600  1.30e12 2022-1… 11890   12800 121631   2000\n# … with 2,284 more rows, 20 more variables: 종목구분 <chr>, IDX_CD <chr>,\n#   CMP_KOR <chr>, SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>,\n#   CFO <dbl>, DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>,\n#   rank_PBR <int>, rank_PER <int>, rank_PCR <int>, rank_PSR <int>,\n#   rank_DY <int>, ret <dbl>, k_ratio <dbl>, and abbreviated variable names\n#   ¹​시장구분, ²​기준일.x, ³​주당배당금\n\n\n테이블을 합친 후, 섹터 정보가 없는 경우 ’기타’를 입력합니다.\n이번에는 각 섹터별로 아웃라이어를 제거한 후 순위와 Z-Score를 구하도록 하겠습니다. 첫번째로 퀄리티 지표의 Z-Score를 계산합니다.\n\nz_quality = data_bind %>% select(종목코드, SEC_NM_KOR, ROE, GPA, CFO) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(across(c(ROE, GPA, CFO), .fns = ~min_rank(desc(.)), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_ROE, rank_GPA, rank_CFO), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_quality = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_quality %>% select(종목코드, z_quality))\n\nJoining, by = \"종목코드\"\n\ndata_bind\n\n# A tibble: 2,294 × 31\n   종목코드 종목명    시장…¹  종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>     <chr>  <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000020   동화약품  KOSPI   8650  2.42e11 2022-1…   647      NA  12534    180\n 2 000040   KR모터스  KOSPI    599  5.76e10 2022-1…    NA      NA    385      0\n 3 000050   경방      KOSPI  10800  2.96e11 2022-1…   872      NA  30033    125\n 4 000060   메리츠화… KOSPI  29600  3.37e12 2022-1…  5768    6808  22086    620\n 5 000070   삼양홀딩… KOSPI  63800  5.46e11 2022-1… 30711      NA 226314   3000\n 6 000080   하이트진… KOSPI  24650  1.73e12 2022-1…  1031    1984  15657    800\n 7 000100   유한양행  KOSPI  55000  4.03e12 2022-1…  1496    1673  28297    400\n 8 000120   CJ대한통… KOSPI  81000  1.85e12 2022-1…  1841   10250 178766      0\n 9 000140   하이트진… KOSPI  10050  2.33e11 2022-1…  1529      NA  23538    450\n10 000150   두산      KOSPI  78600  1.30e12 2022-1… 11890   12800 121631   2000\n# … with 2,284 more rows, 21 more variables: 종목구분 <chr>, IDX_CD <chr>,\n#   CMP_KOR <chr>, SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>,\n#   CFO <dbl>, DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>,\n#   rank_PBR <int>, rank_PER <int>, rank_PCR <int>, rank_PSR <int>,\n#   rank_DY <int>, ret <dbl>, k_ratio <dbl>, z_quality <dbl>, and abbreviated\n#   variable names ¹​시장구분, ²​기준일.x, ³​주당배당금\n\n\n두번째로 밸류 지표의 Z-Score를 계산합니다.\n\nz_value =\n  data_bind %>% select(종목코드, SEC_NM_KOR, DY, PBR, PCR, PER, PSR) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(rank_DY = min_rank(desc(DY))) %>%\n  mutate(across(c(PBR, PCR, PER, PSR), .fns = ~min_rank(.), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_DY, rank_PBR, rank_PCR, rank_PER, rank_PSR), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_value = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_value %>% select(종목코드, z_value))\n\nJoining, by = \"종목코드\"\n\n\n마지막으로 모멘텀 지표의 Z-Score를 구합니다.\n\nz_momentum =\n  data_bind %>% select(종목코드, SEC_NM_KOR, ret, k_ratio) %>%\n  group_by(SEC_NM_KOR) %>%\n  mutate(across(c(ret, k_ratio), .fns = ~min_rank(desc(.)), .names = \"rank_{col}\")) %>%  \n  mutate(across(c(rank_ret, rank_k_ratio), .fns = ~scale(.), .names = \"z_{col}\")) %>%\n  mutate(z_momentum = rowSums(across(contains('z_rank')))) %>%\n  ungroup()\n\ndata_bind = data_bind %>%\n  left_join(z_momentum %>% select(종목코드, z_momentum))\n\nJoining, by = \"종목코드\"\n\n\n각 팩터의 분포를 시각화해보도록 하겠습니다.\n\ndata_bind %>%\n  select(종목코드, contains('z_')) %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_grid(name ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1768 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n각각 퀄리티 지표는 3개, 밸류 지표는 5개, 모멘텀 지표는 2개 기준을 이용해 계산했습니다. 그림에서 알 수 있듯이 기준을 많이 사용할 수록 Z-Score가 넓게 퍼져있는 모습을 보이며, 각 팩터별 분포가 동일하지 않습니다. 따라서 다시 Z-Score를 계산해 분포의 넓이를 비슷하게 맞춰주도록 합니다.\n\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\ndata_bind_final  = data_bind %>%\n  select(종목코드, z_quality, z_value, z_momentum) %>%\n  mutate(across(c(z_quality, z_value, z_momentum), .fns = ~scale(.))) %>%\n  set_colnames(c('종목코드', 'quality', 'value', 'momentum'))\n\ndata_bind_final %>%\n  pivot_longer(-종목코드) %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() +\n  facet_grid(name ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1768 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n재계산된 Z-Score의 분포의 넓이를 살펴보면 이전에 비해 훨씬 비슷해진 것을 알 수 있습니다. 각 팩터들 간의 상관관계를 살펴보겠습니다.\n\ndata_bind_final %>%\n  select(-종목코드) %>%\n  cor(., use = 'complete.obs') %>%\n  round(., 2)\n\n         quality value momentum\nquality     1.00  0.08     0.08\nvalue       0.08  1.00    -0.15\nmomentum    0.08 -0.15     1.00\n\n\n각 팩터간 상관관계가 매우 낮으며, 여러 팩터를 동시에 고려함으로서 분산효과를 기대할 수 있습니다. 이제 계산된 팩터들을 토대로 최종 포트폴리오를 구성해보도록 하겠습니다.\n\nwts = c(0.3, 0.3, 0.3)\n\ndata_bind_final = data_bind_final %>%\n  column_to_rownames('종목코드') %>%\n  multiply_by(wts) %>% \n  mutate(qvm = rowSums(.)) %>%\n  rownames_to_column(var = '종목코드') %>%\n  select(종목코드, qvm)\n  \ndata_bind = data_bind %>%\n  left_join(data_bind_final) %>%\n  mutate(invest = ifelse(min_rank(qvm) <= 20, 'Y', 'N'))\n\nJoining, by = \"종목코드\"\n\ndata_bind %>%\n  filter(invest == 'Y')\n\n# A tibble: 20 × 35\n   종목코드 종목명   시장…¹   종가 시가총액 기준…²    EPS 선행EPS    BPS 주당…³\n   <chr>    <chr>    <chr>   <dbl>    <dbl> <chr>   <dbl>   <dbl>  <dbl>  <dbl>\n 1 000700   유수홀…  KOSPI    6350  1.65e11 2022-1…   991      NA  13108    400\n 2 001120   LX인터…  KOSPI   42750  1.66e12 2022-1…  9733   11746  49349   2300\n 3 005010   휴스틸   KOSPI    5810  2.28e11 2022-1…   987      NA  15984    160\n 4 009970   영원무…  KOSPI   51200  6.98e11 2022-1… 19026   22866 140307   2000\n 5 017670   SK텔레콤 KOSPI   49700  1.09e13 2022-1…  7191    5167  53218   3295\n 6 030200   KT       KOSPI   34800  9.09e12 2022-1…  5759    5188  63512   1910\n 7 036710   심텍홀…  KOSDAQ   3140  1.52e11 2022-1…   695      NA   4051     50\n 8 049070   인탑스   KOSDAQ  27800  4.78e11 2022-1…  4436    4244  32446    470\n 9 058860   KTis     KOSPI    2430  8.46e10 2022-1…   767      NA   5909    100\n10 065510   휴비츠   KOSDAQ  10000  1.19e11 2022-1…   848    2383   8297    200\n11 078930   GS       KOSPI   45950  4.27e12 2022-1… 15304   19446 108672   2000\n12 084650   랩지노…  KOSDAQ   7110  2.42e11 2022-1…  2497      NA   4747    300\n13 093050   LF       KOSPI   15450  4.52e11 2022-1…  4169      NA  46904    600\n14 094970   제이엠티 KOSDAQ   3115  5.22e10 2022-1…   908      NA   4505    150\n15 124560   태웅로…  KOSDAQ   4805  1.85e11 2022-1…  1726      NA   3292    100\n16 200880   서연이화 KOSPI    6630  1.79e11 2022-1…   973      NA  24588    150\n17 205470   휴마시스 KOSDAQ  17850  6.11e11 2022-1…  4422      NA   5908    200\n18 225220   제놀루션 KOSDAQ   9700  9.30e10 2022-1…  3626      NA   9083    400\n19 306200   세아제강 KOSPI  142000  4.03e11 2022-1… 32640   64527 242703   3500\n20 319660   피에스…  KOSDAQ  17150  2.48e11 2022-1…  2615    2896   9888    600\n# … with 25 more variables: 종목구분 <chr>, IDX_CD <chr>, CMP_KOR <chr>,\n#   SEC_NM_KOR <chr>, 기준일.y <chr>, ROE <dbl>, GPA <dbl>, CFO <dbl>,\n#   DY <dbl>, PBR <dbl>, PCR <dbl>, PER <dbl>, PSR <dbl>, rank_PBR <int>,\n#   rank_PER <int>, rank_PCR <int>, rank_PSR <int>, rank_DY <int>, ret <dbl>,\n#   k_ratio <dbl>, z_quality <dbl>, z_value <dbl>, z_momentum <dbl>, qvm <dbl>,\n#   invest <chr>, and abbreviated variable names ¹​시장구분, ²​기준일.x,\n#   ³​주당배당금\n\n\n\n각 팩터별 비중을 리스트로 만들며, 0.3으로 동일한 비중을 입력합니다다. 비중을 [0.2, 0.4, 0.4]와 같이 팩터별로 다르게 줄 수도 있으며, 이는 어떠한 팩터를 더욱 중요하게 생각하는지 혹은 더욱 좋게 보는지에 따라 조정이 가능합니다.\n팩터별 Z-Score와 비중의 곱을 구한 후 이를 합합니다.\n기존 테이블(data_bind)과 합칩니다.\n최종 Z-Score의 합(qvm) 기준 순위가 1~20인 경우는 투자 종목에 해당하므로 ‘Y’, 그렇지 않으면 ’N’으로 표시합니다.\n\n최종 선택된 종목들을 보면 전반적으로 퀄리티가 높고, 밸류에이션이 낮으며, 최근 수익률이 높습니다. 물론 특정 팩터(예: 모멘텀)가 좋지 않아도 다른 팩터(예: 밸류)가 지나치게 좋아 선택되는 경우도 있습니다. 이제 선택된 종목들과 그렇지 않은 종목들간의 특성을 그림으로 표현해보겠습니다.\n\ndata_bind %>%\n  select(ROE, GPA, CFO, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = min_rank(desc(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n퀄리티 지표가 포함된 데이터를 선택한다.\n각 지표(name)별 그룹을 묶은 후 순위를 계산합니다.\n그림으로 나타냅니다.\n\n붉은색 ▲ 마크는 투자하는 종목, 회색 ● 마크는 투자하지 않는 종목입니다. 전반적으로 멀티팩터 기준으로 선정된 종목들의 퀄리티 순위가 높음을 알 수 있습니다.\n이번에는 동일한 방법으로 밸류 지표의 차이를 살펴보겠습니다.\n\ndata_bind %>%\n  select(DY, PBR, PER, PCR, PSR, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = \n           ifelse(name == 'DY', min_rank(desc(value)), min_rank(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n밸류 지표 역시 멀티팩터 기준으로 선정된 종목들의 순위가 높습니다. 그러나 사용되는 지표가 많은 만큼 일부 지표에서는 순위가 낮은 종목들이 선정되기도 합니다.\n이번에는 모멘텀 지표의 차이를 살펴보겠습니다.\n\ndata_bind %>%\n  select(ret, k_ratio, invest) %>%\n  na.omit() %>%\n  pivot_longer(-invest) %>%\n  group_by(name) %>%\n  mutate(rank = min_rank(desc(value))) %>%\n  ggplot(aes(x = rank, y = 1, shape = invest, color = invest, alpha = invest)) +\n  geom_point(size = 3) +\n  scale_color_manual(values=c(\"grey\", \"red\")) +\n  facet_grid(name~.) \n\nWarning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n모멘텀 지표 역시 멀티팩터 기준으로 선정된 종목들의 순위가 높습니다.\n이처럼 멀티팩터 기준으로 종목을 선정할 경우 각 팩터가 골고루 좋은 종목을 선택할 수 있습니다. 이 외에도 팩터를 만들 수 있는 기본 데이터가 모두 있으므로 최근 적자기업 제외, 매출 증가 등 다양한 전략을 추가할 수도 있습니다."
  },
  {
    "objectID": "backtest.html#return.portfolio-함수",
    "href": "backtest.html#return.portfolio-함수",
    "title": "8  백테스트 실습하기",
    "section": "8.1 Return.Portfolio() 함수",
    "text": "8.1 Return.Portfolio() 함수\n프로그래밍을 이용해 백테스트할 때 전략이 단순하다면 단 몇 줄만으로도 테스트가 가능합니다. 그러나 전략이 복잡해지거나 적용해야 할 요소가 많아질 경우, 패키지를 이용하는 것이 효율적인 방법입니다.\nPerformanceAnalytics 패키지의 Return.portfolio() 함수는 백테스트를 수행하는데 가장 대중적으로 사용되는 함수입니다. 해당 함수의 가장 큰 장점은 각 자산의 수익률과 리밸런싱 비중만 있으면 백테스트 수익률, 회전율 등을 쉽게 계산할 수 있으며, 리밸런싱 시점과 수익률의 시점이 일치하지 않아도 된다는 점입니다. 즉, 수익률 데이터는 일간, 리밸런싱 시점은 분기 혹은 연간으로 된 경우에도 매우 쉽게 백테스트를 수행할 수 있습니다.\n\n8.1.1 인자 목록 살펴보기\n먼저 Return.portfolio() 함수는 다음과 같은 형태로 구성되어 있습니다.\n\nReturn.portfolio(R, weights = NULL, wealth.index = FALSE,\n  contribution = FALSE, geometric = TRUE,\n  rebalance_on = c(NA, \"years\", \"quarters\", \n                   \"months\", \"weeks\", \"days\"),\n  value = 1, verbose = FALSE, ...)\n\n\n\n\n\n\n\n\n인자\n내용\n\n\n\n\nR\n\n\n\n각 자산 수익률 데이터\n\n\n\nweights\n리밸런싱 시기의 자산별 목표 비중. 미 입력시 동일비중 포트폴리오를 가정해 백테스트가 이루어짐\n\n\nwealth.index\n포트폴리오 시작점이 1인 wealth index에 대한 생성 여부이며, 디폴트는 FALSE로 설정\n\n\ncontribution\n포트폴리오 내에서 자산별 성과기여를 나타내는지에 대한 여부이며, 디폴트는 FALSE로 설정\n\n\ngeometric\n포트폴리오 수익률 계산시 복리(기하)수익률 적용 여부이며, 디폴트는 TRUE로서 복리수익률을 계산\n\n\nrebalance_on\nweight 값이 미입력 혹은 매번 같은 비중일 경우, 리밸런싱 주기를 선택할 수 있음\n\n\nvalue\n초기 포트폴리오 가치를 의미하며, 디폴트는 1\n\n\nverbose\n부가적인 결과를 표시할지에 대한 여부. 디폴트인 FALSE를 입력하면 포트폴리오 수익률만이 시계열 형태로 계산되며, TRUE를 입력하면 수익률 외에 자산 별 성과기여, 비중, 성과 등이 리스트 형태로 계산됨\n\n\n\n이 중 가장 중요한 인자는 개별 자산의 수익률인 R과 리밸런싱 시기의 자산별 목표 비중인 weights입니다. 매 리밸런싱 시점마다 적용되는 자산별 비중이 동일할 경우(예: 매월 말 60%대 40% 비중으로 리밸런싱) 상수 형태로 입력해도 되지만, 시점마다 자산별 목표비중이 다를 경우 weights는 시계열 형태로 입력되어야 합니다.\n목표 비중을 시계열 형태로 입력할 때 주의해야 할 점은 다음과 같습니다.\n\n시계열 형태로 인식할 수 있도록 행 이름 혹은 인덱스가 날짜 형태로 입력되어야 합니다.\n수익률 데이터와 비중 데이터의 열 개수는 동일해야 하며, 각 열에 해당하는 자산은 동일해야 합니다. 즉, 수익률 데이터의 첫 번째 열에 A주식 데이터가 있다면, 비중 데이터의 첫 번째 열도 A주식의 목표 비중을 입력해야 합니다.\n각 시점의 비중의 합은 1이 되어야 합니다. 그렇지 않을 경우 제대로 된 수익률이 계산되지 않습니다.\n\nweights에 값을 입력하지 않을 경우 동일비중 포트폴리오를 구성하며, 포트폴리오 리밸런싱은 하지 않습니다.\n\n\n8.1.2 출력값 살펴보기\n해당 함수는 verbose 인자를 TRUE로 설정하면 다양한 결괏값을 리스트 형태로 반환합니다.\n\n\n\n\n\n\n\n결과\n내용\n\n\n\n\nreturns\n포트폴리오 수익률\n\n\ncontribution\n일자별 개별 자산의 포트폴리오 수익률 기여도\n\n\nBOP.Weight\n일자별 개별 자산의 포트폴리오 내 비중(시작시점). 리밸런싱이 없을 시 직전 기간 EOP.Weight와 동일\n\n\nEOP.Weight\n일자별 개별 자산의 포트폴리오 내 비중(종료시점)\n\n\nBOP.Value\n일자별 개별 자산의 가치(시작시점). 리밸런싱이 없을 시 직전 기간 EOP.Value와 동일\n\n\nEOP.Value\n일자별 개별 자산의 가치(종료시점)"
  },
  {
    "objectID": "backtest.html#전통적인-60대-40-포트폴리오-백테스트",
    "href": "backtest.html#전통적인-60대-40-포트폴리오-백테스트",
    "title": "8  백테스트 실습하기",
    "section": "8.2 전통적인 60대 40 포트폴리오 백테스트",
    "text": "8.2 전통적인 60대 40 포트폴리오 백테스트\nReturn.portfolio() 함수의 가장 간단한 예제로서 전통적인 60대 40 포트폴리오를 백테스트합니다. 해당 포트폴리오는 주식과 채권에 각각 60%와 40%를 투자하며, 특정 시점마다 해당 비중을 맞춰주기 위해 리밸런싱을 수행합니다. 매해 말 리밸런싱을 가정하는 예제를 살펴보겠습니다.\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\nlibrary(magrittr)\nticker = c('SPY', 'TLT')\ngetSymbols(ticker)\n\n[1] \"SPY\" \"TLT\"\n\nprices = do.call(cbind,\n                 lapply(ticker, function(x) Ad(get(x))))\nrets = Return.calculate(prices) %>% na.omit()\n\n글로벌 자산의 ETF 데이터 중 주식(S&P 500)과 채권(미국 장기채)에 해당하는 데이터를 다운로드한 후 수익률을 계산합니다.\n\ncor(rets)\n\n             SPY.Adjusted TLT.Adjusted\nSPY.Adjusted    1.0000000   -0.3731717\nTLT.Adjusted   -0.3731717    1.0000000\n\n\ncor() 함수를 통해 두 자산간의 상관관계를 확인해보면 매우 낮은 상관관계를 보이며, 강한 분산효과를 기대해볼 수 있습니다.\n\nportfolio = Return.portfolio(R = rets,\n                             weights = c(0.6, 0.4),\n                             rebalance_on = 'years',\n                             verbose = TRUE)\n\nReturn.portfolio() 함수를 이용하여 백테스트를 실행합니다.\n\n자산의 수익률인 R에는 수익률 테이블인 rets를 입력합니다.\n리밸런싱 비중인 weights에는 60%와 40%를 의미하는 c(0.6, 0.4)를 입력합니다.\n리밸런싱 시기인 rebalance_on에는 연간 리밸런싱에 해당하는 years를 입력합니다. 리밸런싱 주기는 이 외에도 quarters, months, weeks, days도 입력이 가능합니다.\n결과물들을 리스트로 확인하기 위해 verbose를 TRUE로 설정합니다.\n\n위 과정을 통해 주식과 채권 투자비중을 매해 60%와 40%로 리밸런싱하는 포트폴리오의 백테스트가 실행됩니다. 아래 표는 함수 내에서 포트폴리오의 수익률이 어떻게 계산되는지를 요약한 과정입니다.\n\n\n\n\n\n\n\nReturn.portfolio() 계산 과정\n \n\n\n시작금액\n시작합계\n시작비중\n수익률\n종료금액\n종료합계\n종료비중\n최종수익률\n\n  \n      \n    1.주식 \n    2.채권 \n    3.1+2 \n    4.주식 \n    5.채권 \n    6.주식 \n    7.채권 \n    8.주식 \n    9.채권 \n    10.8+9 \n    11.주식 \n    12.채권 \n    13.최종 \n  \n \n\n  \n    2017-12-26 \n    1.603 \n    0.940 \n    2.543 \n    0.630 \n    0.370 \n    -0.001 \n    0.003 \n    1.601 \n    0.943 \n    2.544 \n    0.629 \n    0.371 \n    0.000 \n  \n  \n    2017-12-27 \n    1.601 \n    0.943 \n    2.544 \n    0.629 \n    0.371 \n    0.000 \n    0.013 \n    1.602 \n    0.956 \n    2.557 \n    0.626 \n    0.374 \n    0.005 \n  \n  \n    2017-12-28 \n    1.602 \n    0.956 \n    2.557 \n    0.626 \n    0.374 \n    0.002 \n    -0.001 \n    1.605 \n    0.955 \n    2.560 \n    0.627 \n    0.373 \n    0.001 \n  \n  \n    2017-12-29 \n    1.605 \n    0.955 \n    2.560 \n    0.627 \n    0.373 \n    -0.004 \n    0.002 \n    1.599 \n    0.956 \n    2.555 \n    0.626 \n    0.374 \n    -0.002 \n  \n  \n    2018-01-02 \n    1.533 \n    1.022 \n    2.555 \n    0.600 \n    0.400 \n    0.007 \n    -0.011 \n    1.544 \n    1.011 \n    2.555 \n    0.604 \n    0.396 \n    0.000 \n  \n  \n    2018-01-03 \n    1.544 \n    1.011 \n    2.555 \n    0.604 \n    0.396 \n    0.006 \n    0.005 \n    1.554 \n    1.016 \n    2.570 \n    0.605 \n    0.395 \n    0.006 \n  \n  \n    2018-01-04 \n    1.554 \n    1.016 \n    2.570 \n    0.605 \n    0.395 \n    0.004 \n    0.000 \n    1.560 \n    1.016 \n    2.576 \n    0.606 \n    0.394 \n    0.002 \n  \n\n\n\n\n\n먼저 2017-12-27에 해당하는 데이터를 보면 시작시점에 주식과 채권에는 각각 1.601과 0.943이 투자되어 있으며, 이를 합하면 2.544이 됩니다. 이를 포트폴리오 내 비중으로 환산하면 비중은 각각 0.629와 0.371가 됩니다.\n해당일의 주식과 채권의 수익률은 각각 0, 0.013이 되며, 이를 시작금액에 곱하면 종료시점의 금액은 1.602와 0.956이 됩니다. 각각의 금액을 종료금액의 합인 2.557로 나누게 되면, 포트폴리오 내 비중은 0.626, 0.374로 변하게 됩니다. 포트폴리오 수익률은 2017-12-27 포트폴리오 금액인 2.557을 전일의 포트폴리오 금액인 2.544로 나누어 계산된 값인 0.005가 됩니다.\n리밸런싱이 없다면 2017-12-27일의 종료금액과 종료비중은 다음 날인 2017-12-28의 시작금액과 시작비중에 그대로 적용되며, 위와 동일한 단계를 통해 포트폴리오 수익률이 계산됩니다.\n그러나 매해 리밸런싱을 가정했으므로, 첫 영업일인 2018-01-02에는 포트폴리오 리밸런싱이 이루어집니다. 따라서 전일 2017-12-29의 종료금액의 합인 2.555를 사전에 정의한 0.6과 0.4에 맞게 각 자산을 시작시점에 매수 혹은 매도하게 됩니다. 이후에는 기존과 동일하게 해당일의 수익률을 곱해 종료시점의 금액과 비중을 구한 후 포트폴리오 수익률을 계산하게 됩니다.\n리밸런싱 전일 종료시점의 비중과 리밸런싱 당일 시작시점의 비중 차이의 절대값을 합하면, 포트폴리오의 회전율을 계산할 수도 있습니다. 해당 예제에서는 2017-12-29 종료시점의 비중인 0.626, 0.374와 2018-01-02 시작시점의 비중인 0.6, 0.4의 차이인 0.026, -0.026의 절대값의 합계인 0.052가 회전율이 됩니다.\n이처럼 리밸런싱을 원하는 시점과 비중을 정의하면, Return.portfolio() 함수 내에서는 이러한 단계를 거쳐 포트폴리오의 수익률, 시작과 종료시점의 금액 및 비중이 계산되며, 이를 응용하여 회전율을 계산할 수도 있습니다.\n\nportfolios = cbind(rets, portfolio$returns) %>%\n  setNames(c('주식', '채권', '60대 40'))\n\ncharts.PerformanceSummary(portfolios,\n                          main = '60대 40 포트폴리오')\n\n\n\n\n\n\n\n\nPerformanceAnalytics 패키지의 charts.PerformanceSummary() 함수는 기간별 수익률을 입력 시 누적수익률, 일별 수익률, 드로우다운(낙폭) 그래프를 자동으로 그려줍니다.\n그래프는 색으로 구분되어 각각 주식 수익률(SPY), 채권 수익률(TLT), 60대 40 포트폴리오 수익률을 나타냅니다. 주식과 채권은 상반되는 움직임을 보이며 상승하며, 분산 투자 포트폴리오는 각 개별 자산에 비해 훨씬 안정적인 수익률을 보입니다.\n\nturnover = xts(\n  rowSums(abs(portfolio$BOP.Weight -\n                timeSeries::lag(portfolio$EOP.Weight)),\n          na.rm = TRUE),\n  order.by = index(portfolio$BOP.Weight))\n\nchart.TimeSeries(turnover)\n\n\n\n\n\n\n\n\n전일 종료시점의 비중인 EOP.Weight를 lag() 함수를 이용해 한 단계씩 내린 후 시작시점의 비중인 BOP.Weight와의 차이의 절댓값을 더해주면 해당 시점에서의 회전율이 계산됩니다. lag() 함수의 경우 dplyr 패키지에도 동일한 이름의 함수가 있으므로, 충돌을 방지하기 위해 timeSeries 패키지의 함수임을 선언해줍니다. 이를 xts() 함수를 이용해 시계열 형태로 만든 후 chart.TimeSeries() 함수를 이용해 그래프로 나타내줍니다.\n리밸런싱 시점에 해당하는 매해 첫 영업일에 회전율이 발생하며, 그렇지 않은 날은 매수 혹은 매도가 없으므로 회전율 역시 0을 기록합니다. 2008년에는 주식과 채권의 등락폭이 심했으므로 이듬해엔 2009년 리밸런싱으로 인한 회전율이 심하지만, 이를 제외한 해는 회전율이 그리 심하지 않습니다."
  },
  {
    "objectID": "backtest.html#마켓-타이밍-전략-백테스트",
    "href": "backtest.html#마켓-타이밍-전략-백테스트",
    "title": "8  백테스트 실습하기",
    "section": "8.3 마켓 타이밍 전략 백테스트",
    "text": "8.3 마켓 타이밍 전략 백테스트\n이전 테스트가 리밸런싱 시점별 비중이 60%와 40%로 고정되어 있었다면, 이번에는 시점별 비중이 다른 형태의 예제를 살펴보겠습니다.\n메브 파버(Meb Faber)는 본인의 논문을 통해, 시점 선택(Market Timing) 전략을 사용할 경우 단순 매수 후 보유 대비 극심한 하락장에서 낙폭을 줄일 수 있으며, 이로 인해 위험 대비 수익률을 올릴 수 있다고 설명합니다. 논문에서 말하는 시점 선택의 투자 규칙은 다음과 같습니다.\n\\[주가 > 10개월\\,이동평균 \\to 매수\\] \\[주가 < 10개월\\,이동평균 \\to 매도\\,및\\,현금\\,보유\\]\n해당 규칙을 미국 S&P 500에 적용하는 예제를 살펴보겠습니다. 현재 주식 가격이 과거 10개월 주식 가격의 단순 평균 대비 이상이면 매수, 그렇지 않으면 전량 매도 후 현금을 보유하는 전략이며, 리밸런싱은 매월 실행합니다.\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\n\nsymbols = c('SPY', 'SHY')\ngetSymbols(symbols, src = 'yahoo')\n\n[1] \"SPY\" \"SHY\"\n\nprices = do.call(cbind,\n                 lapply(symbols, function(x) Ad(get(x))))\nrets = Return.calculate(prices) %>% na.omit\n\n먼저 주식과 현금에 해당하는 ETF 데이터를 다운로드합니다. 주식에 해당하는 ETF로 는 S&P 500 수익률을 추종하는 SPY를 사용하며, 현금에 해당하는 ETF로는 미국 단기채 수익률을 추종하는 SHY를 사용합니다.\n\nwts = list()\nlookback = 10\n\nep = endpoints(rets, on = 'months')\nprint(ep)\n\n  [1]    0   19   38   60   80  102  123  144  167  186  209  230  250  271  291\n [16]  311  333  354  375  397  418  439  462  481  503  523  542  564  585  605\n [31]  627  649  670  691  713  733  755  774  793  816  837  857  879  900  922\n [46]  943  964  985 1007 1027 1046 1069 1089 1110 1132 1152 1175 1196 1217 1238\n [61] 1259 1279 1299 1321 1341 1363 1384 1405 1428 1447 1468 1489 1509 1530 1549\n [76] 1569 1591 1613 1633 1655 1677 1697 1720 1740 1761 1782 1801 1822 1843 1864\n [91] 1885 1907 1928 1949 1972 1991 2013 2033 2052 2074 2095 2115 2137 2159 2180\n[106] 2201 2223 2243 2265 2284 2304 2326 2347 2368 2390 2410 2433 2454 2475 2496\n[121] 2517 2537 2556 2579 2598 2620 2642 2662 2685 2705 2727 2748 2768 2789 2808\n[136] 2829 2850 2872 2893 2914 2937 2956 2979 3000 3019 3040 3059 3080 3101 3123\n[151] 3143 3165 3187 3207 3230 3250 3271 3292 3311 3333 3354 3374 3396 3418 3439\n[166] 3460 3482 3502 3524 3543 3562 3585 3606 3626 3648 3669 3691 3712 3733 3754\n[181] 3776 3796 3815 3838 3858 3879 3900 3920 3943 3964 3985 4006 4027 4038\n\n\n각 시점별 비중이 입력될 wts를 공백의 리스트 형식으로 저장해주며, n개월 이동평균값에 해당하는 lookback 변수는 10을 입력합니다.\nxts 패키지의 endpoints() 함수를 이용해 매월 말일의 위치를 구합니다. 해당 함수는 endpoints(x, on= 'months', k=1)의 형태로 이루어지며 x는 시계열 데이터, on은 원하는 기간, k는 구간 길이를 의미합니다. 즉, 시계열 데이터에서 월말에 해당하는 부분의 위치를 반환하며, 매월이 아닌 weeks, quarters, years도 입력이 가능합니다. 결과적으로 ep에는 rets의 인덱스 중 매월 말일에 해당하는 부분의 위치가 구해집니다.\n\nrets[ep] %>% head()\n\n            SPY.Adjusted  SHY.Adjusted\n2007-01-31  0.0067236486  0.0011246135\n2007-02-28  0.0102514789 -0.0007453530\n2007-03-30  0.0002115764  0.0000000000\n2007-04-30 -0.0082925917  0.0007468093\n2007-05-31 -0.0010424323 -0.0006236709\n2007-06-29  0.0003326170  0.0020005636\n\n\n이를 이용해 월말 지점만 뽑을 수도 있습니다.\n\ni = lookback + 1\nsub_price = prices[ep[i-lookback] : ep[i] , 1]\n\nhead(sub_price, 3)\n\n           SPY.Adjusted\n2007-01-03     103.4001\n2007-01-04     103.6195\n2007-01-05     102.7930\n\ntail(sub_price, 3)\n\n           SPY.Adjusted\n2007-10-26     113.8292\n2007-10-29     114.2071\n2007-10-30     113.4143\n\nsma = mean(sub_price)\n\nwt = rep(0, 2)\nwt[1] = ifelse(last(sub_price) > sma, 1, 0)\nwt[2] = 1 - wt[1]\nwts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n\n해당 전략은 for loop 구문을 통해, 매월 말 과거 10개월 이동평균을 구한 후 매수 혹은 매도를 선택한 후 비중을 계산합니다. 예시를 위해 첫 번째 시점의 테스트 과정을 살펴보며, 과거 10개월에 해당하는 가격의 이동평균이 필요하므로 처음 시작은 i+1 인 11부터 가능합니다.\n\n주가는 일별 데이터이며, 현재부터 과거 10개월에 해당하는 주가를 선택해야 합니다. 앞서 endpoints() 함수를 통해 주가에서 월말 기준점의 위치를 찾았으며, ep[i]는 현재시점 주가의 위치를, ep[i-lookback]는 현재부터 10개월 전 주가 위치를 의미합니다. 이를 통해 과거 10개월 간 주가를 찾은 후 sub_price에 저장합니다.\nmean()을 통해 10개월 주가의 평균을 계산합니다.\nrep(0, 2)를 통해 비중이 들어갈 0벡터를 생성합니다.\nifelse() 구문을 통해 해당 전략의 조건에 맞는 비중을 계산합니다. wt[1]은 주식의 투자비중이며, 만일 현재 주가가 10개월 이동평균보다 클 경우 주식에 해당하는 비중은 1을, 그렇지 않을 경우 0을 부여합니다. wt[2]는 현금의 투자비중이며, 1에서 주식의 투자비중을 뺀 값을 입력합니다. 아래 표에는 해당 규칙이 요약되어 있습니다.\n위에서 만들어진 벡터를 xts()를 통해 시계열 형태로 바꾼 후, wts의 i번째 리스트에 저장해줍니다.\n\n\n\n\n\n\n\n\n\n자산\n현재주가 > 10개월 이동평균\n현재 주가 < 10개월 이동평균\n\n\n\n\n주식비중\nwt[1] = 1\nwt[1] = 0\n\n\n현금비중\nwt[2] = 0\nwt[2] = 1\n\n\n\n위 과정을 for loop 구문을 통해 전체 기간에 적용한 백테스트는 다음과 같습니다.\n\nep = endpoints(rets, on = 'months')\nwts = list()\nlookback = 10\n\nfor (i in (lookback+1) : length(ep)) {\n  sub_price = prices[ep[i-lookback] : ep[i] , 1]\n  sma = mean(sub_price)\n  wt = rep(0, 2)\n  wt[1] = ifelse(last(sub_price) > sma, 1, 0)\n  wt[2] = 1 - wt[1]\n  \n  wts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n}\n\nwts = do.call(rbind, wts)\n\n매월 말 과거 10개월 이동평균을 구한 후 현재 주가와 비교해 주식 혹은 현금 투자비중을 구한 후 wts 리스트에 저장합니다. 그 후 do.call() 함수를 통해 리스트를 테이블로 묶어줍니다.\n수익률 데이터와 비중 데이터가 구해졌으므로 Return.portfolio() 함수를 통해 포트폴리오의 수익률을 계산합니다.\n\nTactical = Return.portfolio(rets, wts, verbose = TRUE)\nportfolios = na.omit(cbind(rets[,1], Tactical$returns)) %>%\n  setNames(c('매수 후 보유', '시점 선택 전략'))\n\ncharts.PerformanceSummary(portfolios,\n                          main = \"Buy & Hold vs Tactical\")\n\n\n\n\n\n\n\n\n\n수익률 데이터와 비중 데이터의 입력을 통해 백테스트를 실행합니다.\ncbind() 함수를 통해 SPY 데이터와 포트폴리오 수익률을 합쳐줍니다. 시점 선택 포트폴리오의 경우 lookback 기간인 초기 10개월에 대한 수익률이 없어 NA로 표시되므로 na.omit()을 통해 해당 부분을 제거합니다.\ncharts.PerformanceSummary() 함수를 통해 수익률을 그래프로 나타냅니다.\n\n검은색 그래프는 S&P 500 에 매수 후 보유 시 수익률이고, 주황색 그래프는 시점 선택 전략을 적용한 수익률입니다. 2008년과 같은 하락장에서 낙폭이 훨씬 낮음이 확인됩니다.\n\nturnover = xts(rowSums(abs(Tactical$BOP.Weight -\n                             timeSeries::lag(Tactical$EOP.Weight)),\n                       na.rm = TRUE),\n               order.by = index(Tactical$BOP.Weight))\n\nchart.TimeSeries(turnover)\n\n\n\n\n\n\n\n\n해당 전략의 회전율을 확인해보면, 몇 년간 매매가 없는 경우도 있습니다. 그러나 매매가 발생할 시 매수와 매도 포지션 양쪽의 매매로 인해 200%의 회전율이 발생하게 됩니다."
  },
  {
    "objectID": "backtest.html#동적-자산배분-백테스트",
    "href": "backtest.html#동적-자산배분-백테스트",
    "title": "8  백테스트 실습하기",
    "section": "8.4 동적 자산배분 백테스트",
    "text": "8.4 동적 자산배분 백테스트\n마지막으로 기존에 배웠던 것들을 응용해 동적 자산배분의 백테스트를 수행하겠습니다. 일반적인 자산배분이 주식과 채권, 대체자산에 투자비중을 사전에 정해놓고 약간의 비율만 수정하는 정적 자산배분인 반면, 동적 자산배분이란 투자비중에 대한 제한이 없이 동적으로 포트폴리오를 구성하는 방법입니다.\n동적 자산배분을 이용한 포트폴리오는 다음과 같이 구성됩니다.\n\n글로벌 10개 자산 중 과거 12개월 수익률이 높은 5개 자산을 선택합니다.\n최소분산 포트폴리오를 구성하며, 개별 투자비중은 20%로 합니다.\n매월 리밸런싱을 실시합니다.\n\n\nlibrary(quantmod)\nlibrary(PerformanceAnalytics)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nsymbols = c('SPY', # 미국 주식\n            'IEV', # 유럽 주식 \n            'EWJ', # 일본 주식\n            'EEM', # 이머징 주식\n            'TLT', # 미국 장기채\n            'IEF', # 미국 중기채\n            'IYR', # 미국 리츠\n            'RWX', # 글로벌 리츠\n            'GLD', # 금\n            'DBC'  # 상품\n            )\n\ngetSymbols(symbols, src = 'yahoo')\n\n [1] \"SPY\" \"IEV\" \"EWJ\" \"EEM\" \"TLT\" \"IEF\" \"IYR\" \"RWX\" \"GLD\" \"DBC\"\n\nprices = do.call(cbind, lapply(symbols, function(x) Ad(get(x)))) %>%\n  setNames(symbols)\n\nrets = Return.calculate(prices) %>% na.omit()\n\n글로벌 자산을 대표하는 ETF 데이터를 다운로드한후 수정주가의 수익률을 계산합니다.\n\nep = endpoints(rets, on = 'months')\nwts = list()\nlookback = 12\nwt_zero = rep(0, 10) %>% setNames(colnames(rets))\n\n백테스트에 사용되는 각종 값을 사전에 정의합니다.\n\nendpoints() 함수를 통해 매월 말일의 위치를 구합니다.\n매월의 투자비중이 들어갈 빈 리스트를 wts에 설정합니다.\n수익률을 측정할 과거 n기간을 12개월로 설정합니다.\nrep() 함수를 통해 비중이 들어갈 0으로 이루어진 벡터를 만들며 이름을 설정합니다.\n\n다음은 매월 말 투자 규칙에 따라 포트폴리오의 비중을 구하는 백테스트 과정입니다.\n\nfor (i in (lookback+1) : length(ep)) {\n  sub_ret = rets[ep[i-lookback] : ep[i] , ]\n  cum = Return.cumulative(sub_ret)\n  \n  K = rank(-cum) <= 5\n  covmat = cov(sub_ret[, K])\n  \n  wt = wt_zero\n  wt[K] = 0.2\n  \n  wts[[i]] = xts(t(wt), order.by = index(rets[ep[i]]))\n}\n\nwts = do.call(rbind, wts)\n\nfor loop 구문을 통해 매월 말 과거 12개월 수익률을 구한 후 비중을 계산하므로, 처음 시작은 i+1인 13부터 가능합니다.\n\nep[i]는 현재시점 수익률의 위치를, ep[i-lookback]는 현재부터 12개월 전 수익률의 위치를 의미합니다. 이를 통해 과거 12개월 간 수익률을 찾은 후 sub_ret에 저장합니다.\nReturn.cumulative() 함수를 통해 해당 기간의 자산별 누적수익률을 구합니다.\nrank() 함수를 통해 수익률 상위 5개 자산을 선택하며, 내림차순으로 정렬해야하므로 마이너스(-)를 붙여줍니다.\ncov() 함수를 통해 수익률 상위 5개 자산의 분산-공분산 행렬을 구하도록 합니다.\n임시로 비중이 저장될 wt 변수에 위에서 만든 0벡터(wt_zero)를 입력한 후 optimalPortfolio() 함수를 통해 최소분산 포트폴리오를 구성하는 해를 찾습니다. 개별 투자비중의 제한은 최소 10%, 최대 30%를 설정하며, 구해진 해를 wt의 K번째 값에 입력합니다.\n위에서 만들어진 벡터를 xts()를 통해 시계열 형태로 바꾼 후 wts의 i번째 리스트에 저장합니다.\nfor loop 구문이 끝난 후 do.call() 함수를 통해 투자비중이 저장된 리스트를 테이블 형태로 바꿔줍니다.\n\n이를 통해 동적 자산배분의 투자 규칙에 맞는 매월 말 투자비중이 계산되었습니다.\n\nGDAA = Return.portfolio(rets, wts, verbose = TRUE)\ncharts.PerformanceSummary(GDAA$returns, main = '동적자산배분')\n\n\n\n\n\n\n\n\n수익률과 비중 데이터가 있으므로 Return.portfolio() 함수를 통해 백테스트 수익률을 계산할 수 있습니다. charts.PerformanceSummary() 함수를 통해 누적수익률을 확인하면 해당 전략을 이용한 포트폴리오가 꾸준히 우상향하는 모습을 보이게됩니다.\n\nwts %>% fortify.zoo() %>%\n  gather(key, value, -Index) %>%\n  mutate(Index = as.Date(Index)) %>%\n  mutate(key = factor(key, levels = unique(key))) %>%\n  ggplot(aes(x = Index, y = value)) +\n  geom_area(aes(color = key, fill = key),\n            position = 'stack') +\n  xlab(NULL) + ylab(NULL) +  theme_bw() +\n  scale_x_date(date_breaks=\"years\", date_labels=\"%Y\",\n               expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(plot.title = element_text(hjust = 0.5,\n                                  size = 12),\n        legend.position = 'bottom',\n        legend.title = element_blank(),\n        axis.text.x = element_text(angle = 45,\n                                   hjust = 1, size = 8),\n        panel.grid.minor.x = element_blank()) +\n  guides(color = guide_legend(byrow = TRUE))\n\n\n\n\n\n\n\n\n반면 자산별 투자비중의 변화가 많은 것을 알 수 있습니다. 그 원인은 수익률 상위 5개에 해당하는 자산이 매월 말 바뀌며, 최소분산 포트폴리오를 구성하는 비중이 계속해서 바뀌기 때문입니다.\n회전율이 상대적으로 낮았던 기존 백테스트에서는 매매비용, 세금, 기타비용 등을 고려하지 않아도 수익률에 크게 영향이 없지만, 회전율이 상대적으로 높은 전략에서는 이러한 것들을 무시하지 않을 수 없습니다.\n\nGDAA$turnover = xts(\n  rowSums(abs(GDAA$BOP.Weight -\n                timeSeries::lag(GDAA$EOP.Weight)),\n          na.rm = TRUE),\n  order.by = index(GDAA$BOP.Weight))\n\nchart.TimeSeries(GDAA$turnover)\n\n\n\n\n\n\n\n\n기존에 살펴본 방법으로 회전율을 계산한다면 매월 상당한 매매회전이 발생함이 확인됩니다.\n\nfee = 0.0030\nGDAA$net = GDAA$returns - GDAA$turnover*fee\n\n매수 혹은 매도당 발생하는 세금, 수수료, 시장충격 등 총 비용을 0.3%로 가정합니다. 포트폴리오 수익률에서 회전율과 총 비용의 곱을 빼면, 비용 후 포트폴리오의 순수익률이 계산됩니다.\n\ncbind(GDAA$returns, GDAA$net) %>%\n  setNames(c('No Fee', 'After Fee')) %>%\n  charts.PerformanceSummary(main = 'GDAA')\n\n\n\n\n\n\n\n\n기존 비용을 고려하지 않은 포트폴리오(검은색)에 비해, 비용을 차감한 포트폴리오(붉은색)의 수익률이 시간이 지남에 따라 서서히 감소합니다. 이러한 차이는 비용이 크거나 매매회전율이 높을수록 더욱 벌어지게 됩니다."
  },
  {
    "objectID": "performance.html#결과-측정-지표",
    "href": "performance.html#결과-측정-지표",
    "title": "9  성과 및 위험 평가하기",
    "section": "9.1 결과 측정 지표",
    "text": "9.1 결과 측정 지표\n포트폴리오의 평가에서 가장 중요한 지표는 수익률과 위험입니다. 수익률은 누적수익률과 연율화 수익률, 연도별 수익률이 주요 지표이며, 위험은 변동성과 낙폭이 주요 지표입니다.\n이 외에도 승률, 롤링 윈도우 값 등 다양한 지표를 살펴보기도 합니다. 이러한 지표를 수식을 이용해 직접 계산할 수도 있지만, PerformanceAnalytics 패키지에서 제공하는 다양한 함수들을 이용해 편하게 계산할 수 있습니다.\n\n9.1.1 수익률 및 변동성\n\nlibrary(PerformanceAnalytics)\nchart.TimeSeries(price)\n\n\n\n\n\n\n\n\nchart.TimeSeries() 함수를 통해 수익률을 그릴 수 있습니다.\n\nlibrary(ggplot2)\nlibrary(magrittr)\n\nprice %>% fortify.zoo() %>%\n  set_colnames(c('date', 'value')) %>%\n  ggplot(aes(x = date, y = value)) +\n  geom_line()\n\n\n\n\n\n\n\n\n좀 더 섬세한 그래프 작업을 해야할 때는 ggplot() 함수를 이용하면 됩니다.\n\nret = Return.calculate(price)\nchart.CumReturns(ret)\n\n\n\n\n\n\n\n\n만일 수익률로 계산된 경우 chart.CumReturns() 함수를 이용해 누적수익률을 그릴수도 있습니다.\n수익률 중 가장 많이보는 지표는 누적 수익률, 연율화 수익률(산술), 연율화 수익률(기하)입니다. 각 수익률을 구하는 법은 다음과 같습니다.\n\n누적 수익률: \\((1+r_1) \\times (1+r_2) \\times \\dots \\ \\times (1+r_n) - 1 = \\{\\prod_{i=1}^n(1+r_i)\\}-1\\),\n연율화 수익률(산술): \\(\\frac{(r_1 + r_2 + \\dots + r_i)}{n} \\times scale\\)\n연율화 수익률(기하): \\(\\{\\prod_{i=1}^n(1+r_i)\\}^{scale / Days} - 1\\)\n\n먼저 누적수익률은 각 수익률에 1을 더한 값을 모두 곱한 후 1을 빼면 됩니다. 연율화 수익률(산술)은 단순히 수익률의 평균을 구한 후 연율화를 위한 조정값(\\(scale\\))을 곱해주면 됩니다. 데이터가 일간일 경우 조정값은 252, 주간일 경우 52, 월간일 경우 12입니다. 현재 데이터는 월간 기준이므로 조정값은 12가 됩니다. 마지막으로 연율화 수익률(기하)은 각 수익률에 1을 더한 값의 곱을 구한 후 연율화를 위해 승수를 적용한 후 1을 빼주며, Days는 시계열의 관측 기간입니다. 마지막으로 연율화 수익률(기하)의 경우 각 수익률에 1을 더한 값의 곱을 구한 후, 연율화를 위해 승수를 곱한 후 1을 빼주면 되며, \\(Days\\)는 시계열의 관측 기간입니다.\n수식에 맞게 값을 입력해 계산할 수도 있지만, 함수를 이용하면 더욱 손쉽게 계산이 가능하며 실수할 가능성도 줄어듭니다.\n\nReturn.cumulative(ret)\n\n                  BRK-B.Adjusted\nCumulative Return       12.28879\n\n\n누적수익률은 Return.cumulative() 함수를 통해 구할 수 있습니다.\n\nReturn.annualized(ret, geometric = FALSE) # 연율화 수익률(산술)\n\n                  BRK-B.Adjusted\nAnnualized Return      0.1229626\n\nReturn.annualized(ret) # 연율화 수익률(기하)\n\n                  BRK-B.Adjusted\nAnnualized Return      0.1019027\n\n\n연율화 수익률(산술)은 Return.annualized() 함수 내 geometric 인자를 FALSE로 선택해줌으로써, 연율화 수익률(기하)는 Return.annualized() 함수를 통해 계산이 가능합니다.\n위험으로 가장 많이 사용되는 지표는 변동성입니다. 연율화 변동성은 sd() 함수를 통해 변동성을 계산한 후 조정값을 곱해 계산할 수도 있지만, StdDev.annualized() 함수를 사용해 더욱 쉽게 계산할 수도 있습니다.\n\nStdDev.annualized(ret) # 연율화 변동성\n\n                              BRK-B.Adjusted\nAnnualized Standard Deviation      0.2284221\n\n\n수익을 위험으로 나누어 위험 조정 수익률을 보는 지표가 샤프 지수(Sharpe Ratio)입니다. 해당 지수는 \\(\\frac {R_i - R_f}{\\sigma_i}\\)로 계산되며, 분자에는 포트폴리오 수익률에서 무위험 수익률을 차감한 값이, 분모에는 포트폴리오의 변동성이 오게 됩니다.\n\nSharpeRatio.annualized(ret, Rf = 0, geometric = TRUE)\n\n                                BRK-B.Adjusted\nAnnualized Sharpe Ratio (Rf=0%)      0.4461159\n\n\nSharpeRatio.annualized() 함수를 이용하면 포트폴리오 수익률에서 무위험 수익률을 차감한 값을 연율화로 변경한 후 연율화 변동성으로 나누어 샤프 지수를 계산합니다. geometric을 TRUE로 설정하면 기하평균 기준 연율화 수익률을, FALSE로 설정하면 산술평균 기준 연율화 수익률을 계산합니다.\n\ntable.AnnualizedReturns(ret)\n\n                          BRK-B.Adjusted\nAnnualized Return                 0.1019\nAnnualized Std Dev                0.2284\nAnnualized Sharpe (Rf=0%)         0.4461\n\n\n연간 수익률, 변동성, 샤프지수를 한 번에 계산할 경우 table.AnnualizedReturns() 함수를 사용하면 됩니다.\n\n\n9.1.2 낙폭(drawdown)과 최대낙폭(MDD)\n먼저 낙폭(Drawdown)은 수익률이 하락한 후 반등하기 전까지 얼마나 하락했는지를 나타냅니다. 최대낙폭(Maximum Drawdown)은 이러한 낙폭 중 가장 값이 큰 값으로서, 최고점에서 최저점까지 얼마나 손실을 보는지를 나타냅니다. 투자를 함에 있어 수익률이 하락하는 것은 어쩔 수 없지만, 최대낙폭이 지나치게 큰 전략에 투자하는 것은 매우 위험한 선택이 될 수 있습니다.\n\n\n\n\n\nR에서는 각종 낙폭에 대한 지표를 손쉽게 구할 수 있습니다.\n\ntable.Drawdowns(ret, top = 10)\n\n         From     Trough         To   Depth Length To Trough Recovery\n1  2007-12-11 2009-03-05 2013-02-15 -0.5386   1305       310      995\n2  1998-06-22 2000-03-10 2003-11-14 -0.4935   1360       435      925\n3  2020-01-21 2020-03-23 2020-11-16 -0.2957    210        44      166\n4  2022-03-29 2022-10-12       <NA> -0.2658    204       137       NA\n5  2014-12-19 2016-01-25 2016-11-10 -0.1869    478       275      203\n6  1996-05-13 1996-06-03 1997-02-12 -0.1625    192        15      177\n7  2018-10-10 2018-12-24 2019-12-12 -0.1609    296        52      244\n8  2004-04-13 2005-09-21 2006-08-21 -0.1599    595       365      230\n9  2018-02-02 2018-06-27 2018-09-18 -0.1489    158       101       57\n10 1997-06-16 1997-08-29 1998-01-20 -0.1423    151        54       97\n\n\nFrom은 전고점, Trough는 저점, To는 회복지점 입니다. Depth는 하락정도이며, Length, To Trough, Recovery는 낙폭 일수를 나타냅니다. 금융위기때의 경우 최대 53%가 하락했으며, 310일간 하락 및 995일간 회복하여 전고점 회복까지 1305일이 걸렸습니다.\n\nmaxDrawdown(ret)\n\n[1] 0.5386158\n\n\nMDD를 구할때는 maxDrawdown() 함수가 사용됩니다.\n\nchart.Drawdown(ret)\n\n\n\n\n\n\n\n\nchart.Drawdown() 함수를 통해 낙폭 그래프를 그릴수도 있습니다.\n\nlibrary(ggplot2)\nlibrary(magrittr)\n\ndd = Drawdowns(ret)\n\ndd %>% fortify.zoo() %>%\n  set_colnames(c('date', 'value')) %>%\n  ggplot(aes(x = date, y = value)) +\n  geom_line()\n\n\n\n\n\n\n\n\nDrawdowns() 함수를 통해 낙폭을 계산할 수도 있으며, 이 후 ggplot() 함수를 통해 그림을 그릴 수도 있습니다.\n\n\n9.1.3 기타 지표\n\nCalmarRatio(ret)\n\n             BRK-B.Adjusted\nCalmar Ratio      0.1891937\n\n\n칼마 지수(Calmar Ratio)는 연율화 수익률을 최대낙폭으로 나눈 값으로서, 특히나 안정적인 절대 수익률을 추구하는 헤지펀드에서 많이 참조하는 지표입니다.\n\nSortinoRatio(ret)\n\n                         BRK-B.Adjusted\nSortino Ratio (MAR = 0%)      0.0518033\n\n\n소티노 지수(Sortino)는 샤프 지수와 비슷하며, 전체 변동성이 아닌 하락 위험(\\(\\sigma^{downside}\\))을 사용합니다.\n\\[S = \\frac{E(R-R^f)}{\\sigma^{downside}}\\] 하락 위험(또는 하락 편차)은 최소 허용 수익률(MAR) 미만 수익률의 표준편차로 계산됩니다.\n\\[\\sigma^{downside} = \\sigma(R1_{R<MAR})\\] 최소 허용 수익률은 종종 무위험 수익률이나 0으로 설정됩니다. 하락 위험에 사용된 지표 함수 R1{R<MAR}은 수익률이 0보다 작으면 1, 그렇지 않으면 0으로 계산합니다. 따라서 수익률이 최소 허용 수익률보다 높을 때 수익률의 변동은 하락 위험에 영향을 주지 않습니다. 이는 투자자들이 오직 (또는 많은 부분) 하락에만 관심을 갖는다는 가정에 기초합니다. 따라서 소르티노지수는 투자자가 2년 동안 매해 5%를 버는지, 혹은 첫해에는 1%와 이듬해에는 9%를 버는지는 신경 쓰지 않는다고 가정합니다. 반면 샤프지수는 투자자가 전자를 선호한다는 가정을 기반으로 합니다.\n\n\n9.1.4 연도별 수익률\n월별, 분기별, 연도별 수익률을 계산할 때는 apply.*() 함수가 사용됩니다.\n\napply.yearly(ret, Return.cumulative) %>% head()\n\n           BRK-B.Adjusted\n1996-12-31    -0.04137935\n1997-12-31     0.38399285\n1998-12-31     0.52696551\n1999-12-31    -0.22127664\n2000-12-29     0.28633892\n2001-12-31     0.07264227\n\n\napply.yearly() 함수 내 계산 함수를 Return.cumulative로 설정한다면 연도별 수익률을 계산할 수 있습니다.\n\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nR.yr = apply.yearly(ret, Return.cumulative) %>%\n  fortify.zoo() %>%\n  mutate(Index = year(Index)) %>%\n  set_colnames(c('Index', 'value'))\n\nggplot(R.yr, aes(x = Index, y = value)) +\n  geom_bar(position = \"dodge\", stat = \"identity\", fill = 'skyblue') +\n  ggtitle('Yearly Return') +\n  xlab(NULL) +\n  ylab(NULL) +\n  theme_bw() +\n  scale_y_continuous(expand = c(0.03, 0.03)) +\n  scale_x_continuous(breaks = R.yr$Index,\n                     expand = c(0.01, 0.01)) +\n  theme(plot.title = element_text(hjust = 0.5,\n                                  size = 12),\n        legend.position = 'bottom',\n        legend.title = element_blank(),\n        legend.text = element_text(size=7),\n        axis.text.x = element_text(angle = 45,\n                                   hjust = 1, size = 8),\n        panel.grid.minor.x = element_blank() ) +\n  guides(fill = guide_legend(byrow = TRUE)) +\n      geom_text(aes(label = paste(round(value * 100, 2), \"%\"),\n                    vjust = ifelse(value >= 0, -0.5, 1.5)),\n                position = position_dodge(width = 1),\n                size = 3)\n\n\n\n\n\n\n\n\napply.yearly() 함수를 통해 계산한 연도별 수익률에 ggplot() 함수를 응용하면 막대 그래프로 나타낼 수도 있으며, 시각화를 통해 포트폴리오의 수익률 추이가 더욱 쉽게 확인됩니다.\n\n\n9.1.5 승률 및 롤링 윈도우\n승률이란 포트폴리오가 벤치마크 대비 높은 성과를 기록한 비율을 의미하며 다음과 같이 계산됩니다.\n\\[\\frac{(포트폴리오 수익률 > 벤치마크) 일수}{전체 기간}\\]\n벤치마크가 S&P 500 지수, KOSPI 200 지수처럼 구체적으로 존재하는 경우도 있지만, 절대수익을 추구하는 경우에는 이러한 벤치마크가 0 혹은 무위험 수익률이 되기도 합니다.\n\nUpsideFrequency(ret, MAR = 0)\n\n[1] 0.4943436\n\n\nUpsideFrequency() 함수는 벤치마크 대비 승률을 계산해줍니다. MAR 인자는 0이 기본값으로 설정되어 있으며, 원하는 벤치마크가 있을 시 이를 입력해주면 됩니다.\n\nUpsideFrequency(ret %>% apply.monthly(Return.cumulative), MAR = 0)\n\n[1] 0.5607477\n\n\n일간 기준 승률은 노이즈가 많으므로 월간, 혹은 연간으로 계산할 필요도 있습니다. 이번에는 S&P500 대비 승률을 계산해보도록 합니다.\n\ngetSymbols('^GSPC', from = '1996-05-09')\n\n[1] \"^GSPC\"\n\nBM = Ad(GSPC) %>% Return.calculate()\n\nUpsideFrequency(ret, MAR = BM)\n\n[1] 0.4802024\n\nUpsideFrequency(ret %>% apply.yearly(Return.cumulative), MAR = BM %>% apply.yearly(Return.cumulative))\n\n[1] 0.6071429\n\n\nS&P500 수익률에 해당하는 ‘GSPC’ 데이터를 받은 후 수익률을 계산합니다. 이를 버크셔 일간 및 연간 수익률과 비교하여 승률을 구합니다.\n위에서 구한 각종 지표들은 투자자가 포트폴리오의 시작부터 현재까지 투자를 했다는 전제 하에 계산됩니다. 그러나 투자를 시작하는 시점은 사람마다 다르기에, 무작위 시점에 투자했을 때 향후 n개월 후 승률 혹은 연율화 수익률 등을 계산할 필요도 있습니다. 이러한 기법을 롤링 윈도우라고 합니다.\n\nret_m = ret %>% apply.monthly(., Return.cumulative) \n\n먼저 수익률을 월간으로 변경합니다.\n\nroll_12 = ret_m %>% rollapply(., 12, Return.cumulative)\nroll_24 = ret_m %>% rollapply(., 24, Return.cumulative)\nroll_36 = ret_m %>% rollapply(., 36, Return.cumulative)\n\ncbind(roll_12, roll_24, roll_36) %>%\n  UpsideFrequency(na.rm = TRUE)\n\n                            BRK.B.Adjusted BRK.B.Adjusted.1 BRK.B.Adjusted.2\nUpside Frequency (MAR = 0%)      0.7290323        0.8255034        0.9055944\n\n\n롤링 윈도우 승률은 무작위 시점에 투자했을 시 미래 n개월 동안의 누적 수익률을 구하고, 해당 값이 벤치마크 대비 수익이 높았던 비율을 계산합니다. 만일 12개월 롤링 윈도우 승률이 100%라면, 어떠한 시점에 투자해도 12개월 후에는 언제나 벤치마크를 이겼음을 의미합니다. 반면 아무리 누적 수익률이 높은 전략도 이러한 롤링 윈도우 승률이 지나치게 낮다면, 단순히 한 번의 운으로 인해 수익률이 높은 것처럼 보일수 있습니다.\n함수를 이용해 해당 값을 구하는 과정은 다음과 같습니다.\n\napply.*() 함수를 이용해 원하는 기간의 수익률로 변경하며, 위 예제에서는 월간 수익률로 변경했습니다.\nrollapply() 함수를 통해 원하는 기간의 롤링 윈도우 통곗값을 구해줍니다. 각각 12개월, 24개월, 36개월 기간에 대해 연율화 수익률을 계산해줍니다.\n값들을 묶어준 후 UpsideFrequency() 함수를 통해 승률을 계산합니다.\n\n해당 과정을 통해 계산된 12개월, 24개월, 36개월 롤링 승률을 사려보면, 투자 기간이 길어질수록 승률이 높아집니다. 이번에는 시각화로 나타내보겠습니다.\n\ncbind(roll_12, roll_24, roll_36) %>%\n  fortify.zoo() %>%\n  set_colnames(c('date', '12', '24', '36')) %>%\n  pivot_longer(names_to = 'period', values_to = 'return', -date) %>%\n  ggplot(aes(x = date, y = return, color = period)) + \n  geom_line(size = 1.3) +\n  geom_hline(aes(yintercept = 0), color = 'black')"
  },
  {
    "objectID": "performance.html#팩터-회귀분석",
    "href": "performance.html#팩터-회귀분석",
    "title": "9  성과 및 위험 평가하기",
    "section": "9.2 팩터 회귀분석",
    "text": "9.2 팩터 회귀분석\n포트폴리오 수익률에 대한 성과 평가만큼 중요한 것이, 수익률이 어디에서 발생했는가에 대한 요인을 분석하는 것입니다. 베타를 통한 개별 주식과 주식시장과의 관계를 시작으로, 수익률을 설명하기 위한 여러 모형들이 개발되고 발표되었습니다. 그중 일반적으로 많이 사용되는 모형은 기존의 CAPM에 사이즈 팩터(SMB), 밸류 팩터(HML)를 추가한 파마-프렌치의 3팩터 모형, 그리고 3팩터 모형에 모멘텀 팩터(UMD)를 추가한 카하트의 4팩터 모형입니다.\n\\[R - R_f= \\alpha +  \\beta_m \\times \\ [R_m - R_f] + \\beta_{SMB} \\times R_{SMB} + \\beta_{HML} \\times R_{HML} + \\beta_{UMD} \\times R_{UMD}\\]\n위 수식에 맞게 회귀분석을 실시하며, 이를 위해 4팩터 데이터를 다운받습니다.\n\nlibrary(frenchdata)\n\nff_three = download_french_data('Fama/French 3 Factors')\nff_mom = download_french_data('Momentum Factor (Mom)')\n\nff = ff_three$subsets$data[[1]] %>%\n  inner_join(ff_mom$subsets$data[[1]]) %>%\n  mutate(date = as.character(date)) %>%\n  mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n  mutate(across(-date, ~. / 100)) \n\nret_bind = ret_m %>%\n  fortify.zoo() %>%\n  set_colnames(c('date', 'ri')) %>%\n  mutate(date = as.Date(as.yearmon(date, \"%Y%m\"), frac = 1)) %>%\n  inner_join(ff) %>%\n  mutate(r_excess = ri - RF)\n\n\n쓰리팩터와 모멘텀 데이터를 받습니다.\ndate가 yyyymm으로 되어있으므로 yyyy-mm-dd로 변경하며 월말 데이터로 바꿉니다.\ndate 열을 제외한 열이 퍼센트 데이터이므로 100으로 나눕니다.\n버크셔 수익률 역시 클렌징 처리를 한 후 두 데이터를 합칩니다.\n버크셔 수익률에서 무위험 수익률을 빼 초과수익률을 계산합니다.\n\n\nreg = lm(r_excess ~ `Mkt-RF` + SMB+ HML + Mom, data = ret_bind)\n\nsummary(reg)\n\n\nCall:\nlm(formula = r_excess ~ `Mkt-RF` + SMB + HML + Mom, data = ret_bind)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.125098 -0.027838 -0.004936  0.022913  0.184605 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.003036   0.002447   1.240    0.216    \n`Mkt-RF`     0.710336   0.056438  12.586  < 2e-16 ***\nSMB         -0.508077   0.076659  -6.628 1.48e-10 ***\nHML          0.443402   0.073921   5.998 5.48e-09 ***\nMom          0.012662   0.051984   0.244    0.808    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0427 on 314 degrees of freedom\nMultiple R-squared:  0.428, Adjusted R-squared:  0.4208 \nF-statistic: 58.75 on 4 and 314 DF,  p-value: < 2.2e-16\n\n\nlm() 함수를 통해 회귀분석을 수행합니다. 베타의 절댓값이 크다는 의미는 수익률이 해당 팩터와의 관계가 높다는 의미이며, 양수일 경우에는 양의 관계가, 음수일 경우에는 음의 관계가 높다는 의미입니다. 또한 t값 혹은 P값을 통해 관계가 얼마나 유의한지도 확인할 수 있습니다.\n\n시장 베타에 해당하는 \\(\\beta_m\\)은 1보다 낮습니다. 즉 시장과의 관계가 낮다고 볼 수 있습니다. 또한 t값이 충분히 유의합니다.\n사이즈 베타에 해당하는 \\(\\beta_{SMB}\\)는 음수입니다. 즉 소형주보다 대형주 수익률과 관계가 있습니다. t값 역시 충분히 유의힙니다.\n밸류 베타에 해당하는 \\(\\beta_{HML}\\)은 양수입니다. 즉 가치주 수익률과 관계가 있습니다. t값 역시 충분히 유의합니다.\n모멘텀 베타에 해당하는 \\(\\beta_{Mom}\\)의 t밸류는 매우 작아 유의하지 않습니다.\n이를 제외한 알파의 t값은 유의하지 않습니다. 즉 기존의 팩터로 모든 수익률의 설명이 가능합니다.\n\n\nlibrary(broom)\ntidy(reg)\n\n# A tibble: 5 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.00304   0.00245     1.24  2.16e- 1\n2 `Mkt-RF`     0.710     0.0564     12.6   1.09e-29\n3 SMB         -0.508     0.0767     -6.63  1.48e-10\n4 HML          0.443     0.0739      6.00  5.48e- 9\n5 Mom          0.0127    0.0520      0.244 8.08e- 1\n\n\nbroom 패키지의 tidy() 함수를 사용하면 분석 결과 중 계수에 해당하는 값만을 요약해서 볼 수 있습니다.\n\nlibrary(stargazer)\nstargazer(reg, type = 'text', out = 'reg_table.html')\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                             r_excess          \n-----------------------------------------------\n`Mkt-RF`                     0.710***          \n                              (0.056)          \n                                               \nSMB                          -0.508***         \n                              (0.077)          \n                                               \nHML                          0.443***          \n                              (0.074)          \n                                               \nMom                            0.013           \n                              (0.052)          \n                                               \nConstant                       0.003           \n                              (0.002)          \n                                               \n-----------------------------------------------\nObservations                    319            \nR2                             0.428           \nAdjusted R2                    0.421           \nResidual Std. Error      0.043 (df = 314)      \nF Statistic           58.747*** (df = 4; 314)  \n===============================================\nNote:               *p<0.1; **p<0.05; ***p<0.01\n\n\nstargazer 패키지를 사용하면, 회귀분석 결과를 논문에서 많이 사용되는 테이블 형식으로 손쉽게 출력과 저장을 할 수 있습니다.테이블이 출력과 함께 reg_table.html 이름으로 HTML 파일도 저장됩니다."
  },
  {
    "objectID": "r_sql.html#r에서-sql-db에-접속하기",
    "href": "r_sql.html#r에서-sql-db에-접속하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.1 R에서 SQL DB에 접속하기",
    "text": "4.1 R에서 SQL DB에 접속하기\nDBI 패키지를 이용하면 R 내에서 SQL DB에 접속 및 작업이 가능합니다. 먼저 DB 인스턴스에 연결을 합니다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', # 위에서 설정한 root 비밀번호\n  host = '127.0.0.1',\n  dbname = 'shop' # 사용하고자 하는 스키마\n)\n\n\ndrv: MySQL을 사용하므로 MySQL()을 입력합니다.\nuser: 관리자 계정에 해당하는 root를 입력합니다.\npassword: 위에서 설정한 root 관리자 계정의 비밀번호를 입력합니다.\nhost: 로컬 주소를 입력합니다. (일반적으로 127.0.0.1로 셋팅되어 있습니다.)\ndbname: 사용하고자 하는 데이터베이스(스키마) 이름을 입력합니다.\n\n이제 R과 SQL DB가 연결 되었습니다. dbListTables() 함수를 통해 데이터베이스 내의 테이블의 리스트를 확인할 수 있습니다.\n\ndbListTables(con)\n\n이제 R 내에서 SQL DB의 데이터를 불러와보겠습니다. dbGetQuery() 함수는 DB에 쿼리를 전송한 후 결과를 받아오는 함수이며, goods 테이블을 조회하는 쿼리를 전송해보겠습니다.\n\ngoods = dbGetQuery(con, 'select * from goods;')\n\n이처럼 SQL DB의 데이터를 R로 가져올 수 있으며, 얼마든지 복잡한 형태의 쿼리 전송도 가능합니다.\n\ndbGetQuery(con, 'select goods_classify, count(*) as cnt\n           from goods\n           group by goods_classify\n           order by cnt desc;')"
  },
  {
    "objectID": "r_sql.html#테이블-생성하기",
    "href": "r_sql.html#테이블-생성하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.2 테이블 생성하기",
    "text": "4.2 테이블 생성하기\n예제로 내장 데이터셋인 economics를 저장할 테이블을 만들어 보겠습니다. SQL에서는 CREATE TABLE 쿼리를 이용해 테이블을 만들수 있습니다. 그러나 R에서 SQL로 쿼리를 전송하여 테이블을 만들수도 있습니다.\n\ndbSendQuery(con,\n \"CREATE TABLE economics(\n  date Date PRIMARY KEY,\n  pce double,\n  pop double,\n  psavert double,\n  uempmed double,\n  unemploy double\n)\"\n)\n\n같은 날짜가 중복에서 입력되면 안되는 유일한 값이므로 date는 PRIMARY KEY로 설정해 줍니다. dbSendQuery() 함수는 dbGetQuery() 함수와는 다르게 단순히 쿼리를 전송하는 역할만 합니다. Workbench를 열어 해당 테이블이 제대로 만들어 졌는지 확인해보도록 하겟습니다.\n\n\n\n\n\n스키마 부분에서 새로고침을 눌러보면, **economics***** 테이블이 제대로 만들어졌으며, date 컬럼은 Primary Key를 나타내는 PK가 표시됩니다."
  },
  {
    "objectID": "r_sql.html#데이터-저장하기",
    "href": "r_sql.html#데이터-저장하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.3 데이터 저장하기",
    "text": "4.3 데이터 저장하기\nR의 데이터를 SQL DB에 저장하기 위해서는 추가적인 다음과 같은 설정이 필요합니다.\n\ndbSendQuery(con,\n  \"SET GLOBAL local_infile = TRUE;\"\n)\n\n위 쿼리를 통해 local_infile를 TRUE로 설정하면, R의 데이터를 SQL DB에 직접 저장이 가능합니다. 이제 economics 데이터셋을 불러오도록 합니다.\n먼저 economics 데이터셋을 불러오도록 합니다.\n\neconomics = ggplot2::economics\neconomics = data.frame(economics)\n\neconomics 데이터는 ggplot2 패키지에 존재하며, spec_tbl_df 형태이므로 data.frame() 함수를 통해 데이터프레임 형태로 변경합니다. 해당 데이터를 SQL DB에 저장해보도록 하겠으며, 해당 작업에는 dbWriteTable() 함수가 이용됩니다.\n\ndbWriteTable(con, \"economics\", economics[1:300, ],\n             overwrite = TRUE, row.names = FALSE)\n\ndbWriteTable() 함수를 이용해 economics 데이터의 1행부터 300행 까지의 데이터를 저장합니다. overwrite 인자를 TRUE로 설정하면 이미 존재하는 테이블에 새로운 데이터를 덮어쓰게 됩니다. row.names는 행 이름을 새로운 열로 추가할지 여부이므로 FALSE로 설정합니다.\nWorkbench에서 확인을 해보면 economics 테이블에 해당 데이터가 저장되어 있습니다.\n\n\n\n\n\n나머지에 해당하는 301행부터 574행 까지의 데이터도 저장해보도록 하겠습니다.\n\ndbWriteTable(con, \"economics\", economics[301:574, ],\n             append = TRUE, row.names = FALSE)\n\n이번에는 overwrite 인자 대신 append 인자를 TRUE로 설정합니다. 만약 overwrite = TRUE를 입력한다면 기존의 데이터가 모두 지워지고 새로운 데이터가 저장되는 반면, append = TRUE를 입력하면 기존의 데이터가 유지된 상태에서 새로운 데이터가 추가적으로 저장됩니다.\n이처럼 R 내에서 작업한 결과물을 SQL DB에 손쉽게 저장할 수 있습니다."
  },
  {
    "objectID": "r_sql.html#데이터-추가하기",
    "href": "r_sql.html#데이터-추가하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.4 데이터 추가하기",
    "text": "4.4 데이터 추가하기\n기본 데이터에는 2015년 4월 1일까지의 데이터만 존재합니다. 만일 새로운 데이터를 구해 기존 DB에 추가하고자 할 경우 SQL에서는 INSERT INTO 쿼리가 사용됩니다.\n\nINSERT INTO [테이블] (열1, 열2, ...)\nVALUE (값1, 값2 , ….);\n\n위 쿼리를 이용해 가상의 2015년 5월 1일 데이터를 추가해주도록 합니다.\n\ndbSendQuery(con,\n  \"INSERT INTO economics (date, pce, pop, psavert, uempmed, unemploy)\n  VALUES ('2015-05-01', '12300', '321000', '8', '12', '8600');\"\n)\n\nWorkbench에서 확인을 해보면 economics 테이블의 가장 하단에 2015-05-01 데이터가 추가되었습니다."
  },
  {
    "objectID": "r_sql.html#데이터-수정하기",
    "href": "r_sql.html#데이터-수정하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.5 데이터 수정하기",
    "text": "4.5 데이터 수정하기\n만일 DB의 데이터를 수정해야 할 경우 SQL에서는 UPDATE 쿼리가 사용됩니다.\n\nUPDATE [테이블] SET [열] = '변경할값' WHERE [조건]\n\n2015년 5월 1일 데이터 중 psavert는 7.9로, uempmed를 14로 수정해보도록 하겠습니다.\n\ndbSendQuery(con,\n  \"UPDATE economics\n  SET psavert = '7.9', uempmed = '14'\n  WHERE DATE = '2015-05-01';\"\n)\n\n데이터를 확인을 해보면 2015-05-01의 데이터가 수정되었습니다."
  },
  {
    "objectID": "r_sql.html#데이터-삭제하기",
    "href": "r_sql.html#데이터-삭제하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.6 데이터 삭제하기",
    "text": "4.6 데이터 삭제하기\n만일 특정 데이터를 삭제해야 할 경우 SQL에서는 DELETE FROM 쿼리가 사용됩니다.\n\nDELETE FROM [테이블]\nWHERE [조건]\n\n이번에는 2015년 5월 1일 데이터를 삭제해보도록 하겠습니다.\n\ndbSendQuery(con,\n  \"DELETE FROM economics\n  WHERE DATE = '2015-05-01';\"\n)\n\n데이터를 확인을 해보면 2015-05-01의 데이터가 삭제되었습니다."
  },
  {
    "objectID": "r_sql.html#테이블-삭제하기",
    "href": "r_sql.html#테이블-삭제하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.7 테이블 삭제하기",
    "text": "4.7 테이블 삭제하기\n만일 테이블 전체를 삭제해야 할 경우 SQL에서는 DROP TABLE 쿼리가 사용됩니다.\n\nDROP TABLE [테이블]\n\n우리가 작업했던 economics 테이블을 삭제해보겠습니다.\n\ndbSendQuery(con,\n  \"DROP TABLE economics;\"\n)\n\nWorkbench의 스키마 부분에서 새로고침을 눌러보면, data 스키마 내에서 economics 테이블이 삭제되었습니다."
  },
  {
    "objectID": "r_sql.html#스키마-생성하기-및-삭제",
    "href": "r_sql.html#스키마-생성하기-및-삭제",
    "title": "4  R과 SQL 연결하기",
    "section": "4.8 스키마 생성하기 및 삭제",
    "text": "4.8 스키마 생성하기 및 삭제\n처음에 dbConnect() 함수 내에 dbname을 통해 data 스키마를 사용하겠다고 선언했습니다. 만일 새로운 스키마를 생성하고자 할 경우의 쿼리는 CREATE DATABASE [스키마] 이며, R에서도 쿼리 전송을 통해 명령을 수행할 수 있습니다.\n\ndbSendQuery(con, \"CREATE DATABASE new_db;\")\n\nWorkbench의 스키마 부분에서 새로고침을 눌러보면, new_db 스키마가 새롭게 생성됩니다.\n\n\n\n\n\n반대로 이를 삭제하는 쿼리는 DROP DATABASE [스키마] 입니다.\n\ndbSendQuery(con, \"DROP DATABASE new_db;\")"
  },
  {
    "objectID": "r_sql.html#연결-해제하기",
    "href": "r_sql.html#연결-해제하기",
    "title": "4  R과 SQL 연결하기",
    "section": "4.9 연결 해제하기",
    "text": "4.9 연결 해제하기\nR에서 SQL을 이용한 모든 작업이 완료되면 반드시 R의 DB 접속을 종료해주어야 합니다. 만일 접속을 종료하지 않고 R을 닫을 경우, 향후 접속문제가 발생할 수도 있습니다.\n\ndbDisconnect(con)\n\ndbDisconnect() 함수를 통해 R의 DB 연결을 해제할 수 있습니다. 다시 DB를 사용하려면 dbConnect() 함수를 이용해 재접속을 하면 됩니다."
  },
  {
    "objectID": "sql.html#데이터베이스의-구성-요소",
    "href": "sql.html#데이터베이스의-구성-요소",
    "title": "2  SQL 기초",
    "section": "2.1 데이터베이스의 구성 요소",
    "text": "2.1 데이터베이스의 구성 요소\n데이터베이스는 각각의 테이블로 이루어져 있으며, 테이블의 구성요소는 크게 다음과 같다.\n\n열(컬럼): 테이블에 보관하는 데이터 항목이다.\n행(레코드): 데이터 한 건에 해당하며, RDBMS는 반드시 행 단위로 데이터를 읽고 쓴다.\n셀(값): 행과 열이 교차하는 하나의 값이며, 하나의 셀 안에는 하나의 데이터만 넣을 수 있다."
  },
  {
    "objectID": "sql.html#데이터베이스와-테이블-만들기",
    "href": "sql.html#데이터베이스와-테이블-만들기",
    "title": "2  SQL 기초",
    "section": "2.2 데이터베이스와 테이블 만들기",
    "text": "2.2 데이터베이스와 테이블 만들기\n먼저 각각의 테이블이 저장될 데이터베이스(스키마)를 만들어 보도록 하자. MySQL Workbench를 열어 아래의 쿼리를 입력한다.\n\ncreate database shop;\n\n\n\n\n\n\ncreate database [데이터베이스명]은 데이터베이스를 만드는 SQL 쿼리다. 쿼리를 실행하는 방법은 원하는 부분을 선택한 후 Ctrl + Shift + Enter(맥 사용자의 경우 Modifier + Shift + Return) 키를 누른다. SQL 쿼리문의 끝에는 세미콜론(;)을 붙이며, 대문자나 소문자는 구분하지 않는다. 단 테이블에 등록된 데이터는 대/소문자가 구분된다.\n쿼리가 실행되면 하단의 [Action Output] 부분에 create database shop 이라는 문구가 뜨며, shop이라는 데이터베이스가 만들어졌음을 알 수 있다. 이를 확인할 수 있는 방법은 아래 그림과 같이 [Navigator]부분 하단에서 [Schemas]를 선택한 후 우측 상단의 새로고침 마크를 클릭하면 shop 데이터베이스가 생겼음이 확인된다.\n\n\n\n\n\n데이터베이스를 만들고 난 후에는 사용하고자 하는 데이터베이스를 지정해야하며, 이는 MySQL을 새로 열때마다 실행해야 한다.\n\nuse shop;\n\nuse [데이터베이스명]; 쿼리를 통해 shop 데이터베이스를 사용할 것을 지정하였다.\n이제 데이터베이스 하부에 테이블을 만들어보도록 하자. 테이블을 만드는 쿼리 형식은 다음과 같다.\n\ncreate table <테이블명>\n(\n<열 이름 1> <데이터 형태> <이 열의 제약>,\n<열 이름 2> <데이터 형태> <이 열의 제약>,\n<열 이름 3> <데이터 형태> <이 열의 제약>,\n….\n<테이블의 제약 1>, <테이블의 제약 2>, …. \n);\n\n위 형식에 맞춰 goods 테이블을 만들어주도록 한다.\n\ncreate table goods\n(\ngoods_id char(4) not null,\ngoods_name varchar(100) not null,\ngoods_classify varchar(32) not null,\nsell_price integer,\nbuy_price integer,\nregister_date date,\nprimary key (goods_id)\n);\n\n모든 열에 integer나 char 등의 데이터 형식을 지정해 주어야 한다. MySQL에서 사용할 수 있는 데이터 타입의 종류는 크게 CHAR, BINARY, TEXT, VARCHAR, BLOB, 숫자형 데이터 타입이 있으며, 입력되는 데이터에 맞는 타입을 설정한다. 또한 각종 제약을 설정해줄 수 있다. null이란 데이터가 없음을 의미하며, not null은 반드시 데이터가 존재해야 한다는 의미이다. 마지막으로 goods_id 열을 기본 키(primary key)로 지정해준다.\n위 쿼리를 실행한 후 좌측의 SCHEMAS 부분에서 새로고침을 해보면, shop 데이터베이스의 Tables에 [goods]가 생성되며, Columns 부분에서 우리가 입력한 열들을 확인할 수 있다. 또한 열 이름을 클릭하면 하단의 Information 부분에서 해당 열의 데이터 타입 또한 확인할 수 있다.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n데이터베이스나 테이블, 열 이름으로 사용할 수 있는 문자는 다음과 같다.\n\n영문자(간혹 한글이 되기는 하나 추천하지 않음)\n숫자\n언더바(_)\n\n\n\n\n2.2.1 테이블 정의 변경하기\n테이블에 열을 추가로 만들거나 삭제를 해야하는 등 테이블의 정의를 변경해야 하는 경우 ALTER TABLE 문을 사용하면 된다. 먼저 열을 추가하는 쿼리는 다음과 같다.\n\nalter table <테이블명> add column <열 이름> <열 정의>;\n\nshop 테이블에 goods_name이라는 열을 추가하며, 데이터 타입은 varchar(100)으로 설정하는 쿼리는 다음과 같다.\n\nalter table goods add column goods_name_eng varchar(100);\n\n쿼리를 실행하고 SCHEMAS 부분에서 새로고침을 누르면 shop 데이터베이스 내 goods 테이블에 goods_name_eng 열이 추가된 것이 확인된다.\n\n\n\n\n\n반대로 열을 삭제하는 쿼리는 다음과 같다.\n\nalter table <테이블명> drop column <열명>;\n\n이를 이용해 위에서 만든 goods_name_eng 열을 삭제하도록 한다.\n\nalter table goods drop column goods_name_eng;\n\n쿼리 실행후 SCHEMAS 부분에서 새로고침을 누르면 goods 테이블에서 해당 열이 삭제된 것을 확인할 수 있다.\n\n\n2.2.2 테이블에 데이터 등록하기\n현재 goods 테이블은 아무런 데이터가 없는 빈 테이블 상태이므로, 데이터를 등록해주어야 한다. SQL에서 데이터를 등록하는 쿼리는 다음과 같다.\n\ninsert into <테이블명> values (값);\n\n아래 쿼리를 입력하여 goods 테이블에 데이터를 등록해주도록 한다.\n\ninsert into goods values ('0001', '티셔츠', '의류', 1000, 500, '2020-09-20');\ninsert into goods values ('0002', '펀칭기', '사무용품', 500, 320, '2020-09-11');\ninsert into goods values ('0003', '와이셔츠', '의류', 4000, 2800, NULL);\ninsert into goods values ('0004', '식칼', '주방용품', 3000, 2800, '2020-09-20');\ninsert into goods values ('0005', '압력솥', '주방용품', 6800, 5000, '2020-01-15');\ninsert into goods values ('0006', '포크', '주방용품', 500, NULL, '2020-09-20');\ninsert into goods values ('0007', '도마', '주방용품', 880, 790, '2020-04-28');\ninsert into goods values ('0008', '볼펜', '사무용품', 100, NULL, '2020-11-11');\n\n\n\n\n\n\n쿼리가 제대로 실행되었으면 하단의 Output 부분이 위 그림과 같이 나타난다. 이 부분에서 SQL 초보자들에게 발생하는 대부분의 오류는 다음과 같다.\n\n한 번 입력한 데이터를 다시 입력(Error Code: 1062. Duplicate entry ‘000x’ for key ‘goods.PRIMARY’ 오류 메세지 발생)\n테이블 내 열의 갯수와 입력하는 데이터의 열 갯수가 같지 않음(Error Code: 1136. Column count doesn’t match value count at row 1 오류 메세지 발생)\n\n이 외에도 발생하는 오류들은 하단의 Output 부분에 그 원인이 있으므로, 당황하지 말고 해당 메세지를 살펴보고 수정하면 된다."
  },
  {
    "objectID": "sql.html#sql-기초구문-익히기",
    "href": "sql.html#sql-기초구문-익히기",
    "title": "2  SQL 기초",
    "section": "2.3 SQL 기초구문 익히기",
    "text": "2.3 SQL 기초구문 익히기\n위에서 만든 테이블을 바탕으로 SQL에서 자주 사용되는 기초 구문들을 실습해보겠다.\n\n2.3.1 select: 열 선택하기\n테이블에서 원하는 열을 선택할 때는 select 문을 사용하며, 쿼리는 다음과 같다.\n\nselect <열 이름 1> , <열 이름 2>, … <열 이름 n>\nfrom <테이블명>;\n\ngoods 테이블 중 goods_id, goods_name, buy_price 열만 선택해보도록 하자.\n\nselect goods_id, goods_name, buy_price\nfrom goods;\n\n\n\n\n\n\n쿼리를 실행하면 하단의 [Result Grid]에 결과가 표시되며, 우리가 선택한 열만 표시된다. 만일 모든 데이터를 한번에 보고 싶다면 select * from <테이블명>; 형태로 입력하면 된다.\n\nselect * from goods;\n\n\n\n\n\n\nas 키워드를 사용하면 열에 별명을 부여할 수도 있다. 만일 저장된 테이블의 열 이름이 길 경우 이를 모두 출력하면 직관적으로 내용을 이해하기 힘드므로 이름을 간결하게 변경하는 것이 나을 때도 있다. as 키워드를 사용하는 방법은 다음과 같다.\n\nselect <열 이름 1> as <별명>\nfrom <테이블명>;\n\n이를 이용해 goods_id, goods_name, buy_price의 이름을 바꾼 후 출력해보도록 하자.\n\nselect goods_id as id,\n    goods_name as name,\n    buy_price as price\nfrom goods;\n\n\n\n\n\n\nselect 구를 통해 단순히 현재 있는 열을 선택할 뿐만 아니라 상수 및 계산식도 작성이 가능하다. 아래 쿼리를 실행해보도록 하자.\n\nselect '상품' as category,\n    38 as num,\n    '2022-01-01' as date,\n    goods_id,\n    goods_name,\n    sell_price, buy_price, sell_price - buy_price as profit\nfrom goods;\n\n\n\n\n\n\ncategory, num, date 열에는 각각 상품, 38, 2022-01-01이라는 상수가 입력된다. 또한 sell_price - buy_price를 통해 두 열의 차이를 계산할 수 있으며, as 키워드를 통해 해당 열을 profit 으로 출력한다. 만일 별명을 부여하지 않을 경우 해당 열 이름은 계산식인 [sell_price - buy_price]가 그대로 출력된다.\n\n\n2.3.2 distinct: 중복 제거하기\n중복된 데이터가 있는 경우 중복되는 값을 제거하고 고유한 값만 확인하고 싶을 때는 distinct 키워드를 사용하며, 사용법은 다음과 같다.\n\nselect distinct <열 이름>\nfrom <테이블명>;\n\n상품 분류에 해당하는 goods_classify 열에는 중복된 값들이 존재한다. 만일 상품 분류가 어떤 것이 있는지 고유한 값만을 확인하고 싶을 경우 아래 쿼리를 실행하면 된다.\n\nselect distinct goods_classify\nfrom goods;\n\n\n\n\n\n\n상품 분류 중 고유한 값인 의류, 사무용품, 주방용품만이 출력된다.\n\n\n2.3.3 where: 원하는 행 선택하기\n여러 데이터 중 조건에 부합하는 행만 선택할 때는 where 구를 사용하면 된다. 이는 엑셀에서 필터 기능과도 비슷하다. where 구는 from 구 바로 뒤에 사용해야 작동한다.\n\nselect <열 이름>, …\nfrom <테이블명>\nwhere <조건식>;\n\n테이블에서 상품 분류(goods_classify)가 의류인 데이터만 선택해보도록 하자.\n\nselect goods_name, goods_classify\nfrom goods\nwhere goods_classify = '의류';\n\n\n\n\n\n\n여러 데이터 중 goods_classify가 의류인 데이터 2개(티셔츠, 와이셔츠)만 선택되었다."
  },
  {
    "objectID": "sql.html#연산자",
    "href": "sql.html#연산자",
    "title": "2  SQL 기초",
    "section": "2.4 연산자",
    "text": "2.4 연산자\n연산자는 SQL 문에서 연산을 수행하기 위해 사용되는 사전에 예약된 단어 또는 문자로써 일반적으로 where 구 안에서 사용된다. 흔히 사용되는 연산자는 다음과 같다.\n\n산술 연산자\n비교 연산자\n논리 연산자\n\n\n2.4.1 산술 연산자\n산술 연산자는 더하기, 빼기, 곱하기, 나누기 등 계산을 할 때 사용되는 연산자이다. 만일 판매가에서 구매가를 뺀 이익이 500 이상인 데이터만 선택하려면 다음과 같은 쿼리를 실행한다.\n\nselect *, sell_price - buy_price as profit\nfrom goods\nwhere sell_price - buy_price >= 500;\n\n\n\n\n\n\nwhere 구문 내애 [sell_price - buy_price]를 계산하여 이익이 500 이상인 조건에 만족하는 데이터만을 선택하였다.\n\n\n2.4.2 비교 연산자\n비교 연산자는 데이터의 크기를 비교할 때 사용되는 연산자이며, 종류는 다음과 같다.\n\n\n\n연산자\n의미\n\n\n\n\n=\n~와 같다\n\n\n<>\n~와 같지 않다\n\n\n>=\n~ 이상\n\n\n>\n~ 보다 크다\n\n\n<=\n~ 이하\n\n\n<\n~ 보다 작다\n\n\n\nsell_price가 1000 이상인 데이터만 선택하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere sell_price >= 1000;\n\n\n\n\n\n\n숫자 뿐 아니라 날짜에도 비교 연산자를 사용할 수 있다. 등록일(register_date)이 2020년 9월 27일 이전인 데이터만 선택하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, register_date\nfrom goods\nwhere register_date < '2020-09-27';\n\n\n\n\n\n\n\n\n2.4.3 논리 연산자\nwhere 구 내에 and 연산자와 or 연산자와 같은 논리 연산자를 사용하면 복수의 검색 조건을 조합할 수 있다. 예를 들어 상품 분류가 주방용품이고 판매가가 3000 이상인 데이터를 조회하는 쿼리는 다음과 같다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere goods_classify = '주방용품'\nand sell_price >= 3000;\n\n\n\n\n\n\n두 조건을 모두 만족하는 데이터가 선택되었다. 만약 상품 분류가 주방용품이거나 판매가가 3000 이상인 경우처럼 여러 조건 중 하나만 만족해도 되는 경우를 검색하고 싶을 경우에는 or 연산자를 사용하면 된다.\n\nselect goods_name, goods_classify, sell_price\nfrom goods\nwhere goods_classify = '주방용품'\nor sell_price >= 3000;"
  },
  {
    "objectID": "sql.html#집약-함수",
    "href": "sql.html#집약-함수",
    "title": "2  SQL 기초",
    "section": "2.5 집약 함수",
    "text": "2.5 집약 함수\n집약 함수란 여러 개의 레코드를 하나로 집약시키는 기능으로써, 대표적으로 사용되는 집약 함수는 다음과 같다.\n\n\n\n함수명\n의미\n\n\n\n\ncount\n행 숫자를 계산\n\n\nsum\n합계를 계산\n\n\navg\n평균을 구함\n\n\nmax\n최댓값을 구함\n\n\nmin\n최솟값을 구함\n\n\n\n\n2.5.1 count: 행 숫자를 계산\ncount 함수는 행의 숫자를 계산한다. goods 테이블에 몇 개의 행이 있는 확인하는 쿼리는 다음과 같다.\n\nselect count(*)\nfrom goods;\n\n\n\n\n\n\n별표(*)는 모든 열을 의미하며 총 8개의 행이 있다는 것이 확인되었다. 그러나 이는 null이 포함된 행의 수이다. 만일 null을 제외한 행의 수를 계산하고자 할 때는 인수에 특정 열을 지정한다.\n\nselect count(buy_price)\nfrom goods;\n\n\n\n\n\n\n‘buy_price’ 열의 8개 데이터 중에는 총 2개의 null값이 있다. 따라서 count 함수를 실행하면 null을 제외한 6개의 행이 있음이 확인된다. 즉 count(*)는 null을 포함한 행의 갯수를, count(열 이름)은 null을 제외한 행 수를 계산한다.\n\n\n2.5.2 sum: 합계를 계산\nsum 함수는 특정 열의 합계를 계산하며, null 값은 무시하고 계산이 된다. sell_price와 buy_price 열의 합계를 구하는 쿼리는 다음과 같다.\n\nselect sum(sell_price), sum(buy_price)\nfrom goods;\n\n\n\n\n\n\n\n\n2.5.3 avg: 산술평균을 계산\navg 함수는 산술평균을 구하며, 사용법은 sum과 동일하다. sell_price 열의 평균을 구하는 쿼리는 다음과 같다.\n\nselect avg(sell_price)\nfrom goods;\n\n\n\n\n\n\n\n\n2.5.4 중복값 제외 후 집약함수 사용하기\n만일 상품 분류가 몇 개가 있는지 확인하고 싶을 때는 어떻게 하면 될까? count 함수의 인자에 distict 키워드를 사용해 중복되지 않은 데이터의 갯수를 계산할 수 있다.\n\nselect count(distinct goods_classify) \nfrom goods;\n\n\n\n\n\n\ngoods_classify 에는 의류, 사무용품, 주방용품 3개가 있으므로 이에 해당하는 값이 계산되었다. 이는 count 뿐만 아니라 sum(distinct 열 이름)과 같이 다른 집약함수에도 동일하게 적용이 가능하다."
  },
  {
    "objectID": "sql.html#그룹화와-정렬",
    "href": "sql.html#그룹화와-정렬",
    "title": "2  SQL 기초",
    "section": "2.6 그룹화와 정렬",
    "text": "2.6 그룹화와 정렬\n데이터를 특정 기준으로 그룹을 나누어 값을 계산해야 하는 경우가 많다. 예를 들어 상품 분류 별 혹은 등록일 별 그룹을 나누어 손익을 계산한다고 생각해 보자. 이러한 경우 SQL에서는 group by 구를 사용하여 데이터를 그룹화할 수 있다. 또한 검색 결과를 특정 기준으로 정렬할 필요가 있을 경우 order by 구를 사용하면 된다.\n\n2.6.1 그룹 나누기\n\n\n\n\n\n위 그림의 경우 category 별로 그룹을 나누어 평균을 계산하기 위해서는 데이터를 Blue, Green, Red 별로 그룹을 나누어 평균을 계산해야 한다. 이러한 그룹화 작업을 수행하는 구가 group by이며, 사용법은 아래와 같이 그룹을 나누고자 하는 열을 입력하면 된다.\n\nselect <열 이름 1>, <열 이름 2>, …..\nfrom <테이블명>\ngroup by <열 이름 1>, <열 이름 2>, ….\n\n상품 분류 별 데이터의 수를 계산하기 위한 쿼리는 다음과 같다.\n\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\n\n\n\n\n\ngoods_classify 별로 그룹을 나눈 후 count(*)를 통해 각 그룹 별 행 갯수를 구할 수 있다. group by 구는 반드시 from 구 뒤에 두어야 한다. 이번에는 buy_price 별 행 갯수를 구해보도록 하자.\n\nselect buy_price, count(*)\nfrom goods\ngroup by buy_price;\n\n\n\n\n\n\nbuy_price 열에는 null 데이터도 포함되어 있으며, 이 역시 별도의 그룹으로 분류됨을 알 수 있다. 만일 where 구를 통해 조건에 맞는 데이터를 선택한 후 group by 구를 통해 그룹을 나눌때는 어떻게 해야 할까? 이 경우 where 구 뒤에 group by 구를 작성해야 한다. 상품 분류가 의류인 것 중 buy_price 별 데이터의 수를 구하는 쿼리는 다음과 같다.\n\nselect buy_price, count(*)\nfrom goods\nwhere goods_classify = '의류'\ngroup by buy_price;\n\n만일 group by를 통해 나온 결과에 조건을 지정하려면 어떻게 해야 할까? 이 경우 where이 아닌 having 구를 사용해야 한다.\n\nselect <열 이름 1>, <열 이름 2>, …\nfrom <테이블 명>\ngroup by <열 이름 1>, <열 이름 2>, …\nhaving <그룹값에 대한 조건>\n\n예를 들어 상품 분류별로 판매가의 평균을 구한 후, 이 값이 2500 이상인 데이터를 구하는 쿼리는 다음과 같다.\n\nselect goods_classify, avg(sell_price)\nfrom goods\ngroup by goods_classify\nhaving avg(sell_price) >= 2500;\n\n\n\n\n\n\n요약하자면 where는 group by 계산 이전, having은 group by 계산 이후 적용된다.\n\n\n2.6.2 검색 결과 정렬하기\nSQL에서는 결과가 무작위로 정렬되므로 쿼리를 실행할 때 마다 결과가 변한다. 오름차순이나 내림차순으로 결과를 정렬하고자 할 경우에는 order by 구를 사용한다.\n\nselect <열 이름 1>, <열 이름 2>, …\nfrom <테이블명>\norder by <재정렬 기준 열 1>, <재정렬 기준 열 2>, ...\n\n예를 들어 sell_price가 싼 순서, 즉 오름차순으로 정렬할 경우 쿼리는 다음과 같다.\n\nselect *\nfrom goods\norder by sell_price;\n\n\n\n\n\n\norder by 구는 기본적으로 오름차순으로 데이터를 정렬한다. 만일 내림차순으로 정렬하고자 할 경우 재정렬 기준 뒤에 desc 키워드를 사용한다.\n\nselect *\nfrom goods\norder by sell_price desc;"
  },
  {
    "objectID": "sql.html#뷰와-서브쿼리",
    "href": "sql.html#뷰와-서브쿼리",
    "title": "2  SQL 기초",
    "section": "2.7 뷰와 서브쿼리",
    "text": "2.7 뷰와 서브쿼리\n기초구문 만으로는 복잡한 형태의 데이터분석을 하는게 한계가 있으며, 뷰와 서브쿼리를 이용하면 이러한 작업을 쉽게 할 수 있다.\n\n2.7.1 뷰 만들기\n뷰는 기본적으로 테이블과 거의 동일하다. 그러나 테이블과의 차이는 실제 데이터를 저장하고 있지 않다는 점이다. 뷰는 데이터를 저장하지 않고 있으며, 뷰에서 데이터를 꺼내려고 할 때 내부적으로 쿼리를 실행하여 일시적인 가상 테이블을 만든다. 즉, 데이터가 아닌 쿼리를 저장하고 있다고 보면 된다. 이러한 뷰가 가진 장점은 다음과 같다.\n\n데이터를 저장하지 않기 때문에 기억 장치 용량을 절약할 수 있다.\n자주 사용하는 쿼리를 매번 작성하지 않고 뷰로 저장하면 반복해서 사용이 가능한다. 뷰는 원래의 테이블과 연동되므로, 데이터가 최신 상태로 갱신되면 뷰의 결과 역시 자동으로 최신 상태를 보여준다.\n\n뷰는 create view 문을 사용해 만들 수 있다.\n\ncreate view 뷰 이름 (<뷰의 열 이름 1>, <뷰의 열 이름 2>, ...)\nas\n<쿼리>;\n\n만일 상품 분류 별 행 갯수를 매일 조회해야 한다면, 매번 쿼리를 실행하는 것 보다 뷰를 만들어 이를 확인하는 것이 훨씬 효율적이다. 아래의 쿼리를 통해 해당 뷰를 만들 수 있다.\n\ncreate view GoodSum (goods_classify, cnt_goods)\nas\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\n\n\n\n\n\n위 쿼리를 실행한 후 SCHEMAS 부분에서 새로고침을 눌러보면 Views 하부에 goodsum 이라는 뷰가 생긴것이 확인된다. 뷰의 데이터를 확인하는 방법은 테이블의 데이터를 확인하는 방법과 동일하다.\n\nselect *\nfrom GoodSum;\n\n\n\n\n\n\n\n\n2.7.2 뷰 삭제하기\n뷰를 삭제하려면 drop view 뷰명 문을 사용한다.\n\ndrop view GoodSum;\n\n혹은 SCHEMAS 영역에서 삭제하고자 하는 뷰를 선택한 후 마우스 우클릭을 눌러 [Drop View]를 클릭해도 해당 뷰가 삭제된다.\n\n\n\n\n\n\n\n2.7.3 서브쿼리\n서브쿼리란 쿼리 내의 쿼리이며, 일회용 뷰를 의미한다. 즉, 뷰를 정의하는 구문을 그대로 다른 구 안에 삽입하는 것이다. 먼저 뷰를 만든 후 이를 확인하는 쿼리는 다음과 같다.\n\ncreate view GoodSum (goods_classify, cnt_goods)\nas\nselect goods_classify, count(*)\nfrom goods\ngroup by goods_classify;\n\nselect * from GoodSum;\n\n이와 동일한 결과가 나오게 하는 서브쿼리는 다음과 같다.\n\nselect goods_classify, cnt_goods\nfrom (\n select goods_classify, count(*) as cnt_goods\n from goods\n group by goods_classify\n) as GoodsSum;\n\nfrom 구 뒤의 괄호안에 해당하는 부분은 뷰를 만들 때 사용하던 코드와 동일하다. 즉, ① from 구 안의 select 문(서브쿼리)가 실행되고, ② 이 결과를 바탕으로 바깥쪽 select 문이 실행된다.\n\n\n2.7.4 스칼라 서브쿼리\n스칼라 서브쿼리란 단이 값이 반환되는 서브쿼리다. 이를 통해 =, <, > 등 비교 연산자의 입력값으로 사용할 수 있다. 예를 들어 판매단가가 전체 평균 판매단가보다 높은 상품만을 검색하려면 어떻게 해야할까? 먼저 평균 단가를 계산해야 한다.\n\nselect avg(sell_price)\nfrom goods;\n\n\n\n\n\n\n해당 쿼리를 서브쿼리에 넣어 원하는 값을 찾을 수 있다.\n\nselect *\nfrom goods\nwhere sell_price > (select avg(sell_price) from goods);\n\n\n\n\n\n\n스칼라 서브쿼리는 where 구 뿐만 아니라 select, group by, having, order by 구 등 거의 모든 곳에 쓸 수 있다. 평균 판매가격을 새로운 열로 만드는 쿼리는 다음과 같다.\n\nselect goods_id, goods_name, sell_price,\n    (select avg(sell_price) from goods) as avg_price\nfrom goods;\n\n\n\n\n\n\nselect 구문 내에 select avg(sell_price) from goods 쿼리를 입력하여 평균 판매가격을 계산한 후 이를 avg_price 라는 열 이름으로 출력한다.\n이번에는 좀 더 복잡한 조건에 해당하는 데이터를 찾아보도록 하자. 상품 분류 별 평균 판매가격이 전체 데이터의 평균 판매가격 이상인 데이터만 출력하는 쿼리는 다음과 같다.\n\nselect goods_classify, avg(sell_price)\nfrom goods\ngroup by goods_classify\nhaving avg(sell_price) > (select avg(sell_price) from goods);\n\n\n\n\n\n\n먼저 group by 구문을 이용해 상품 분류 별 평균 판매가격을 계산한다. 그 후 having 구문 내에 전체 평균 판매가격을 계산하는 서브쿼리인 select avg(sell_price) from goods 를 입력하여 2097.5 라는 값을 계산하고, 그룹별 평균 판매가격이 이 값보다 큰 데이터만을 선택하게 된다."
  },
  {
    "objectID": "sql.html#함수-술어와-case-식",
    "href": "sql.html#함수-술어와-case-식",
    "title": "2  SQL 기초",
    "section": "2.8 함수, 술어와 case 식",
    "text": "2.8 함수, 술어와 case 식\nSQL에서도 함수를 이용해 다양한 연산을 할 수 있으며, 다음과 같은 함수가 존재한다. 본 책에서는 수치 계산을 위한 ‘산술 함수’, 문자열 처리를 위한 ‘문자열 함수’, 날짜 처리를 위한 ’날짜 함수’에 대해 대해 알아보겠다. 또한 함수의 변형 형태인 술어는 반환 값이 진리값(TRUE/FALSE/UNKNOWN)인 함수라 볼 수 있다. 마지막으로 case 식 역시 함수의 일종으로써, SQL 내에서의 if문 이라고도 볼 수 있다. case는 조건에 해당하는 목록을 평가하고 가능한 여러 결과 식 중 하나를 반환한다.\n\n2.8.1 산술 함수\n산술 함수는 숫자형 데이터의 절대값, 올림, 내림, 반올림 등을 계산할 수 있게 해준다. 먼저 m, n, p 3개 열로 구성된 테이블(SampleMath)을 만들어 주도록 한다.\n\ncreate table SampleMath\n(m  numeric (10,3),\n n  integer,\n p  integer);\n\ninsert into SampleMath(m, n, p) values (500, 0, NULL);\ninsert into SampleMath(m, n, p) values (-180, 0, NULL);\ninsert into SampleMath(m, n, p) values (NULL, NULL, NULL);\ninsert into SampleMath(m, n, p) values (NULL, 7, 3);\ninsert into SampleMath(m, n, p) values (NULL, 5, 2);\ninsert into SampleMath(m, n, p) values (NULL, 4, NULL);\ninsert into SampleMath(m, n, p) values (8, NULL, 3);\ninsert into SampleMath(m, n, p) values (2.27, 1, NULL);\ninsert into SampleMath(m, n, p) values (5.555,2, NULL);\ninsert into SampleMath(m, n, p) values (NULL, 1, NULL);\ninsert into SampleMath(m, n, p) values (8.76, NULL, NULL);\n\n\n\n\n\n\n\n2.8.1.1 abs: 절대값 계산하기\nabs 함수는 해당 열에 있는 값들의 절대값을 구해준다.\n\nselect m, abs(m) as abs_m\nfrom SampleMath;\n\n\n\n\n\n\nabs_m은 m열의 절대값을 계산한 것이며, 두번째 행을 보면 -180의 절대값에 해당하는 180이 계산되었다.\n\n\n2.8.1.2 mod: 나눗셈의 나머지 구하기\n7 나누기 3의 몫은 2이며 나머지는 1이다. mod 함수는 이 나머지에 해당하는 값을 구해준다.\n\nselect n, p, mod(n, p) as mod_col\nfrom SampleMath;\n\n\n\n\n\n\nmod(n, p)를 통해 n/p의 나머지를 구한다. 즉 7/3의 나머지인 1, 5/2의 나머지인 1이 계산되며, null은 계산이 불가한 데이터이므로 결과 역시 null로 나온다.\n\n\n\n2.8.2 round: 반올림 하기\nround 함수를 통해 반올림을 할 수 있으며, 몇 째자리에서 반올림을 할지 정할 수 있다. round(m, 2)의 경우 할 경우 m열의 데이터를 소수 둘째자리까지 반올림한다.\n\nselect m, n, round(m, n) as round_col\nfrom SampleMath;\n\n\n\n\n\n\n위의 쿼리는 m 열을 n 자리까지 반올림한다. n이 0인 경우 소수 0번째 자리, 즉 정수부분까지 반올림을 한다. n이 1인 경우에는 소수 첫째자리까지 반올림을 하기 위해 소수 둘째자리에서 반올림을 한다. round와 비슷한 함수로 올림에는 ceil, 내림에는 floor 함수가 있으므로 상황에 맞게 사용하면 된다\n\n\n2.8.3 문자열 함수\n문자열 함수는 문자 데이터를 처리할 때 사용되는 함수들이다. 먼저 아래의 샘플 테이블(SampleStr)을 만들도록 하자.\n\ncreate table SampleStr\n(str1  varchar(40),\n str2  varchar(40),\n str3  varchar(40));\n\ninsert into SampleStr (str1, str2, str3) values ('가나다', '라마', NULL);\ninsert into SampleStr (str1, str2, str3) values ('abc', 'def', NULL);\ninsert into SampleStr (str1, str2, str3) values ('김', '철수', '입니다');\ninsert into SampleStr (str1, str2, str3) values ('aaa', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values (NULL, '가가가', NULL);\ninsert into SampleStr (str1, str2, str3) values ('@!#$%', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('ABC', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('aBC', NULL, NULL);\ninsert into SampleStr (str1, str2, str3) values ('abc철수', 'abc', 'ABC');\ninsert into SampleStr (str1, str2, str3) values ('abcdefabc','abc', 'ABC');\ninsert into SampleStr (str1, str2, str3) values ('아이우', '이','우');\n\n\n\n\n\n\n\n2.8.3.1 concat: 문자열 연결\nconcat 함수는 여러 열의 문자열을 연결하는데 사용됩니다. (타 RDMS에서는 ||로 문자를 합치기도 한다.) 먼저 str1과 str2 열의 문자를 합쳐보도록 하자.\n\nselect str1, str2, concat(str1, str2) as str_concat\nfrom SampleStr;\n\n\n\n\n\n\n두 열의 문자가 하나로 합쳐지며, null이 포함된 경우는 결과 역시 null이 반환된다.\n\n\n2.8.3.2 lower: 소문자로 변환\nlower 함수는 모든 알파벳을 소문자로 변환한다.\n\nselect str1, lower(str1) as low_str\nfrom SampleStr;\n\n\n\n\n\n\nABC가 abc로 변환되는 등 모든 알파벳이 소문자로 변환되었다. 반대로 모든 알파벳을 대문자로 변환하고자 할 경우 upper 함수를 사용하면 된다.\n\n\n2.8.3.3 replace: 문자를 변경\nreplace 함수는 문자열 안에 있는 일부 문자를 다른 문자열로 변경하며, replace(대상 문자열, 치환 전 문자열, 치환 후 문자열) 형태로 입력한다.\n\nselect str1, str2, str3,\n    replace(str1, str2, str3) as rep_str\nfrom SampleStr;\n\n str1열 중 str2열에 해당하는 문자가 있을 경우 str3열의 문자로 변경된다.\n\n\n\n2.8.4 날짜 함수\nSQL에는 날짜를 다루는 많은 함수가 있으며, DBMS 종류마다 그 형태가 약간씩 다르다.\n\n2.8.4.1 현재 날짜, 시간, 일시\n현재 날짜(current_date)와 시간(current_time), 일시(current_timestamp)를 다루는 함수의 경우 from 구문이 없이 사용이 가능하다.\n\nselect current_date, current_time, current_timestamp;\n\n\n\n\n\n\n\n\n2.8.4.2 날짜 요소 추출하기\nextract(날짜 요소 from 날짜) 함수를 통해 년, 월, 시, 초 등을 추출할 수 있다.\n\nselect\n    current_timestamp,\n    extract(year from current_timestamp) as year,\n    extract(month from current_timestamp) as month,\n    extract(day from current_timestamp) as day,\n    extract(hour from current_timestamp) as hour,\n    extract(minute from current_timestamp) as minute,\n    extract(second from current_timestamp) as second;\n\n\n\n\n\n\n\n\n\n2.8.5 술어\n술어란 반환 값이 진리값(TRUE, FALSE, UNKNOWN)인 함수를 가리킨다. 대표적인 예로는 like, between, is null, in 등이 있다.\n\n2.8.5.1 like: 문자열 부분 일치\n앞에서 문자열을 검색할 때는 등호(=)를 사용했지만, 이는 완전히 일치하는 경우에만 참이 된다. 반면 like 술어는 문자열 중 부분 일치를 검색할 때 사용한다. 먼저 아래의 테이블을 만들도록 한다.\n\ncreate table SampleLike\n(strcol varchar(6) not null,\nprimary key (strcol));\n\ninsert into SampleLike (strcol) values ('abcddd');\ninsert into SampleLike (strcol) values ('dddabc');\ninsert into SampleLike (strcol) values ('abdddc');\ninsert into SampleLike (strcol) values ('abcdd');\ninsert into SampleLike (strcol) values ('ddabc');\ninsert into SampleLike (strcol) values ('abddc');\n\n\n\n\n\n\n일치에는 크게 3가지 종류가 있다.\n\n전방 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 가장 앞에 위치하고 있는 레코드를 선택한다.\n중간 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 어딘가에 포함되어 있으면 레코드를 검색하며 위치는 어디든 상관없다.\n후방 일치: 검색 조건이 되는 문자열이 검색 대상 문자열의 가장 뒤에 위치하고 있는 레코드를 검색한다.\n\n먼저 전방 일치 검색은 다음과 같다.\n\nselect *\nfrom samplelike\nwhere strcol like 'ddd%';\n\n\n\n\n\n\n%는 ‘0문자 이상의 임의 문자열’ 을 의미하는 특수 기호이며, 위의 예에서 ’ddd%’는 ’ddd로 시작하는 모든 문자열’을 의미한다.\n다음으로 중간 일치 검색은 다음과 같다.\n\nselect *\nfrom SampleLike\nwhere strcol like '%ddd%';\n\n\n\n\n\n\n위의 예에서 ‘%ddd%’ 처럼 문자열 처음과 끝을 %로 감쌀 경우 ’문자열 안에 ddd를 포함하고 있는 모든 문자열’을 나타낸다. 결과를 살펴보면 ddd로 시작하거나 끝나는, 혹은 문자열 가운데에 ddd가 있는 문자열이 검색된다.\n마지막으로 후방 일치 검색을 해보도록 하겠다.\n\nselect *\nfrom SampleLike\nwhere strcol like '%ddd';\n\n ’%ddd’의 경우 전방 일치와 반대로 ddd로 끝나는 문자열을 검색한다.\n\n\n2.8.5.2 between: 범위 검색\nbetween은 범위 검색을 수행한다. goods 테이블에서 sell_price가 100원부터 1000원까지인 상품을 선택할 때 between 술어를 사용하면 다음과 같이 나타낼 수 있다.\n\nselect *\nfrom goods\nwhere sell_price between 100 and 1000;\n\n\n\n\n\n\nbetween을 사용할 경우 범위에 해당하는 100과 1000 데이터도 포함한다.\n\n\n2.8.5.3 is null, is not null: null 데이터 선택\n만일 null이 포함된 행을 선택하려면 어떻게 해야 할까? where 구를 where buy_price = null 형식으로 작성하면 될 듯 하지만 해당 쿼리를 실행하면 오류가 발생한다. 이는 null이 비교가 불가능한 특별한 표시어이기 때문이며, 이때는 is null 술어를 사용해야 한다. 먼저 buy_price가 null인 데이터를 선택하는 쿼리는 다음과 같다.\n\nselect *\nfrom goods\nwhere buy_price is null;\n\n\n\n\n\n\nbuy_price가 null인 데이터만 선택된다. 반대로 null이 포함되지 않은 데이터만 선택하고 싶을 때는 is not null 술어를 사용한다.\n\nselect *\nfrom goods\nwhere buy_price is not null;\n\n\n\n\n\n\n\n\n2.8.5.4 in: 복수의 값을 지정\n만일 buy_price가 320, 500, 5000인 상품을 선택할 경우, or을 쓰면 다음과 같이 쿼리를 작성해야 한다.\n\nselect *\nfrom goods\nwhere buy_price = 320 \n    or buy_price = 500\n    or buy_price = 5000;\n\n그러나 이러한 나열식의 쿼리는 조건이 많아질수록 길어지고 효율성이 떨어진다. 이 때 사용할 수 있는 것이 in 술어로써 in(값 1, 값 2, …) 형태를 통해 간단하게 표현할 수 있다.\n\nselect *\nfrom goods\nwhere buy_price in (320, 500, 5000);\n\n\n\n\n\n\n반대로 buy_price가 320, 500, 5000이 아닌 데이터만 선택하고 싶을 때는 not in 술어를 사용한다.\n\nselect *\nfrom goods\nwhere buy_price not in (320, 500, 5000);\n\n\n\n\n\n\n\n\n\n2.8.6 case 식\ncase 식은 경우에 따라 값을 구분하며, 쿼리 형식은 다음과 같다.\n\ncase when <평가식 1> then <식 1>\n    when <평가식 2> then <식 2>\n    when <평가식 3> then <식 3>\n        ⋮\n    else <식 n>\nend\n\nsell_price 열의 가격에 따라 고가/중가/저가로 나눠보도록 하겠다.\n\nselect goods_name, sell_price,\n    case when sell_price >=  6000 then '고가'    \n         when sell_price >= 3000 and sell_price < 6000 then '중가'\n         when sell_price < 3000 then '저가'\n         else null\nend as price_classify\nfrom goods;\n\n\n\n\n\n\nelse 구문은 위에서 만족하는 조건이 없을 때의 반환값으로써 생략할 수도 있지만 명시적으로 기술하는 것이 좋으며, end는 생략이 불가능하다. 조건에 따른 결과가 end as 뒤에 입력한 ‘price_classify’ 열에 표시된다."
  },
  {
    "objectID": "sql.html#테이블의-집합과-결합",
    "href": "sql.html#테이블의-집합과-결합",
    "title": "2  SQL 기초",
    "section": "2.9 테이블의 집합과 결합",
    "text": "2.9 테이블의 집합과 결합\nSQL을 사용할 경우 하나의 테이블만 이용해 데이터를 다루는 일은 거의 없으며, 한번에 여러개의 테이블을 더하거나 결합하여 원하는 데이터를 얻을 수 있다. 이번에는 테이블의 각종 결합 방법에 대해 알아보도록 하겠다.\n\n2.9.1 테이블 결합\n앞서 살펴 본 union 은 행으로 테이블을 합치는 것이었다. 이번에 살펴 볼 결합(join)은 다른 테이블에서 열을 가지고 와 열을 늘리는 작업을 한다. 실무에서는 원하는 데이터가 여러 테이블에 분산되어 있는 경우가 많으므로, 테이블을 결합하여 사용해야 한다. join을 시각화하면 다음과 같다.\n\n\n\n\n\n먼저 아래의 테이블(StoreGoods)을 만든다.\n\nCREATE TABLE StoreGoods\n(store_id CHAR(4) NOT NULL,\n store_name VARCHAR(200) NOT NULL,\n goods_id CHAR(4) NOT NULL,\n num INTEGER NOT NULL,\n PRIMARY KEY (store_id, goods_id));\n\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0001', 30);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0002', 50);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000A', '서울',  '0003', 15);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0002', 30);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B',' 대전',  '0003', 120);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0004', 20);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0006', 10);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000B', '대전',  '0007', 40);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0003', 20);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0004', 50);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0006', 90);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000C', '부산',  '0007', 70);\ninsert into StoreGoods (store_id, store_name, goods_id, num) values ('000D', '대구',  '0001', 100);\n\n\n\n\n\n\nGoods와 StoreGoods 테이블에 있는 열들을 정리하면 다음과 같다.\n\n\n\n\nGoods\nStoreGoods\n\n\n\n\ngoods_id (상품ID)\nO\nO\n\n\ngoods_name (상품명)\nO\n\n\n\ngoods_classify (상품분류)\nO\n\n\n\nsell_price (판매단가)\nO\n\n\n\nbuy_price (매입단가)\nO\n\n\n\nregister_date (등록일)\nO\n\n\n\nstore_id (점포ID)\n\nO\n\n\nstore_name (점포명)\n\nO\n\n\nnum (수량)\n\nO\n\n\n\n\n2.9.1.1 inner join: 내부 결합\n내부 결합(inner join)은 가장 많이 사용되는 결합 방법이다. 위의 테이블을 살펴보면 goods_id는 두 테이블에 모두 존재하며, 다른 열들은 한쪽 테이블에만 존재한다. 따라서 goods_id를 기준으로 StoreGoods 테이블에 Goods 테이블을 결합하는 방법은 다음과 같으며, 이는 마치 엑셀의 vlookup과도 비슷하다.\n\nselect store.store_id, store.store_name, store.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \ninner join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\n\n지금까지는 from에 하나의 테이블만 지정했지만, join 시에는 두 테이블(StoreGoods, Goods)에서 내용을 가지고 온다. 따라서 두 테이블에 store와 goods라는 별명을 붙였다. (원래 테이블명을 그대로 사용해도 되나 테이블명이 길면 가독성이 떨어지므로 일반적으로 별명을 붙인다.)\non 뒤에 결합 조건을 붙인다. 이는 * join 구문 바로 뒤에 붙이며, store의 goods_id 열과 goods 열의 goods_id 열을 이용해 두 테이블을 연결한다는 의미다.\nselect 구에서는 <테이블 별명>.<열 이름> 형식으로 기술한다. 이는 테이블이 여러개가 있으므로, 어느 테이블에서 데이터를 가지고 오는지 혼동하는 것을 방지하기 위해서이다.\n\n\n\n2.9.1.2 outer join 외부 결합\ninner join은 두 테이블에 모두 존재하는 데이터를 합쳤지만, outer join은 한쪽 테이블에만 존재하는 데이터도 출력한다. 먼저 StoreGoods와 Goods에 존재하는 상품ID를 검색한다.\n\nselect distinct(goods_id) from StoreGoods;\nselect distinct(goods_id) from Goods;\n\n\nStoreGoods: 0001, 0002, 0003, 0004, 0006, 0007\nGoods: 0001, 0002, 0003, 0004, 0005, 0006, 0007, 0008\n\nStoreGoods 1~4, 6~7번이, Goods 1번부터 8번까지 상품이 있다. 즉, StoreGoods 5번(압력솥)과 8번(볼펜) ID에 해당하는 물건이 없다. 이제 outer join을 해보도록 한다.\n\nselect store.store_id, store.store_name, goods.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \nright outer join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\ngoods_id가 5(압력솥)와 8(볼펜)의 경우 StoreGoods 테이블에 데이터가 존재하지 않는다. 즉, 현재 어떤 점포에서도 취급하지 않는 상품이다. inner join은 양쪽 테이블에 모두 존재하는 정보만을 선택하기 때문에 Goods 테이블에만 존재하는 두 상품은 결과로 출력되지 않았다. 반면 outer join은 한쪽 테이블에만 존재해도 누락 없이 모두 출력하며, 정보가 없는 부분은 NULL로 표시한다.\n또한 outer join은 어느 쪽 테이블을 마스터로 할 것인지 정해야 한다. 즉 left 혹은 right를 지정해주어야 한다. left를 사용하면 from 구에서 왼쪽에 지정한 테이블을 마스터로 설정하며, right를 사용하면 오른쪽 테이블을 마스터로 한다. 위의 쿼리는 마스터 테이블을 right로 지정하였기에 오른쪽에 해당하는 Goods 테이블의 내용이 모두 출력되고, goods_id를 기준으로 왼쪽에 해당하는 StoreGoods 테이블의 내용이 결합되었다. 위 쿼리를 left outer join 으로 바꿔보도록 하자.\n\nselect store.store_id, store.store_name, goods.goods_id,\n    goods.goods_name, goods.sell_price\nfrom StoreGoods as store \nleft outer join Goods as goods\n    on store.goods_id = goods.goods_id;\n\n\n\n\n\n\n마스터 테이블인 StoreGoods에 존재하는 goods_id(1~4, 6~7)는 결합되는 테이블인 Goods에도 모두 존재하므로 이번에는 NULL이 생성되지 않는다. 어떤 테이블을 기준으로 삼아야 하는가를 미리 생각하여 left outer join을 할지 right outer join을 할지 결정해야 한다."
  },
  {
    "objectID": "sql.html#sql-고급-처리",
    "href": "sql.html#sql-고급-처리",
    "title": "2  SQL 기초",
    "section": "2.10 SQL 고급 처리",
    "text": "2.10 SQL 고급 처리\n이번에는 마지막으로 순위 계산, 누적합 계산, 소계를 구하는 등 고급 집계 처리를 하는 방법인 윈도우 함수에 대해 배워보겠다.\n\n2.10.1 윈도우 함수\n윈도우 함수를 이용하면 랭킹, 순번 생성 등 일반적인 집약 함수로는 불가능한 고급처리를 할 수 있다. 윈도우 함수의 사용법은 크게 다음과 같다.\n\n<윈도우 함수> over ([partition by <열 리스트>] order by <정렬용 열 리스트>)\n\n이 중 partition by는 생략이 가능하다.\n윈도우 함수로 사용할 수 있는 함수는 크게 다음과 같다.\n\n윈도우 전용 함수: rank, dense_rank, row_number 등\n집약함수: sum, avg, count, max, min 등\n\n\n\n\n\n\n\nNote\n\n\n\n윈도우 전용 함수는 원칙적으로 select 구에만 사용할 수 있다.\n\n\n\n2.10.1.1 rank: 순위를 계산\nrank 함수는 순위를 구하는 함수다. 예를 들어 Goods 테이블의 상품 중 상품분류(goods_classify) 별로 판매단가(sell_price)가 낮은 순서대로 순위를 구하는 방법은 다음과 같다.\n\nselect goods_name, goods_classify, sell_price,\n    rank() over (partition by goods_classify order by sell_price) as ranking\nfrom Goods;\n\n\n\n\n\n\n\npartition by는 순위를 정할 대상 범위를 설정하며, 어떤 조건으로 그룹을 나눈다고 생각하면 이해가 쉽다. 상품 분류마다 순위를 구하고자 하므로 goods_classify를 입력한다.\norder by는 윈도우 함수를 어떤 열에 어떤 순서로 적용할지 정한다. 판매단가를 오름차순으로 순위를 구하고자 하므로 sell_price를 입력하였다. 만일 내림차순으로 순위를 구하고자 할 경우 desc 를 입력하면 된다. (기본적으로 asc 즉 오름차순이 적용된다.)\n순위를 구하는 윈도우 전용 함수인 rank()를 입력한다.\n\n이 중 partition by를 통해 구분된 레코드 집합을 ’윈도우’라고 하며, 이는 ’범위’를 나타낸다. 만일 partition by를 지정하지 않으면 전체 테이블이 윈도우가 되므로, 아래와 같이 sell_price 열 자체를 기준으로 순위가 구해진다.\n\nselect goods_name, goods_classify, sell_price,\n    rank () over (order by sell_price) as ranking\nfrom Goods; \n\n\n\n\n\n\n순위를 구하는 함수는 rank 외에도 다양하게 존재하며, 그 결과가 약간씩 다르다.\n\nrank: 같은 순위인 행이 복수개 있으면 후순위를 건너뛴다. 예) 1위가 3개인 경우: 1위, 1위, 1위, 4위, …\ndense_rank: 같은 순위인 행이 복수가 있어도 후순위를 건너뛰지 않는다. 예) 1위가 3개인 경우: 1위, 1위, 1위, 2위, …\nrow_number: 순위와 상관없이 연속 번호를 부여한다. 예: 1위가 3개인 레코드인 경우: 1위, 2위, 3위, 4위, …\n\n각 함수 별 차이를 살펴보도록 하자.\n\nselect goods_name, goods_classify, sell_price,\n    rank() over (order by sell_price) as ranking,\n    dense_rank() over (order by sell_price) as ranking,\n    row_number() over (order by sell_price) as ranking\nfrom Goods;\n\n\n\n\n\n\n\n\n2.10.1.2 윈도우 함수에서 집약 함수의 사용\nsum이나 avg와 같은 집약 함수도 윈도우 함수로 사용할 수 있다.\n\nselect goods_id, goods_name, sell_price,\n    sum(sell_price) over() as current_sum\nfrom Goods;\n\n\n\n\n\n\nover()를 빈 칸으로 둘 경우 current_sum 열에는 모든 sell_price의 합계가 나타난다. 이번에는 누적합계를 구해보도록 하자.\n\nselect goods_id, goods_name, sell_price,\n    sum(sell_price) over(order by goods_id) as current_sum\nfrom Goods;\n\n\n\n\n\n\norder by에 열을 지정할 경우 goods_id를 기준으로 오름차순으로 정렬한 후 누적합계를 구한다. 즉 첫번째 행은 1000, 두번째 행은 1000+500=1500, 세번째 행은 1000+500+4000=5500 과 같이 누적해서 합계가 계산되며, 이는 다른 집계함수도 마찬가지이다. 이번에는 누적평균을 계산해보도록 하자.\n\nselect goods_id, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id) as current_avg\nfrom Goods;\n\n\n\n\n\n\n누적합계와 동일하게 첫번째 행은 (1000)/1=1000, 두번째 행은 (1000+500)/2=750, 세번째 행은 (1000+500+4000)/3=1833.33과 같이 누적해가며 평균을 계산한다.\npartition by를 추가하면 윈도우 별로 집계도 가능하다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    sum(sell_price) over(partition by goods_classify order by goods_id) as current_sum\nfrom Goods;\n\n partition by에 해당하는 goods_classify 별로(사무용품, 의류, 주방용품) 누적합계가 계산된다.\n\n\n2.10.1.3 이동평균 계산하기\n윈도우 함수에서는 그 범위를 정해 ’프레임’을 만들 수도 있다. 이는 over 내의 order by 구문 뒤에 범위 지정 키워드를 사용하면 된다. 예를 들어 모든 열에 대한 누적평균이 아닌 최근 3개 데이터만 이용해 평균을 구하는 이동평균을 계산하는 쿼리는 다음과 같다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id rows 2 preceding) as moving_avg\nfrom Goods;\n\n\n\n\n\n\nrows n proceding을 입력할 경우 앞의 n 행까지만 프레임을 만들어 계산한다. 위 예제에서는 n=2를 입력했으므로 현재 행과 앞의 두개 행, 즉 3개 행으로만 이동평균을 계산한다. 결과를 살펴보면 1행과 2행은 앞의 두개 행에 해당하는 데이터가 없으므로 존재하는 데이터들로 평균이 계산된다. 3행은 1~3행을 이용해 평균이 계산되며 4행은 2~4행, 5행은 3~5행 등 프레임이 움직이며 이동평균이 계산된다.\n앞의 행이 아닌 뒤의 행을 이용해 계산하고 싶을 경우 preceding 대신 following을 입력한다. 현재 행과 뒤의 두개 행으로 이동평균을 계산하는 법은 다음과 같다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id rows between current row and 2 following) as moving_avg\nfrom Goods;\n\n current row and 2 following는 현재 행과 뒤의 두개 행을 의미하며, 앞서 살펴 본 preceding과 반대로 뒤에서 부터 이동평균의 계산된다. preceding과 following을 동시에 사용하는 것도 가능하다.\n\nselect goods_id, goods_classify, goods_name, sell_price,\n    avg(sell_price) over(order by goods_id\n    rows between 1 preceding and 1 following)\n    as moving_avg\nfrom goods;\n\n\n\n\n\n\nrows between n preceding and m following을 입력하면 앞의 n행과 뒤의 m행 까지를 프레임으로 지정한다. 위의 예에서는 앞의 1개 행과 뒤의 1개 행, 총 3개 행을 이용해 이동평균이 계산된다."
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "5  API를 이용한 데이터 수집",
    "section": "",
    "text": "6 야후 파이낸스 이용하기\n야후 파이낸스에서는 주가 데이터를 무료로 제공하며, quantmod 패키지의 getSymbols() 함수는 해당 API에 접속해 데이터를 다운로드합니다.\n미국 시장의 데이터만 필요할 경우 유료 데이터 벤더를 이용하는 것도 좋은 방법입니다. 미국에는 금융 데이터를 API로 제공하는 수많은 업체가 있으며, tiingo의 경우는 월 $10만 지불하면 미국과 중국의 4만여개 종목에 대한 데이터를 API 형태로 받을 수 있습니다. 이는 상장폐지된 종목을 커버할 뿐만 아니라, API를 이용하므로 크롤링과는 비교할 수 없는 속도로 데이터를 받을 수 있다는 장점이 있습니다. 이 외에도 Alpha Vantage, Quandl, Polygon 등 수많은 데이터 벤더가 존재합니다.\ntiingo는 무료 계정도 하루 1,000회까지 API 요청을 할 수 있으며, R/파이썬에서 사용할 수 있는 패키지도 있어 쉽게 사용이 가능합니다."
  },
  {
    "objectID": "api.html#주가-다운로드",
    "href": "api.html#주가-다운로드",
    "title": "5  API를 이용한 데이터 수집",
    "section": "6.1 주가 다운로드",
    "text": "6.1 주가 다운로드\ngetSymbols() 함수의 기본적인 사용법은 매우 간단합니다. 괄호 안에 다운로드하려는 종목의 티커를 입력하면 됩니다.\n\nlibrary(quantmod)\ngetSymbols('AAPL')\n\n[1] \"AAPL\"\n\n\n\nhead(AAPL)\n\n           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted\n2007-01-03  3.081786  3.092143 2.925000   2.992857  1238319600      2.551164\n2007-01-04  3.001786  3.069643 2.993571   3.059286   847260400      2.607790\n2007-01-05  3.063214  3.078571 3.014286   3.037500   834741600      2.589219\n2007-01-08  3.070000  3.090357 3.045714   3.052500   797106800      2.602006\n2007-01-09  3.087500  3.320714 3.041071   3.306071  3349298400      2.818154\n2007-01-10  3.383929  3.492857 3.337500   3.464286  2952880000      2.953019\n\n\n먼저 getSymbols() 함수 내에 애플의 티커인 AAPL을 입력합니다. 티커와 동일한 변수인 AAPL이 생성되며, 주가 데이터가 다운로드된 후 xts 형태로 입력됩니다.\n다운로드 결과로 총 6개의 열이 생성됩니다. Open은 시가, High는 고가, Low는 저가, Close는 종가를 의미합니다. 또한 Volume은 거래량을 의미하며, Adjusted는 배당이 반영된 수정주가를 의미합니다. 이 중 가장 많이 사용되는 데이터는 Adjusted, 즉 배당이 반영된 수정주가입니다.\n\nchart_Series(Ad(AAPL))\n\n\n\n\n\n\n\n\nAd() 함수를 통해 다운로드한 데이터에서 수정주가만을 선택한 후 chart_Series() 함수를 이용해 시계열 그래프를 그릴 수도 있습니다. 시계열 기간을 입력하지 않으면 2007년 1월부터 현재까지의 데이터가 다운로드되며, 입력 변수를 추가해서 원하는 기간의 데이터를 다운로드할 수도 있습니다.\n\ndata = getSymbols('AAPL',\n                  from = '2000-01-01', to = '2018-12-31',\n                  auto.assign = FALSE)\nhead(data)\n\n           AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume AAPL.Adjusted\n2000-01-03  0.936384  1.004464 0.907924   0.999442   535796800      0.851942\n2000-01-04  0.966518  0.987723 0.903460   0.915179   512377600      0.780115\n2000-01-05  0.926339  0.987165 0.919643   0.928571   778321600      0.791530\n2000-01-06  0.947545  0.955357 0.848214   0.848214   767972800      0.723033\n2000-01-07  0.861607  0.901786 0.852679   0.888393   460734400      0.757282\n2000-01-10  0.910714  0.912946 0.845982   0.872768   505064000      0.743963\n\n\nfrom에는 시작시점을 입력하고 to에는 종료시점을 입력하면 해당 기간의 데이터가 다운로드됩니다.\ngetSymbols() 함수를 통해 다운로드한 데이터는 자동으로 티커와 동일한 변수명에 저장됩니다. 만일 티커명이 아닌 원하는 변수명에 데이터를 저장하려면 auto.assign 인자를 FALSE로 설정해주면 다운로드한 데이터가 원하는 변수에 저장됩니다.\n\nticker = c('META', 'NVDA') \ngetSymbols(ticker)\n\n[1] \"META\" \"NVDA\"\n\n\n\nhead(META)\n\n           META.Open META.High META.Low META.Close META.Volume META.Adjusted\n2012-05-18     42.05     45.00    38.00      38.23   573576400         38.23\n2012-05-21     36.53     36.66    33.00      34.03   168192700         34.03\n2012-05-22     32.61     33.59    30.94      31.00   101786600         31.00\n2012-05-23     31.37     32.50    31.36      32.00    73600000         32.00\n2012-05-24     32.95     33.21    31.77      33.03    50237200         33.03\n2012-05-25     32.90     32.95    31.11      31.91    37149800         31.91\n\n\n\nhead(NVDA)\n\n           NVDA.Open NVDA.High NVDA.Low NVDA.Close NVDA.Volume NVDA.Adjusted\n2007-01-03  6.178333  6.253333 5.798333   6.013333   115482000      5.518749\n2007-01-04  5.991667  6.013333 5.838333   5.985000    79729800      5.492748\n2007-01-05  5.843333  5.866667 5.570000   5.610000   124334400      5.148589\n2007-01-08  5.630000  5.760000 5.533333   5.651667    65727000      5.186831\n2007-01-09  5.660000  5.698333 5.535000   5.541667    76416600      5.085878\n2007-01-10  5.483333  5.866667 5.400000   5.815000   110874600      5.336729\n\n\n한 번에 여러 종목의 주가를 다운로드할 수도 있습니다. 위 예제와 같이 메타와 엔비디아의 티커인 META와 NVDA를 ticker 변수에 입력하고 getSymbols() 함수에 티커를 입력한 변수를 넣으면 두 종목의 주가가 순차적으로 다운로드됩니다."
  },
  {
    "objectID": "api.html#국내-종목-주가-다운로드",
    "href": "api.html#국내-종목-주가-다운로드",
    "title": "5  API를 이용한 데이터 수집",
    "section": "6.2 국내 종목 주가 다운로드",
    "text": "6.2 국내 종목 주가 다운로드\ngetSymbols() 함수를 이용하면 미국뿐 아니라 국내 종목의 주가도 다운로드할 수 있습니다. 국내 종목의 티커는 총 6자리로 구성되어 있으며, 해당 함수에 입력되는 티커는 코스피 상장 종목의 경우 티커.KS, 코스닥 상장 종목의 경우 티커.KQ의 형태로 입력해야 합니다.\n다음은 코스피 상장 종목인 삼성전자 데이터의 다운로드 예시입니다.\n\ngetSymbols('005930.KS')\n\n[1] \"005930.KS\"\n\n\n\ntail(Ad(`005930.KS`))\n\n           005930.KS.Adjusted\n2023-01-12              60500\n2023-01-13              60800\n2023-01-16              61100\n2023-01-17              61000\n2023-01-18              60400\n2023-01-19              60600\n\n\nCl() 함수는 Close, 즉 종가만을 선택하며, 사용 방법은 Ad() 함수와 동일합니다. 비록 배당을 고려할 수는 없지만, 전반적으로 오류가 없는 데이터를 사용할 수 있습니다.\n다음은 코스닥 상장종목인 셀트리온제약의 예시이며, 티커인 068670에 .KQ를 붙여 함수에 입력합니다. 역시나 데이터가 다운로드되어 티커명의 변수에 저장됩니다.\n\ngetSymbols(\"068760.KQ\")\n\n[1] \"068760.KQ\"\n\n\n\ntail(Cl(`068760.KQ`))\n\n           068760.KQ.Close\n2023-01-12              NA\n2023-01-13              NA\n2023-01-16              NA\n2023-01-17              NA\n2023-01-18              NA\n2023-01-19           65300"
  },
  {
    "objectID": "api.html#sql에-데이터-저장하기",
    "href": "api.html#sql에-데이터-저장하기",
    "title": "5  API를 이용한 데이터 수집",
    "section": "6.3 SQL에 데이터 저장하기",
    "text": "6.3 SQL에 데이터 저장하기\nAPI나 크롤링을 통해 수집한 데이털르 SQL에 저장해보도록 하겠다. 먼저 SQL에서 다음과 같이 데이터베이스와 주가가 들어갈 테이블을 만든다.\n\ncreate database stock_db;\nuse stock_db;\n\ncreate table price\n(\n    날짜 date,\n    시가 double,\n    고가 double,\n    저가 double,\n    종가 double,\n    거래량 double,\n    종목코드 varchar(6),\n    primary key(날짜, 종목코드)\n);\n\n\n\n\n\n\n이제 삼성전자 주가를 SQL에 저장해보도록 하자.\n\nlibrary(magrittr)\n\ndf = `005930.KS` %>% fortify.zoo() %>%\n  select(1:6) %>%\n  mutate(종목코드 = '005930') %>%\n  set_colnames(c('날짜', '시가', '고가', '저가', '종가', '거래량', '종목코드'))\n\n데이터를 받은 후 클렌징 처리를 해준다.\n\nlibrary(DBI)\nlibrary(RMySQL)\n\ncon = dbConnect(\n  drv = MySQL(),\n  user = 'root',\n  password = '1234', \n  host = '127.0.0.1',\n  dbname = 'stock_db'\n)\n\ndbSendQuery(con,\n  \"SET GLOBAL local_infile = TRUE;\"\n)\n\ndbWriteTable(con, \"price\", df,\n             overwrite = TRUE, row.names = FALSE)\n\n\nR과 SQL을 연결한다.\nlocal_infile를 TRUE로 설정한다.\ndbWriteTable() 함수를 이용해 데이터를 price 테이블에 저장한다.\n\n\n\n\n\n\nSQL을 확인해보면 주가 데이터가 저장되어 있습니다."
  },
  {
    "objectID": "api.html#가입-및-api-token-받기",
    "href": "api.html#가입-및-api-token-받기",
    "title": "5  API를 이용한 데이터 수집",
    "section": "7.1 가입 및 API token 받기",
    "text": "7.1 가입 및 API token 받기\n먼저 https://api.tiingo.com/ 사이트에 접속하여 우측 상단의 [Sign-up]을 클릭해 회원가입을 합니다. 그 후 로그인을 한 후 우측 상단에서 본인의 ID를 클릭한 후 [Account]를 선택, 좌측 메뉴의 [API] 부분에서 [Token]을 클릭하면 본인의 API token을 확인할 수 있습니다.\n다음으로 발급받은 API Key를 .Renviron 파일에 추가하도록 합니다. 해당 파일에는 여러 패스워드를 추가해 안전하게 관리할 수 있습니다.\n\nfile.edit(\"~/.Renviron\")\n\n.Renviron 파일이 열리면 다음과 같이 입력을 해줍니다.\n\nRIINGO_TOKEN = '발급받은 API'\n\n파일을 저장한 후 해당 파일을 적용하기 위해 R의 Session을 재시작(ctrl+shift+F10)합니다. 그 후 아래 명령어를 실행하여 API Key를 불러오도록 합니다. (재시작하지 않으면 Key를 불러올 수 없습니다.)\n다시 시작한 후 API Key를 불러옵니다.\n\nRIINGO_TOKEN = Sys.getenv(\"RIINGO_TOKEN\")"
  },
  {
    "objectID": "api.html#데이터-다운로드",
    "href": "api.html#데이터-다운로드",
    "title": "5  API를 이용한 데이터 수집",
    "section": "7.2 데이터 다운로드",
    "text": "7.2 데이터 다운로드\nR에서 tiingo를 사용할 수 있게 해주는 riingo 패키지를 이용해 데이터를 받아보도록 하겠습니다. 먼저 tiingo에서 제공하는 종목은 어떠한 것이 있는지 티커 정보들을 확인해봅니다.\n\n# install.packages(\"riingo\")\nlibrary(riingo)\n\ntickers = supported_tickers()\ntickers\n\n# A tibble: 106,998 × 6\n   ticker exchange assetType priceCurr…¹ startDate           endDate            \n   <chr>  <chr>    <chr>     <chr>       <dttm>              <dttm>             \n 1 000001 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 2 000002 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 3 000003 SHE      Stock     CNY         NA                  NA                 \n 4 000004 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 5 000005 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 6 000006 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 7 000007 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n 8 000008 SHE      Stock     CNY         2007-01-04 00:00:00 2023-01-18 00:00:00\n 9 000009 SHE      Stock     CNY         2007-01-05 00:00:00 2023-01-18 00:00:00\n10 000010 SHE      Stock     CNY         2007-08-31 00:00:00 2023-01-18 00:00:00\n# … with 106,988 more rows, and abbreviated variable name ¹​priceCurrency\n\n\nticker(티커), exchange(거래소), assetType(주식 종류), priceCurrency(거래 통화), startDate(시작일), endDate(마감일) 정보가 표시됩니다. 거래소와 통화 별 종목이 몇개가 있는지 확인해보도록 하겠습니다.\n\nlibrary(dplyr)\n\ntickers %>% group_by(exchange, priceCurrency) %>% summarize(n = n()) %>%\n  arrange(priceCurrency, desc(n))\n\n# A tibble: 27 × 3\n# Groups:   exchange [24]\n   exchange priceCurrency     n\n   <chr>    <chr>         <int>\n 1 ASX      AUD             169\n 2 SHE      CNY            2570\n 3 SHG      CNY            1936\n 4 SHEB     HKD              42\n 5 SHE      HKD              12\n 6 NMFQS    USD           46245\n 7 PINK     USD           14416\n 8 NASDAQ   USD           13113\n 9 NYSE     USD            8170\n10 OTCGREY  USD            4011\n# … with 17 more rows\n\n\n이 중 마이너 거래소나 장외 거래소의 경우 정보를 받아도 우리나라의 증권사를 통해서는 실제로 거래를 할 수 없을수도 있습니다. 따라서 실제 거래가 가능한 거래소 데이터만 필터링한 후 해당 종목들을 받는 것이 효율적입니다.\n각 종목의 상세 정보를 확인해보도록 하겠습니다.\n\nriingo_meta(\"AAPL\")\n\n# A tibble: 1 × 6\n  ticker name      description   startDate           endDate             excha…¹\n  <chr>  <chr>     <chr>         <dttm>              <dttm>              <chr>  \n1 AAPL   Apple Inc Apple Inc. (… 1980-12-12 00:00:00 2023-01-18 00:00:00 NASDAQ \n# … with abbreviated variable name ¹​exchangeCode\n\n\nriingo_meta() 함수 내에 티커를 입력하면 티커, 종목명, 사업내역 등 대략적인 정보를 받아올 수 있습니다.\n이제 주가를 받아보도록 합시다.\n\nriingo_prices(\"AAPL\")\n\n# A tibble: 251 × 14\n   ticker date                close  high   low  open    volume adjClose adjHigh\n   <chr>  <dttm>              <dbl> <dbl> <dbl> <dbl>     <int>    <dbl>   <dbl>\n 1 AAPL   2022-01-19 00:00:00  166.  171.  166.  170   92914792     165.    170.\n 2 AAPL   2022-01-20 00:00:00  165.  170.  164.  167.  91420515     163.    168.\n 3 AAPL   2022-01-21 00:00:00  162.  166.  162.  164. 122848858     161.    165.\n 4 AAPL   2022-01-24 00:00:00  162.  162.  155.  160. 162706686     160.    161.\n 5 AAPL   2022-01-25 00:00:00  160.  163.  157.  159. 115798367     159.    162.\n 6 AAPL   2022-01-26 00:00:00  160.  164.  158.  164. 108275308     159.    163.\n 7 AAPL   2022-01-27 00:00:00  159.  164.  158.  162. 121954638     158.    163.\n 8 AAPL   2022-01-28 00:00:00  170.  170.  163.  166. 179935660     169.    169.\n 9 AAPL   2022-01-31 00:00:00  175.  175   170.  170. 115541590     174.    174.\n10 AAPL   2022-02-01 00:00:00  175.  175.  172.  174.  86213911     173.    174.\n# … with 241 more rows, and 5 more variables: adjLow <dbl>, adjOpen <dbl>,\n#   adjVolume <int>, divCash <dbl>, splitFactor <dbl>\n\n\nriingo_prices() 함수 내에 티커를 입력하면 close(종가), high(고가), low(저가), open(시가), volumne(거래량) 및 수정주가와 divCash(현금 배당), splitFactor(주식분할 조정계수)까지 데이터를 받을 수 있습니다.\n이번에는 일별 가치지표를 받아보도록 합니다. (무료 계정의 경우 다우존스 30 지수에 포함되는 종목 정보만 제공합니다.)\n\nriingo_fundamentals_metrics('AAPL')\n\n# A tibble: 254 × 7\n   ticker date                    marketCap enterprise…¹ peRatio pbRatio trail…²\n   <chr>  <dttm>                      <dbl>        <dbl>   <dbl>   <dbl>   <dbl>\n 1 AAPL   2022-01-19 00:00:00 2727235373310      2.81e12    27.1    37.9    1.12\n 2 AAPL   2022-01-20 00:00:00 2699016370470      2.78e12    26.8    37.5    1.11\n 3 AAPL   2022-01-21 00:00:00 2664562936770      2.75e12    26.5    37.0    1.10\n 4 AAPL   2022-01-24 00:00:00 2651601883140      2.74e12    26.4    36.9    1.09\n 5 AAPL   2022-01-25 00:00:00 2621414112660      2.71e12    26.1    36.4    1.08\n 6 AAPL   2022-01-26 00:00:00 2619937536930      2.71e12    26.1    36.4    1.08\n 7 AAPL   2022-01-27 00:00:00 2612226530340      2.70e12    26.0    36.3    1.08\n 8 AAPL   2022-01-28 00:00:00 2779690385530      2.87e12    27.6    38.6    1.15\n 9 AAPL   2022-01-31 00:00:00 2852311897980      2.94e12    28.4    39.7    1.18\n10 AAPL   2022-02-01 00:00:00 2849537593010      2.94e12    28.3    39.6    1.17\n# … with 244 more rows, and abbreviated variable names ¹​enterpriseVal,\n#   ²​trailingPEG1Y\n\n\nriingo_fundamentals_metrics() 함수 내에 티커를 입력하면 일간 시가총액, 기업가치, PER, PBR, PEG 정보가 받아집니다.\n마지막으로 재무제표를 받아보도록 합니다.\n\ndf = riingo_fundamentals_statements('AAPL')\ndf\n\n# A tibble: 4 × 8\n  ticker date                 year quarter balanceSheet  cashF…¹ incom…² overv…³\n  <chr>  <dttm>              <int>   <int> <list>        <list>  <list>  <list> \n1 AAPL   2022-09-24 00:00:00  2022       4 <df [26 × 2]> <df>    <df>    <df>   \n2 AAPL   2022-09-24 00:00:00  2022       0 <df [26 × 2]> <df>    <df>    <df>   \n3 AAPL   2022-06-25 00:00:00  2022       3 <df [26 × 2]> <df>    <df>    <df>   \n4 AAPL   2022-03-26 00:00:00  2022       2 <df [26 × 2]> <df>    <df>    <df>   \n# … with abbreviated variable names ¹​cashFlow, ²​incomeStatement, ³​overview\n\n\n티블 내에 다시 데이터프레임이 들어간 형태입니다. 이 중 필요한 데이터만 선택해 묶음을 풀어주면 됩니다.\n\nlibrary(tidyr)\n\ndf %>%\n  select(ticker, date, year, quarter, balanceSheet) %>%\n  unnest(cols = c('balanceSheet'))\n\n# A tibble: 104 × 6\n   ticker date                 year quarter dataCode                     value\n   <chr>  <dttm>              <int>   <int> <chr>                        <dbl>\n 1 AAPL   2022-09-24 00:00:00  2022       4 liabilitiesCurrent    153982000000\n 2 AAPL   2022-09-24 00:00:00  2022       4 equity                 50672000000\n 3 AAPL   2022-09-24 00:00:00  2022       4 taxLiabilities                   0\n 4 AAPL   2022-09-24 00:00:00  2022       4 liabilitiesNonCurrent 148101000000\n 5 AAPL   2022-09-24 00:00:00  2022       4 retainedEarnings       -3068000000\n 6 AAPL   2022-09-24 00:00:00  2022       4 debtCurrent            21110000000\n 7 AAPL   2022-09-24 00:00:00  2022       4 taxAssets                        0\n 8 AAPL   2022-09-24 00:00:00  2022       4 assetsNonCurrent      217350000000\n 9 AAPL   2022-09-24 00:00:00  2022       4 acctPay                64115000000\n10 AAPL   2022-09-24 00:00:00  2022       4 debt                  120069000000\n# … with 94 more rows"
  },
  {
    "objectID": "intro.html#데이터-불러오기",
    "href": "intro.html#데이터-불러오기",
    "title": "1  데이터 분석 프로세스",
    "section": "1.1 데이터 불러오기",
    "text": "1.1 데이터 불러오기\n회사의 서버에 저장된 데이터를 불러와야 데이터 분석을 할 수 있습니다. 그러나 실무에서는 그보다 먼저 데이터의 수집 및 어떤 플랫폼에 저장할 지 제대로 정의해야, 수월한 데이터 분석을 수행할 수 있습니다.\n\n1.1.1 데이터 수집 및 저장\n제대로 된 데이터가 있어야 제대로 된 분석을 할 수 있습니다. 데이터 구매를 위해 비싼 비용을 사용하지만, 대부분의 데이터가 완벽하다고 말할 수는 없습니다. 해외 금융회사의 경우 여러 벤더로부터 데이터를 구매한 후 크로스체크를 통해 오류가 있는 데이터를 찾아내며, 주니어 퀀트의 경우 데이터 오류 검증을 하는 업무부터 시작해 나갑니다.\n또한 분석을 하기 편한 플랫폼에 저장되어 있어야 빠른 데이터 분석이 가능합니다. 예를 들어 raw data가 엑셀 형태로 되어있다면 관리도 쉽지 않고, 분석 하기에도 불편합니다.\n대부분 금융 데이터의 경우 주가, 재무제표 등 정형 데이터이므로, 데이터 저장에 RDBMS을 이용하는 것이 효율적입니다. sql을 이용할 경우 원하는 데이터를 수초 내에 조회가 가능합니다.\n\n\n\n\n\nRDBMS\n\n\n\n\n그러나 보험사나 카드사와 같이 쌓이는 데이터의 양이 지나치게 만을 경우, 단순히 sql로 데이터를 처리하기에는 한계가 있습니다. 실제로 sql 쿼리를 통해 원하는 데이터를 한달치 뽑는데만 10분 정도가 소요되기도 했습니다. 몇년치에 해당하는 데이터를 모두 뽑는데만 몇 시간이 걸리고, 만일 오류가 있어서 다시 데이터를 뽑아야 한다면 그냥 하루가 날아갑니다.\n이러한 빅데이터의 분석을 위해서는 RDBMS 보다는 하둡이나 스파크, 카프카 등을 이용하는 것이 좋습니다. 예를 들어 스파크의 경우 기존 sql과 비교해 월등히 빠른 속도와, 분석가들이 익숙한 R, Python, sql 문법을 그대로 사용할 수 있는 장점이 있습니다.\n만일 RDBMS로도 원하는 데이터를 ‘참을 만한 시간’ 내에 조회가 가능하다면 그대로 사용을, 도저히 감당이 안될 정도이면 빅데이터 플랫폼으로 변경할 것을 추천하며, 이러한 플랫폼의 차이는 분석가의 업무가 아니긴 하지만 어느 정도는 알고는 있는 것이 좋습니다.\n\n\n1.1.2 데이터 서버 접속 및 불러오기\n데이터 서버가 구축되어 있다고, 무작정 R/Python을 이용해 서버에 접속하여 데이터를 내려받아 분석을 하는 것은 좋지 않습니다. 데이터의 용량이 클 경우 내려받는데만 수 시간이 걸릴 수 있으며, 제대로 처리하지 못할 수도 있습니다. 따라서 서버 내에서 최대한 원하는 형태까지 데이터를 가공한 후(기본 클랜징, 그룹핑, 원하는 기간과 컬럼만 선택 등) R/Python을 이용해 분석을 하는 편이 효율적입니다.\n그러나 이를 위해 데이터를 담당하는 사람에게 일일이 요청할 수는 없습니다. 일부 회사에서 원하는 형태로 데이터를 요청할 때 마다 부서 비용이 지출되기도 하고, 원하는 형태가 아닐 경우 재요청을 해야합니다. 이 과정에서 비용 뿐만 아니라 며칠이 소요됩니다. 따라서 데이터를 분석하는 사람이라면 차라리 직접 서버에 접속해 원하는 데이터를 최대한 가공한 후, R/Python로 서버에 접속하여 데이터를 내려받는 것이 이상적입니다. 이를 위해 기본적인 sql 문법도 알고 있어야 하며, 다행히도 dplyr 패키지를 공부하면 sql 문법도 자연스럽게 공부가 됩니다.\nR의 경우 RJDBC, RODBC, ROrcacle 등의 패키지를 이용해 DB에 직접 연결할 수 있습니다. R과 서버를 연결시키면, R 내에서 직접 sql 쿼리를 날린 후 결과를 받을 수 있습니다.\nR에서는 spark 역시 사용할 수 있습니다.\n\nSparkR: http://spark.apache.org/docs/latest/sparkr.html\nsparklyr: https://spark.rstudio.com/\n\nzeppelin을 사용한다면 PySpark를 이용해 파이썬을 사용할 수도 있습니다.\n\nhttps://zeppelin.apache.org/docs/latest/interpreter/spark.html"
  },
  {
    "objectID": "intro.html#데이터-정리하기-tidy",
    "href": "intro.html#데이터-정리하기-tidy",
    "title": "1  데이터 분석 프로세스",
    "section": "1.2 데이터 정리하기 (tidy)",
    "text": "1.2 데이터 정리하기 (tidy)\n데이터 분석의 단계에서 가장 많은 시간을 할애하는 것이 데이터 정리하기, 즉 클랜징 단계입니다. 데이터가 제대로 클랜징 처리가 되어야 분석이나 모델링을 하는 것이 가능합니다. 다행히 금융 데이터는 데이터가 지저분한 형태로 들어오는 경우가 거의 없지만, 그래도 완벽하게 원하는 형태는 아닙니다. 더구나 비정형 데이터의 경우 클랜징 처리를 어떻게 하느냐에 따라 전혀 다른 결과가 나오기도 합니다. 클랜징이 필요한 예를 들어봅시다.\n\nDate가 yyyymmdd 형태로 들어올 경우, yyyy-mm-dd 형태로 변경\n시가총액이 ‘192,370,650’ 처럼 문자형태로 들어올 경우 192370650 인 숫자형태로 변경\n수익률이 19.30 형태로 들어올 경우, 0.1930 으로 변경\n컬럼이름 변경\n결측치(NA) 처리\n\n먼저 데이터의 전반적인 처리에는 tidyr 패키지가 사용됩니다. 그 외에도 팩터 처리에는 forcats, 시간 처리에는 lubridate, 문자 처리에는 stringr 패키지가 사용됩니다. 특히 금융 데이터는 대부분 시계열 형태로 들어오므로, lubridate 패키지가 많이 사용됩니다.\n또한 magrittr 패키지의 파이프 오퍼레이터(%>%)를 사용해 데이터를 훨씬 직관적으로 처리할 수 있습니다.\n\ntidyr: https://tidyr.tidyverse.org/\nforcats: https://forcats.tidyverse.org/\nlubridate: https://lubridate.tidyverse.org/\nstringr: https://stringr.tidyverse.org/\n\n물론 간단한 클랜징 처리는 R/Python이 아닌 sql 내에서 사전에 처리하는 것이 속도 측면에서 이득입니다."
  },
  {
    "objectID": "intro.html#데이터-분석하기-explore",
    "href": "intro.html#데이터-분석하기-explore",
    "title": "1  데이터 분석 프로세스",
    "section": "1.3 데이터 분석하기 (Explore)",
    "text": "1.3 데이터 분석하기 (Explore)\n원하는 데이터가 준비되었으면, 본격적으로 데이터를 분석해야 한다. 이 단계는 크게 변형, 시각화, 모델링으로 구분됩니다.\n\n1.3.1 데이터 변형\n먼저 각종 테이블을 하나로 합칠 필요가 있으며, 이 때는 *_join() 구문이 사용됩니다.\n\n\n\n\n\njoin\n\n\n\n\n또한 데이터를 분석하기 위해 다음 함수가 대표적으로 사용됩니다.\n\nselect(): 원하는 컬럼 선택\nfilter(): 조건에 맞는 행 선택\nmutate(): 열 생성 및 데이터 변형\ngroup_by(): 그룹별로 데이터를 묶기\n\n이 외에도 dplyr 패키지에는 데이터 분석을 위한 대부분의 함수가 포함되어 있습니다.\n\n\n1.3.2 데이터 시각화\nR의 가장 큰 강점은 데이터 시각화라고 말하는 사람도 있습니다. 그만큼 ggplot2 패키지를 이용해 데이터를 직관적으로 표현할 수 있다. 해당 패키지는 릴랜드 윌킨스(Leland Wilkinson)의 책 The Grammar of Graphics를 기본 철학으로 만들어졌습니다.\nggplot의 경우 인터넷에도 다양한 예제가 있으므로, 원하는 형태의 그림이 있을 시 얼마든지 검색이 가능합니다.\n\nhttps://r-graph-gallery.com/ggplot2-package.html\nhttp://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html"
  },
  {
    "objectID": "intro.html#모델링",
    "href": "intro.html#모델링",
    "title": "1  데이터 분석 프로세스",
    "section": "1.4 모델링",
    "text": "1.4 모델링\n기존의 R 내에 머신러닝 관련 패키지는 너무 분산되어 있었습니다. 그러나 Rstudio에서 통계분석, 머신러닝을 위한 tidymodel 세계관 구축 중입니다.\n\n\n\n\n\ntidymodel\n\n\n\n\n\nhttps://www.tidymodels.org/learn/\n\n과거 해들리 위컴의 R4DS 책이 발간된 이후 tidyverse 생태계가 R의 메인으로 자리잡은 것 처럼, tidymodel 패키지가 완성된 후 책으로 나온다면 이 역시 새로운 세계관으로 자리잡지 않을까 생각한다. 현재 해당 패키지를 만들고 있는 개발자들이 관련 책도 함께 써나가고 있는 중입니다.\n\nhttps://www.tmwr.org/"
  },
  {
    "objectID": "intro.html#소통-communicate",
    "href": "intro.html#소통-communicate",
    "title": "1  데이터 분석 프로세스",
    "section": "1.5 소통 (communicate)",
    "text": "1.5 소통 (communicate)\n혼자 일을 하지 않는 이상 결국 업무의 마무리는 문서화와 보고입니다. 하지만 사내에서만 보는 문서를 굳이 한글이나 워드로 작성하는 것은 매우 비효율적입니다. 코딩으로 나온 값을 다시 csv로 저장한 다음, 엑셀에서 가공하고, 그걸 다시 워드로 옮기고, 생각만 해도 숨막히는 작업입니다. R에서 코딩으로 데이터 분석을 했다면, 결과물 역시 코딩으로 하는 것이 훨씬 효율적입니다.\n\n1.5.1 Quarto\nQuarto는 문서 내에서 코드(R, 파이썬 등)와 텍스트를 동시에 사용가능하여 효율적으로 문서를 작성할 수 있게 해줍니다. 만일 양식이 동일한 문서에서 기초 데이터만 매번 바뀌는 상황이라면, 기존의 환경에서는 매번 기초 데이터를 뽑아 문서로 작성해야 합니다. 그러나 Quarto를 이용한다면 데이터를 받는 것부터 문서화까지 코드로 만들어 두어 100% 자동화가 가능합니다.\n\n\n\n\n\n\nhttps://quarto.org/\n\nQuarto는 기본적은 markdown 기능 외에도 latex, html(css)도 직접 사용 가능해 훨씬 아름다운 문서 작성이 가능합니다. Quarto를 이용한 문서화 과정은 다음과 같습니다.\n\nqmd로 문서를 작성\nknitr 패키지가 코드를 실행한 후 md 파일로 변환\npandoc 패키지가 각종 결과물로 변환 (HTML, PDF, Word, Presentation 등)\n\n\n\n\n\n\n실무적으로는 이러한 것들을 몰라도 Qmd 작성 테크닉만 알고 있다면, 작성 후 Render 버튼을 누르기만 하면 문서가 만들어집니다. 대부분의 경우 편하게 볼 수 있는 HTML 형태로 결과물을 생성하지만, 만일 보고용이라면 PDF로 결과물을 생성한 후, 프린트를 해도 됩니다.\n\n\n1.5.2 Quarto Book\nQuarto Book(Bookdown)은 Quarto를 이용해 만들 수 있으며, 웹북을 만들어 줍니다. 사내에서 업무 프로세스처럼 목차가 있는 문서를 만들어야 할 경우, 대부분 이파일 저파일 덕지덕지 저장해놓기 마련이며 관리도 되지 않습니다. 만일 이러한 것들을 웹북 형태로 만들어 둔다면 통합적으로 관리하기 용이하며, 인덱싱이 되므로 검색하기도 편합니다.\n\nhttps://hyunyulhenry.github.io/quant_cookbook/\n\n\n\n1.5.3 Shiny\nQuarto를 이용한 문서도 결과적으로 일차원적인 문서, 즉 보고자가 작성한 문서라는 한계가 있습니다. 그러나 보고를 받는 사람이 추가적인 데이터를 보고 싶을 경우, 예를 들어 운용중인 100개 펀드 리스트 중 원하는 펀드를 선택한 후, 원하는 날짜의 보유 종목을 확인하고자 할 경우, 매번 보고자가 해당 데이터를 뽑은 후 문서화를 해야 한다.\n그러나 R의 Shiny를 이용할 경우 간편하게 앱을 만들 수 있으며, 이 모든 과정이 가능합니다. 또한 Quarto와 마찬가지로 DB 서버에 연결하는 코드까지 짜둘 경우, DB가 업데이트 됨에 따라 앱의 결과물 역시 최신 데이터를 보여줍니다. 사내에 샤이니를 제대로 만들 줄 아는 사람 한명만 있어도, 굳이 비싼 돈을 주고 tableau를 구매하지 않아도 되고, 확장성도 훨씬 넓습니다.\n\nhttps://doomoolmori.shinyapps.io/boolio/"
  },
  {
    "objectID": "intro.html#배포",
    "href": "intro.html#배포",
    "title": "1  데이터 분석 프로세스",
    "section": "1.6 배포",
    "text": "1.6 배포\n코드를 저장하고, 완성된 문서를 배포하는 것 역시 중요합니다. 먼저 코드 저장의 경우 Rstudio와 Github를 연동해두면, 매우 쉽게 Github로 코드를 업로드할 수 있습니다. 만일 사내에서 Gitlab을 사용한다면, 이 또한 좋은 저장 수단입니다.\nGithub을 이용한다면 Quarto로 생성된 문서 역시 자동으로 url이 생성되므로, 문서를 공유하기 보다는 해당 url을 공유하는 것이 훨씬 좋습니다. 만일 데이터를 새로 분석하거나 양식이 바뀔 경우 파일을 공유하면 이래저래 꼬일 가능성이 있지만, url을 접속하면 최신 버젼의 파일이 자동으로 업데이트 되기 때문입니다.\nShiny의 경우도 Rstudio를 통해 shinyapps.io에 업로드하여 url을 생성할 수 있습니다. 그러나 보안 등의 이슈로 사내에서만 봐야하는 결과물이라면, 사내에 Shiny server를 설치하여 사내전용 url을 생성하는 것 역시 가능합니다. 또한 특정 부서만 접근이 가능하게 하려면 shinymanager 패키지를 통해 ID/PW를 부여할 수도 있습니다.\n매일 자동으로 생성되는 문서가 있다면, 문서가 생성된 후 이메일이나 슬랙/텔레그램으로 결과물을 전송하는 것 역시 가능합니다. 매일 체크해기는 해야하지만 그 중요도가 낮은 문서의 경우, 이러한 자동화를 통해 출근길에 휴대폰으로 간단하게 확인하는 것 또한 가능합니다."
  }
]